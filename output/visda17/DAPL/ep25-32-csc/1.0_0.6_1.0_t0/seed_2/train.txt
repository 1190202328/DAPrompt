***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/DAPL/ep25-32-v1.yaml
dataset_config_file: configs/datasets/visda17.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: ['TRAINER.DAPL.T', '1.0', 'TRAINER.DAPL.TAU', '0.6', 'TRAINER.DAPL.U', '1.0']
output_dir: output/visda17/DAPL/ep25-32-v1/1.0_0.6_1.0_t0/seed_2
resume: 
root: /home/data
seed: 2
source_domains: None
target_domains: None
trainer: DAPL
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 4
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 128
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: True
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 32
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: VisDA17
  NUM_LABELED: -1
  NUM_SHOTS: -1
  ROOT: /home/data
  SOURCE_DOMAINS: ('synthetic',)
  STL10_FOLD: -1
  TARGET_DOMAINS: ('real',)
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bicubic
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.48145466, 0.4578275, 0.40821073]
  PIXEL_STD: [0.26862954, 0.26130258, 0.27577711]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  SIZE: (224, 224)
  TRANSFORMS: ('random_resized_crop', 'random_flip', 'normalize')
MODEL:
  BACKBONE:
    NAME: RN101
    PATH: ./assets
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.003
  LR_SCHEDULER: cosine
  MAX_EPOCH: 25
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (-1,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: 1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/visda17/DAPL/ep25-32-v1/1.0_0.6_1.0_t0/seed_2
RESUME: 
SEED: 2
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: True
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 100
TRAINER:
  CG:
    ALPHA_D: 0.5
    ALPHA_F: 0.5
    EPS_D: 1.0
    EPS_F: 1.0
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 0.5
  DAPL:
    CSC: True
    N_CTX: 16
    N_DMX: 16
    PREC: amp
    T: 1.0
    TAU: 0.6
    U: 1.0
  DDAIG:
    ALPHA: 0.5
    CLAMP: False
    CLAMP_MAX: 1.0
    CLAMP_MIN: -1.0
    G_ARCH: 
    LMDA: 0.3
    WARMUP: 0
  ENTMIN:
    LMDA: 0.001
  FIXMATCH:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ()
    WEIGHT_U: 1.0
  M3SDA:
    LMDA: 0.5
    N_STEP_F: 4
  MCD:
    N_STEP_F: 4
  MEANTEA:
    EMA_ALPHA: 0.999
    RAMPUP: 5
    WEIGHT_U: 1.0
  MIXMATCH:
    MIXUP_BETA: 0.75
    RAMPUP: 20000
    TEMP: 2.0
    WEIGHT_U: 100.0
  MME:
    LMDA: 0.1
  NAME: DAPL
  SE:
    CONF_THRE: 0.95
    EMA_ALPHA: 0.999
    RAMPUP: 300
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 1.13.1+cu116
Is debug build: False
CUDA used to build PyTorch: 11.6
ROCM used to build PyTorch: N/A

OS: Ubuntu 18.04.5 LTS (x86_64)
GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.27

Python version: 3.8.0 (default, Nov  6 2019, 21:49:08)  [GCC 7.3.0] (64-bit runtime)
Python platform: Linux-4.15.0-194-generic-x86_64-with-glibc2.10
Is CUDA available: True
CUDA runtime version: 10.2.89
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA GeForce RTX 2080 Ti
Nvidia driver version: 510.47.03
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] numpy==1.24.1
[pip3] torch==1.13.1+cu116
[pip3] torchaudio==0.13.1+cu116
[pip3] torchvision==0.14.1+cu116
[conda] numpy                     1.24.1                   pypi_0    pypi
[conda] torch                     1.13.1+cu116             pypi_0    pypi
[conda] torchaudio                0.13.1+cu116             pypi_0    pypi
[conda] torchvision               0.14.1+cu116             pypi_0    pypi
        Pillow (9.4.0)

Loading trainer: DAPL
Loading dataset: VisDA17
Building transform_train
+ random resized crop (size=(224, 224))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
***** Dataset statistics *****
  Dataset: VisDA17
  Source domains: ('synthetic',)
  Target domains: ('real',)
  # classes: 12
  # train_x: 152,397
  # train_u: 55,388
  # test: 55,388
Loading CLIP (backbone: RN101)
Building custom CLIP
Initializing class-specific contexts
ctx vectors size: 
Initial context: "X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X"
Number of context words (tokens): 16
Number of domain context words (tokens): 16
Turning off gradients in both the image and the text encoder
Loading evaluator: Classification
No checkpoint found, train from scratch
Initializing summary writer for tensorboard with log_dir=output/visda17/DAPL/ep25-32-v1/1.0_0.6_1.0_t0/seed_2/tensorboard
epoch [1/25][100/4762]	time 0.134 (1.031)	data 0.001 (0.007)	eta 1 day, 10:04:39	loss 0.6585 (1.0379)	loss_x 0.6223 (0.8392)	loss_u 0.0361 (0.1987)	acc_x 84.3750 (72.3750)	lr 2.988172e-03
epoch [1/25][200/4762]	time 0.173 (0.589)	data 0.001 (0.004)	eta 19:27:18	loss 0.5128 (0.8366)	loss_x 0.4728 (0.7117)	loss_u 0.0399 (0.1249)	acc_x 84.3750 (76.0469)	lr 2.988172e-03
epoch [1/25][300/4762]	time 0.142 (0.442)	data 0.001 (0.003)	eta 14:35:17	loss 0.4899 (0.7608)	loss_x 0.4680 (0.6634)	loss_u 0.0219 (0.0975)	acc_x 81.2500 (77.4792)	lr 2.988172e-03
epoch [1/25][400/4762]	time 0.186 (0.368)	data 0.001 (0.002)	eta 12:08:18	loss 0.3339 (0.7141)	loss_x 0.2720 (0.6305)	loss_u 0.0619 (0.0836)	acc_x 90.6250 (78.3906)	lr 2.988172e-03
epoch [1/25][500/4762]	time 0.158 (0.325)	data 0.001 (0.002)	eta 10:42:51	loss 0.7445 (0.6885)	loss_x 0.6690 (0.6136)	loss_u 0.0755 (0.0750)	acc_x 71.8750 (78.8812)	lr 2.988172e-03
epoch [1/25][600/4762]	time 0.142 (0.296)	data 0.002 (0.002)	eta 9:44:45	loss 0.5613 (0.6600)	loss_x 0.5362 (0.5917)	loss_u 0.0251 (0.0682)	acc_x 87.5000 (79.5990)	lr 2.988172e-03
epoch [1/25][700/4762]	time 0.142 (0.275)	data 0.001 (0.002)	eta 9:01:44	loss 0.5968 (0.6400)	loss_x 0.5921 (0.5774)	loss_u 0.0048 (0.0626)	acc_x 81.2500 (80.0357)	lr 2.988172e-03
epoch [1/25][800/4762]	time 0.140 (0.259)	data 0.001 (0.002)	eta 8:30:21	loss 0.8172 (0.6245)	loss_x 0.7709 (0.5656)	loss_u 0.0463 (0.0588)	acc_x 78.1250 (80.3789)	lr 2.988172e-03
epoch [1/25][900/4762]	time 0.148 (0.247)	data 0.001 (0.001)	eta 8:05:28	loss 0.4158 (0.6109)	loss_x 0.3673 (0.5553)	loss_u 0.0485 (0.0556)	acc_x 87.5000 (80.7153)	lr 2.988172e-03
epoch [1/25][1000/4762]	time 0.153 (0.237)	data 0.001 (0.001)	eta 7:46:15	loss 0.5199 (0.6016)	loss_x 0.4869 (0.5485)	loss_u 0.0331 (0.0531)	acc_x 81.2500 (80.9000)	lr 2.988172e-03
epoch [1/25][1100/4762]	time 0.145 (0.229)	data 0.001 (0.001)	eta 7:30:08	loss 0.5803 (0.5933)	loss_x 0.5592 (0.5420)	loss_u 0.0211 (0.0512)	acc_x 78.1250 (81.0170)	lr 2.988172e-03
epoch [1/25][1200/4762]	time 0.138 (0.222)	data 0.001 (0.001)	eta 7:16:54	loss 0.6341 (0.5848)	loss_x 0.6193 (0.5356)	loss_u 0.0148 (0.0491)	acc_x 75.0000 (81.2422)	lr 2.988172e-03
epoch [1/25][1300/4762]	time 0.154 (0.217)	data 0.001 (0.001)	eta 7:05:16	loss 0.1869 (0.5770)	loss_x 0.1229 (0.5290)	loss_u 0.0640 (0.0479)	acc_x 96.8750 (81.4760)	lr 2.988172e-03
epoch [1/25][1400/4762]	time 0.144 (0.212)	data 0.001 (0.001)	eta 6:55:12	loss 0.7570 (0.5697)	loss_x 0.7150 (0.5235)	loss_u 0.0420 (0.0462)	acc_x 71.8750 (81.6272)	lr 2.988172e-03
epoch [1/25][1500/4762]	time 0.157 (0.208)	data 0.001 (0.001)	eta 6:46:36	loss 0.3898 (0.5631)	loss_x 0.3793 (0.5183)	loss_u 0.0105 (0.0448)	acc_x 87.5000 (81.7833)	lr 2.988172e-03
epoch [1/25][1600/4762]	time 0.138 (0.204)	data 0.001 (0.001)	eta 6:39:11	loss 0.3253 (0.5579)	loss_x 0.3137 (0.5142)	loss_u 0.0116 (0.0437)	acc_x 87.5000 (81.9355)	lr 2.988172e-03
epoch [1/25][1700/4762]	time 0.139 (0.201)	data 0.001 (0.001)	eta 6:32:36	loss 0.5881 (0.5533)	loss_x 0.5487 (0.5108)	loss_u 0.0395 (0.0425)	acc_x 78.1250 (82.0515)	lr 2.988172e-03
epoch [1/25][1800/4762]	time 0.146 (0.198)	data 0.001 (0.001)	eta 6:27:18	loss 0.8350 (0.5497)	loss_x 0.8279 (0.5081)	loss_u 0.0071 (0.0415)	acc_x 78.1250 (82.1510)	lr 2.988172e-03
epoch [1/25][1900/4762]	time 0.140 (0.196)	data 0.001 (0.001)	eta 6:22:04	loss 0.5239 (0.5460)	loss_x 0.4896 (0.5056)	loss_u 0.0344 (0.0404)	acc_x 81.2500 (82.2171)	lr 2.988172e-03
epoch [1/25][2000/4762]	time 0.137 (0.193)	data 0.001 (0.001)	eta 6:17:14	loss 0.3003 (0.5425)	loss_x 0.2926 (0.5030)	loss_u 0.0076 (0.0395)	acc_x 87.5000 (82.3516)	lr 2.988172e-03
epoch [1/25][2100/4762]	time 0.171 (0.191)	data 0.001 (0.001)	eta 6:12:50	loss 0.6710 (0.5381)	loss_x 0.5994 (0.4993)	loss_u 0.0716 (0.0388)	acc_x 84.3750 (82.5208)	lr 2.988172e-03
epoch [1/25][2200/4762]	time 0.161 (0.189)	data 0.001 (0.001)	eta 6:08:56	loss 0.5864 (0.5355)	loss_x 0.5308 (0.4972)	loss_u 0.0557 (0.0383)	acc_x 81.2500 (82.6151)	lr 2.988172e-03
epoch [1/25][2300/4762]	time 0.139 (0.188)	data 0.001 (0.001)	eta 6:05:27	loss 0.3637 (0.5333)	loss_x 0.3313 (0.4957)	loss_u 0.0324 (0.0376)	acc_x 90.6250 (82.6685)	lr 2.988172e-03
epoch [1/25][2400/4762]	time 0.141 (0.186)	data 0.001 (0.001)	eta 6:01:54	loss 0.7609 (0.5309)	loss_x 0.7547 (0.4938)	loss_u 0.0061 (0.0371)	acc_x 68.7500 (82.7396)	lr 2.988172e-03
epoch [1/25][2500/4762]	time 0.147 (0.185)	data 0.001 (0.001)	eta 5:58:40	loss 0.2973 (0.5272)	loss_x 0.2914 (0.4906)	loss_u 0.0059 (0.0366)	acc_x 93.7500 (82.8650)	lr 2.988172e-03
epoch [1/25][2600/4762]	time 0.141 (0.183)	data 0.001 (0.001)	eta 5:55:45	loss 0.3171 (0.5237)	loss_x 0.2943 (0.4876)	loss_u 0.0229 (0.0361)	acc_x 93.7500 (82.9279)	lr 2.988172e-03
epoch [1/25][2700/4762]	time 0.159 (0.182)	data 0.001 (0.001)	eta 5:52:59	loss 0.4126 (0.5202)	loss_x 0.4099 (0.4847)	loss_u 0.0027 (0.0355)	acc_x 78.1250 (83.0324)	lr 2.988172e-03
epoch [1/25][2800/4762]	time 0.154 (0.181)	data 0.001 (0.001)	eta 5:50:24	loss 0.5728 (0.5173)	loss_x 0.5243 (0.4822)	loss_u 0.0484 (0.0351)	acc_x 84.3750 (83.1016)	lr 2.988172e-03
epoch [1/25][2900/4762]	time 0.141 (0.180)	data 0.001 (0.001)	eta 5:48:04	loss 0.3855 (0.5156)	loss_x 0.3403 (0.4809)	loss_u 0.0452 (0.0346)	acc_x 90.6250 (83.1444)	lr 2.988172e-03
epoch [1/25][3000/4762]	time 0.139 (0.179)	data 0.001 (0.001)	eta 5:45:50	loss 0.3192 (0.5136)	loss_x 0.3155 (0.4795)	loss_u 0.0037 (0.0341)	acc_x 87.5000 (83.1865)	lr 2.988172e-03
epoch [1/25][3100/4762]	time 0.143 (0.178)	data 0.001 (0.001)	eta 5:43:34	loss 0.5259 (0.5117)	loss_x 0.5124 (0.4781)	loss_u 0.0135 (0.0336)	acc_x 78.1250 (83.2349)	lr 2.988172e-03
epoch [1/25][3200/4762]	time 0.156 (0.177)	data 0.001 (0.001)	eta 5:41:31	loss 0.3962 (0.5096)	loss_x 0.3774 (0.4763)	loss_u 0.0189 (0.0333)	acc_x 87.5000 (83.2900)	lr 2.988172e-03
epoch [1/25][3300/4762]	time 0.153 (0.176)	data 0.001 (0.001)	eta 5:39:42	loss 0.3410 (0.5084)	loss_x 0.3297 (0.4755)	loss_u 0.0114 (0.0328)	acc_x 90.6250 (83.2964)	lr 2.988172e-03
epoch [1/25][3400/4762]	time 0.138 (0.175)	data 0.001 (0.001)	eta 5:37:52	loss 0.5321 (0.5064)	loss_x 0.5274 (0.4739)	loss_u 0.0047 (0.0325)	acc_x 75.0000 (83.3502)	lr 2.988172e-03
epoch [1/25][3500/4762]	time 0.147 (0.175)	data 0.001 (0.001)	eta 5:36:20	loss 0.4327 (0.5044)	loss_x 0.4235 (0.4722)	loss_u 0.0091 (0.0322)	acc_x 84.3750 (83.4223)	lr 2.988172e-03
epoch [1/25][3600/4762]	time 0.166 (0.174)	data 0.001 (0.001)	eta 5:34:53	loss 0.6917 (0.5026)	loss_x 0.6828 (0.4706)	loss_u 0.0089 (0.0320)	acc_x 78.1250 (83.4722)	lr 2.988172e-03
epoch [1/25][3700/4762]	time 0.140 (0.173)	data 0.001 (0.001)	eta 5:33:14	loss 0.2427 (0.5006)	loss_x 0.2264 (0.4689)	loss_u 0.0164 (0.0317)	acc_x 90.6250 (83.5312)	lr 2.988172e-03
epoch [1/25][3800/4762]	time 0.156 (0.173)	data 0.001 (0.001)	eta 5:31:40	loss 0.3139 (0.4987)	loss_x 0.2937 (0.4672)	loss_u 0.0202 (0.0314)	acc_x 90.6250 (83.5987)	lr 2.988172e-03
epoch [1/25][3900/4762]	time 0.148 (0.172)	data 0.001 (0.001)	eta 5:30:09	loss 0.2815 (0.4972)	loss_x 0.2755 (0.4658)	loss_u 0.0060 (0.0314)	acc_x 90.6250 (83.6546)	lr 2.988172e-03
epoch [1/25][4000/4762]	time 0.143 (0.171)	data 0.001 (0.001)	eta 5:28:45	loss 0.5124 (0.4958)	loss_x 0.4888 (0.4648)	loss_u 0.0236 (0.0310)	acc_x 84.3750 (83.6922)	lr 2.988172e-03
epoch [1/25][4100/4762]	time 0.143 (0.171)	data 0.001 (0.001)	eta 5:27:29	loss 0.5051 (0.4941)	loss_x 0.4614 (0.4634)	loss_u 0.0437 (0.0307)	acc_x 78.1250 (83.7279)	lr 2.988172e-03
epoch [1/25][4200/4762]	time 0.143 (0.170)	data 0.001 (0.001)	eta 5:26:12	loss 0.3838 (0.4931)	loss_x 0.3732 (0.4626)	loss_u 0.0106 (0.0305)	acc_x 87.5000 (83.7604)	lr 2.988172e-03
epoch [1/25][4300/4762]	time 0.161 (0.170)	data 0.001 (0.001)	eta 5:24:58	loss 0.2307 (0.4914)	loss_x 0.2261 (0.4612)	loss_u 0.0047 (0.0303)	acc_x 87.5000 (83.8190)	lr 2.988172e-03
epoch [1/25][4400/4762]	time 0.143 (0.169)	data 0.001 (0.001)	eta 5:23:27	loss 0.4639 (0.4900)	loss_x 0.4517 (0.4599)	loss_u 0.0122 (0.0301)	acc_x 81.2500 (83.8501)	lr 2.988172e-03
epoch [1/25][4500/4762]	time 0.146 (0.169)	data 0.001 (0.001)	eta 5:22:28	loss 0.3632 (0.4887)	loss_x 0.3562 (0.4588)	loss_u 0.0070 (0.0299)	acc_x 87.5000 (83.8944)	lr 2.988172e-03
epoch [1/25][4600/4762]	time 0.145 (0.168)	data 0.001 (0.001)	eta 5:21:22	loss 0.4493 (0.4877)	loss_x 0.4446 (0.4581)	loss_u 0.0047 (0.0296)	acc_x 78.1250 (83.9287)	lr 2.988172e-03
epoch [1/25][4700/4762]	time 0.141 (0.168)	data 0.001 (0.001)	eta 5:20:13	loss 0.3544 (0.4862)	loss_x 0.3524 (0.4568)	loss_u 0.0020 (0.0294)	acc_x 81.2500 (83.9608)	lr 2.988172e-03
Do evaluation on test set
=> result
* total: 55,388
* correct: 47,096
* accuracy: 85.03%
* error: 14.97%
* macro_f1: 85.38%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,585	acc: 98.33%
* class: 1 (bicycle)	total: 3,475	correct: 2,938	acc: 84.55%
* class: 2 (bus)	total: 4,690	correct: 4,255	acc: 90.72%
* class: 3 (car)	total: 10,401	correct: 7,849	acc: 75.46%
* class: 4 (horse)	total: 4,691	correct: 4,572	acc: 97.46%
* class: 5 (knife)	total: 2,075	correct: 1,891	acc: 91.13%
* class: 6 (motorcycle)	total: 5,796	correct: 5,513	acc: 95.12%
* class: 7 (person)	total: 4,000	correct: 3,118	acc: 77.95%
* class: 8 (plant)	total: 4,549	correct: 3,933	acc: 86.46%
* class: 9 (skateboard)	total: 2,281	correct: 2,023	acc: 88.69%
* class: 10 (train)	total: 4,236	correct: 3,926	acc: 92.68%
* class: 11 (truck)	total: 5,548	correct: 3,493	acc: 62.96%
* average: 86.79%
Checkpoint saved to "output/visda17/DAPL/ep25-32-v1/1.0_0.6_1.0_t0/seed_2/prompt_learner/model-best.pth.tar"
epoch [2/25][100/4762]	time 0.139 (0.153)	data 0.001 (0.003)	eta 4:51:37	loss 0.2271 (0.4132)	loss_x 0.2255 (0.3932)	loss_u 0.0016 (0.0199)	acc_x 90.6250 (86.2500)	lr 1.781072e-03
epoch [2/25][200/4762]	time 0.137 (0.156)	data 0.001 (0.002)	eta 4:55:48	loss 0.5199 (0.4259)	loss_x 0.5159 (0.4075)	loss_u 0.0041 (0.0185)	acc_x 78.1250 (85.7656)	lr 1.781072e-03
epoch [2/25][300/4762]	time 0.139 (0.154)	data 0.001 (0.002)	eta 4:52:16	loss 0.3605 (0.4284)	loss_x 0.3516 (0.4097)	loss_u 0.0089 (0.0187)	acc_x 84.3750 (85.5729)	lr 1.781072e-03
epoch [2/25][400/4762]	time 0.144 (0.153)	data 0.001 (0.001)	eta 4:49:50	loss 0.6421 (0.4254)	loss_x 0.6340 (0.4069)	loss_u 0.0081 (0.0185)	acc_x 81.2500 (85.7656)	lr 1.781072e-03
epoch [2/25][500/4762]	time 0.144 (0.152)	data 0.001 (0.001)	eta 4:48:17	loss 0.5567 (0.4256)	loss_x 0.5195 (0.4068)	loss_u 0.0373 (0.0188)	acc_x 84.3750 (85.7687)	lr 1.781072e-03
epoch [2/25][600/4762]	time 0.149 (0.152)	data 0.001 (0.001)	eta 4:47:34	loss 0.7983 (0.4271)	loss_x 0.7871 (0.4085)	loss_u 0.0111 (0.0185)	acc_x 75.0000 (85.7031)	lr 1.781072e-03
epoch [2/25][700/4762]	time 0.185 (0.151)	data 0.000 (0.001)	eta 4:46:41	loss 0.1380 (0.4309)	loss_x 0.1308 (0.4126)	loss_u 0.0072 (0.0184)	acc_x 93.7500 (85.5402)	lr 1.781072e-03
epoch [2/25][800/4762]	time 0.137 (0.151)	data 0.001 (0.001)	eta 4:45:41	loss 0.4070 (0.4319)	loss_x 0.3876 (0.4138)	loss_u 0.0194 (0.0181)	acc_x 81.2500 (85.5039)	lr 1.781072e-03
epoch [2/25][900/4762]	time 0.141 (0.150)	data 0.001 (0.001)	eta 4:44:02	loss 0.3967 (0.4315)	loss_x 0.3888 (0.4131)	loss_u 0.0079 (0.0184)	acc_x 87.5000 (85.4896)	lr 1.781072e-03
epoch [2/25][1000/4762]	time 0.170 (0.150)	data 0.001 (0.001)	eta 4:43:33	loss 0.3016 (0.4308)	loss_x 0.2788 (0.4123)	loss_u 0.0228 (0.0185)	acc_x 90.6250 (85.4688)	lr 1.781072e-03
epoch [2/25][1100/4762]	time 0.140 (0.150)	data 0.001 (0.001)	eta 4:42:32	loss 0.8198 (0.4308)	loss_x 0.8047 (0.4125)	loss_u 0.0151 (0.0182)	acc_x 71.8750 (85.4631)	lr 1.781072e-03
epoch [2/25][1200/4762]	time 0.148 (0.150)	data 0.001 (0.001)	eta 4:42:31	loss 0.3901 (0.4297)	loss_x 0.3784 (0.4115)	loss_u 0.0117 (0.0181)	acc_x 84.3750 (85.4896)	lr 1.781072e-03
epoch [2/25][1300/4762]	time 0.147 (0.150)	data 0.001 (0.001)	eta 4:42:06	loss 0.3606 (0.4288)	loss_x 0.3519 (0.4105)	loss_u 0.0087 (0.0182)	acc_x 87.5000 (85.5144)	lr 1.781072e-03
epoch [2/25][1400/4762]	time 0.178 (0.150)	data 0.001 (0.001)	eta 4:42:02	loss 0.4103 (0.4281)	loss_x 0.4086 (0.4098)	loss_u 0.0017 (0.0182)	acc_x 87.5000 (85.5804)	lr 1.781072e-03
epoch [2/25][1500/4762]	time 0.145 (0.150)	data 0.001 (0.001)	eta 4:41:40	loss 0.2030 (0.4272)	loss_x 0.1825 (0.4090)	loss_u 0.0205 (0.0183)	acc_x 93.7500 (85.6146)	lr 1.781072e-03
epoch [2/25][1600/4762]	time 0.203 (0.150)	data 0.001 (0.001)	eta 4:41:46	loss 0.6413 (0.4258)	loss_x 0.6306 (0.4077)	loss_u 0.0107 (0.0181)	acc_x 75.0000 (85.6289)	lr 1.781072e-03
epoch [2/25][1700/4762]	time 0.156 (0.150)	data 0.001 (0.001)	eta 4:41:12	loss 0.3572 (0.4257)	loss_x 0.3475 (0.4077)	loss_u 0.0097 (0.0180)	acc_x 84.3750 (85.6544)	lr 1.781072e-03
epoch [2/25][1800/4762]	time 0.143 (0.150)	data 0.001 (0.001)	eta 4:41:08	loss 0.4326 (0.4254)	loss_x 0.4174 (0.4076)	loss_u 0.0152 (0.0178)	acc_x 87.5000 (85.6997)	lr 1.781072e-03
epoch [2/25][1900/4762]	time 0.161 (0.150)	data 0.001 (0.001)	eta 4:40:54	loss 0.4231 (0.4248)	loss_x 0.3971 (0.4071)	loss_u 0.0260 (0.0177)	acc_x 87.5000 (85.7516)	lr 1.781072e-03
epoch [2/25][2000/4762]	time 0.168 (0.150)	data 0.001 (0.001)	eta 4:40:40	loss 0.2124 (0.4238)	loss_x 0.1988 (0.4062)	loss_u 0.0136 (0.0177)	acc_x 96.8750 (85.7719)	lr 1.781072e-03
epoch [2/25][2100/4762]	time 0.163 (0.150)	data 0.001 (0.001)	eta 4:40:52	loss 0.5660 (0.4238)	loss_x 0.5571 (0.4063)	loss_u 0.0088 (0.0176)	acc_x 84.3750 (85.7693)	lr 1.781072e-03
epoch [2/25][2200/4762]	time 0.139 (0.150)	data 0.004 (0.001)	eta 4:40:51	loss 0.5204 (0.4233)	loss_x 0.5076 (0.4057)	loss_u 0.0127 (0.0176)	acc_x 84.3750 (85.7784)	lr 1.781072e-03
epoch [2/25][2300/4762]	time 0.146 (0.150)	data 0.001 (0.001)	eta 4:40:18	loss 0.3418 (0.4244)	loss_x 0.3299 (0.4066)	loss_u 0.0118 (0.0178)	acc_x 87.5000 (85.7364)	lr 1.781072e-03
epoch [2/25][2400/4762]	time 0.142 (0.150)	data 0.001 (0.001)	eta 4:40:12	loss 0.6266 (0.4250)	loss_x 0.6047 (0.4071)	loss_u 0.0218 (0.0179)	acc_x 78.1250 (85.6992)	lr 1.781072e-03
epoch [2/25][2500/4762]	time 0.137 (0.150)	data 0.001 (0.001)	eta 4:39:52	loss 0.6323 (0.4237)	loss_x 0.6165 (0.4059)	loss_u 0.0158 (0.0178)	acc_x 78.1250 (85.7362)	lr 1.781072e-03
epoch [2/25][2600/4762]	time 0.139 (0.150)	data 0.001 (0.001)	eta 4:39:33	loss 0.2573 (0.4227)	loss_x 0.2536 (0.4050)	loss_u 0.0037 (0.0177)	acc_x 90.6250 (85.7764)	lr 1.781072e-03
epoch [2/25][2700/4762]	time 0.136 (0.150)	data 0.001 (0.001)	eta 4:39:00	loss 0.3939 (0.4220)	loss_x 0.3835 (0.4043)	loss_u 0.0104 (0.0177)	acc_x 87.5000 (85.7998)	lr 1.781072e-03
epoch [2/25][2800/4762]	time 0.140 (0.150)	data 0.001 (0.001)	eta 4:38:40	loss 0.3759 (0.4214)	loss_x 0.3705 (0.4037)	loss_u 0.0054 (0.0177)	acc_x 84.3750 (85.8259)	lr 1.781072e-03
epoch [2/25][2900/4762]	time 0.139 (0.150)	data 0.001 (0.001)	eta 4:38:25	loss 0.3443 (0.4207)	loss_x 0.3307 (0.4030)	loss_u 0.0136 (0.0177)	acc_x 84.3750 (85.8341)	lr 1.781072e-03
epoch [2/25][3000/4762]	time 0.143 (0.150)	data 0.001 (0.001)	eta 4:38:03	loss 0.4107 (0.4202)	loss_x 0.4043 (0.4024)	loss_u 0.0064 (0.0177)	acc_x 87.5000 (85.8729)	lr 1.781072e-03
epoch [2/25][3100/4762]	time 0.139 (0.150)	data 0.001 (0.001)	eta 4:37:50	loss 0.6647 (0.4208)	loss_x 0.6623 (0.4032)	loss_u 0.0025 (0.0176)	acc_x 78.1250 (85.8377)	lr 1.781072e-03
epoch [2/25][3200/4762]	time 0.144 (0.150)	data 0.001 (0.001)	eta 4:37:26	loss 0.3344 (0.4208)	loss_x 0.3246 (0.4032)	loss_u 0.0098 (0.0176)	acc_x 84.3750 (85.8262)	lr 1.781072e-03
epoch [2/25][3300/4762]	time 0.143 (0.150)	data 0.001 (0.001)	eta 4:37:16	loss 0.5272 (0.4212)	loss_x 0.5198 (0.4036)	loss_u 0.0074 (0.0176)	acc_x 78.1250 (85.8163)	lr 1.781072e-03
epoch [2/25][3400/4762]	time 0.147 (0.150)	data 0.001 (0.001)	eta 4:36:57	loss 0.5194 (0.4214)	loss_x 0.4303 (0.4039)	loss_u 0.0891 (0.0175)	acc_x 81.2500 (85.8006)	lr 1.781072e-03
epoch [2/25][3500/4762]	time 0.141 (0.150)	data 0.001 (0.001)	eta 4:36:49	loss 0.3493 (0.4216)	loss_x 0.3097 (0.4042)	loss_u 0.0396 (0.0174)	acc_x 93.7500 (85.7884)	lr 1.781072e-03
epoch [2/25][3600/4762]	time 0.149 (0.150)	data 0.001 (0.001)	eta 4:36:40	loss 0.3418 (0.4219)	loss_x 0.3367 (0.4046)	loss_u 0.0051 (0.0174)	acc_x 84.3750 (85.7674)	lr 1.781072e-03
epoch [2/25][3700/4762]	time 0.137 (0.150)	data 0.001 (0.001)	eta 4:36:20	loss 0.3596 (0.4214)	loss_x 0.3531 (0.4041)	loss_u 0.0065 (0.0174)	acc_x 84.3750 (85.7644)	lr 1.781072e-03
epoch [2/25][3800/4762]	time 0.138 (0.150)	data 0.001 (0.001)	eta 4:36:05	loss 0.3050 (0.4213)	loss_x 0.2131 (0.4039)	loss_u 0.0919 (0.0174)	acc_x 93.7500 (85.7804)	lr 1.781072e-03
epoch [2/25][3900/4762]	time 0.194 (0.150)	data 0.001 (0.001)	eta 4:35:48	loss 0.4961 (0.4206)	loss_x 0.4929 (0.4032)	loss_u 0.0032 (0.0173)	acc_x 81.2500 (85.8085)	lr 1.781072e-03
epoch [2/25][4000/4762]	time 0.139 (0.150)	data 0.001 (0.001)	eta 4:35:30	loss 0.2330 (0.4206)	loss_x 0.2281 (0.4033)	loss_u 0.0049 (0.0173)	acc_x 90.6250 (85.8086)	lr 1.781072e-03
epoch [2/25][4100/4762]	time 0.148 (0.150)	data 0.001 (0.001)	eta 4:35:20	loss 0.6046 (0.4208)	loss_x 0.5896 (0.4035)	loss_u 0.0150 (0.0172)	acc_x 81.2500 (85.8056)	lr 1.781072e-03
epoch [2/25][4200/4762]	time 0.138 (0.150)	data 0.001 (0.001)	eta 4:35:06	loss 0.6031 (0.4206)	loss_x 0.5814 (0.4034)	loss_u 0.0217 (0.0173)	acc_x 75.0000 (85.8006)	lr 1.781072e-03
epoch [2/25][4300/4762]	time 0.137 (0.150)	data 0.001 (0.001)	eta 4:34:43	loss 0.5167 (0.4205)	loss_x 0.4829 (0.4033)	loss_u 0.0338 (0.0172)	acc_x 81.2500 (85.8009)	lr 1.781072e-03
epoch [2/25][4400/4762]	time 0.152 (0.150)	data 0.001 (0.001)	eta 4:34:31	loss 0.3201 (0.4203)	loss_x 0.2866 (0.4031)	loss_u 0.0335 (0.0171)	acc_x 90.6250 (85.8011)	lr 1.781072e-03
epoch [2/25][4500/4762]	time 0.139 (0.150)	data 0.001 (0.001)	eta 4:34:07	loss 0.2576 (0.4201)	loss_x 0.2521 (0.4031)	loss_u 0.0055 (0.0171)	acc_x 87.5000 (85.7931)	lr 1.781072e-03
epoch [2/25][4600/4762]	time 0.139 (0.150)	data 0.001 (0.001)	eta 4:33:45	loss 0.4657 (0.4201)	loss_x 0.4641 (0.4030)	loss_u 0.0016 (0.0171)	acc_x 78.1250 (85.7928)	lr 1.781072e-03
epoch [2/25][4700/4762]	time 0.137 (0.150)	data 0.001 (0.001)	eta 4:33:32	loss 0.2334 (0.4200)	loss_x 0.2203 (0.4029)	loss_u 0.0131 (0.0171)	acc_x 93.7500 (85.8059)	lr 1.781072e-03
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,935
* accuracy: 84.74%
* error: 15.26%
* macro_f1: 85.04%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,585	acc: 98.33%
* class: 1 (bicycle)	total: 3,475	correct: 2,950	acc: 84.89%
* class: 2 (bus)	total: 4,690	correct: 4,279	acc: 91.24%
* class: 3 (car)	total: 10,401	correct: 7,613	acc: 73.19%
* class: 4 (horse)	total: 4,691	correct: 4,579	acc: 97.61%
* class: 5 (knife)	total: 2,075	correct: 1,885	acc: 90.84%
* class: 6 (motorcycle)	total: 5,796	correct: 5,517	acc: 95.19%
* class: 7 (person)	total: 4,000	correct: 3,092	acc: 77.30%
* class: 8 (plant)	total: 4,549	correct: 3,984	acc: 87.58%
* class: 9 (skateboard)	total: 2,281	correct: 2,066	acc: 90.57%
* class: 10 (train)	total: 4,236	correct: 3,921	acc: 92.56%
* class: 11 (truck)	total: 5,548	correct: 3,464	acc: 62.44%
* average: 86.81%
epoch [3/25][100/4762]	time 0.161 (0.152)	data 0.001 (0.004)	eta 4:36:52	loss 0.1658 (0.4088)	loss_x 0.1623 (0.3901)	loss_u 0.0036 (0.0186)	acc_x 93.7500 (86.6250)	lr 4.712526e-05
epoch [3/25][200/4762]	time 0.143 (0.152)	data 0.001 (0.002)	eta 4:36:08	loss 0.2701 (0.4098)	loss_x 0.2636 (0.3935)	loss_u 0.0065 (0.0163)	acc_x 90.6250 (86.4375)	lr 4.712526e-05
epoch [3/25][300/4762]	time 0.164 (0.152)	data 0.001 (0.002)	eta 4:36:56	loss 0.5506 (0.4149)	loss_x 0.5357 (0.3988)	loss_u 0.0149 (0.0161)	acc_x 84.3750 (86.1146)	lr 4.712526e-05
epoch [3/25][400/4762]	time 0.144 (0.152)	data 0.001 (0.002)	eta 4:36:28	loss 0.3046 (0.4121)	loss_x 0.2902 (0.3963)	loss_u 0.0144 (0.0158)	acc_x 93.7500 (86.0156)	lr 4.712526e-05
epoch [3/25][500/4762]	time 0.139 (0.152)	data 0.001 (0.001)	eta 4:36:09	loss 0.6418 (0.4144)	loss_x 0.6333 (0.3986)	loss_u 0.0085 (0.0158)	acc_x 75.0000 (86.0563)	lr 4.712526e-05
epoch [3/25][600/4762]	time 0.144 (0.152)	data 0.001 (0.001)	eta 4:35:10	loss 0.2365 (0.4088)	loss_x 0.2236 (0.3931)	loss_u 0.0129 (0.0156)	acc_x 90.6250 (86.3229)	lr 4.712526e-05
epoch [3/25][700/4762]	time 0.150 (0.151)	data 0.001 (0.001)	eta 4:34:09	loss 0.2715 (0.4102)	loss_x 0.2562 (0.3951)	loss_u 0.0153 (0.0150)	acc_x 90.6250 (86.2321)	lr 4.712526e-05
epoch [3/25][800/4762]	time 0.139 (0.151)	data 0.003 (0.001)	eta 4:33:27	loss 0.2145 (0.4077)	loss_x 0.2072 (0.3929)	loss_u 0.0073 (0.0148)	acc_x 93.7500 (86.3281)	lr 4.712526e-05
epoch [3/25][900/4762]	time 0.145 (0.151)	data 0.001 (0.001)	eta 4:33:10	loss 0.3023 (0.4076)	loss_x 0.2934 (0.3922)	loss_u 0.0089 (0.0153)	acc_x 87.5000 (86.2674)	lr 4.712526e-05
epoch [3/25][1000/4762]	time 0.140 (0.151)	data 0.001 (0.001)	eta 4:32:59	loss 0.4890 (0.4083)	loss_x 0.4857 (0.3929)	loss_u 0.0033 (0.0154)	acc_x 84.3750 (86.2438)	lr 4.712526e-05
epoch [3/25][1100/4762]	time 0.140 (0.151)	data 0.001 (0.001)	eta 4:32:13	loss 0.4479 (0.4090)	loss_x 0.4214 (0.3935)	loss_u 0.0265 (0.0156)	acc_x 84.3750 (86.1790)	lr 4.712526e-05
epoch [3/25][1200/4762]	time 0.149 (0.150)	data 0.001 (0.001)	eta 4:31:32	loss 0.5784 (0.4086)	loss_x 0.5596 (0.3927)	loss_u 0.0189 (0.0159)	acc_x 78.1250 (86.1562)	lr 4.712526e-05
epoch [3/25][1300/4762]	time 0.177 (0.150)	data 0.001 (0.001)	eta 4:31:07	loss 0.3913 (0.4085)	loss_x 0.3890 (0.3927)	loss_u 0.0023 (0.0158)	acc_x 90.6250 (86.1154)	lr 4.712526e-05
epoch [3/25][1400/4762]	time 0.142 (0.150)	data 0.000 (0.001)	eta 4:30:40	loss 0.6119 (0.4077)	loss_x 0.6005 (0.3919)	loss_u 0.0114 (0.0158)	acc_x 84.3750 (86.1473)	lr 4.712526e-05
epoch [3/25][1500/4762]	time 0.153 (0.150)	data 0.001 (0.001)	eta 4:29:59	loss 0.4729 (0.4086)	loss_x 0.4536 (0.3928)	loss_u 0.0193 (0.0157)	acc_x 87.5000 (86.1500)	lr 4.712526e-05
epoch [3/25][1600/4762]	time 0.149 (0.150)	data 0.001 (0.001)	eta 4:29:14	loss 0.1773 (0.4086)	loss_x 0.1647 (0.3930)	loss_u 0.0127 (0.0155)	acc_x 93.7500 (86.1582)	lr 4.712526e-05
epoch [3/25][1700/4762]	time 0.163 (0.149)	data 0.001 (0.001)	eta 4:28:13	loss 0.2766 (0.4089)	loss_x 0.2736 (0.3933)	loss_u 0.0029 (0.0156)	acc_x 87.5000 (86.1324)	lr 4.712526e-05
epoch [3/25][1800/4762]	time 0.152 (0.150)	data 0.001 (0.001)	eta 4:28:28	loss 0.5267 (0.4076)	loss_x 0.5137 (0.3919)	loss_u 0.0131 (0.0156)	acc_x 84.3750 (86.1719)	lr 4.712526e-05
epoch [3/25][1900/4762]	time 0.139 (0.150)	data 0.001 (0.001)	eta 4:28:24	loss 0.3037 (0.4075)	loss_x 0.3021 (0.3920)	loss_u 0.0016 (0.0155)	acc_x 93.7500 (86.1612)	lr 4.712526e-05
epoch [3/25][2000/4762]	time 0.138 (0.150)	data 0.001 (0.001)	eta 4:28:02	loss 0.5398 (0.4073)	loss_x 0.5257 (0.3919)	loss_u 0.0140 (0.0154)	acc_x 90.6250 (86.1719)	lr 4.712526e-05
epoch [3/25][2100/4762]	time 0.151 (0.150)	data 0.001 (0.001)	eta 4:27:43	loss 0.2971 (0.4089)	loss_x 0.2927 (0.3934)	loss_u 0.0045 (0.0154)	acc_x 90.6250 (86.1265)	lr 4.712526e-05
epoch [3/25][2200/4762]	time 0.141 (0.149)	data 0.001 (0.001)	eta 4:27:19	loss 0.7813 (0.4102)	loss_x 0.7794 (0.3948)	loss_u 0.0019 (0.0154)	acc_x 75.0000 (86.0582)	lr 4.712526e-05
epoch [3/25][2300/4762]	time 0.146 (0.149)	data 0.001 (0.001)	eta 4:27:00	loss 0.5303 (0.4105)	loss_x 0.5256 (0.3951)	loss_u 0.0047 (0.0154)	acc_x 81.2500 (86.0435)	lr 4.712526e-05
epoch [3/25][2400/4762]	time 0.147 (0.149)	data 0.001 (0.001)	eta 4:26:48	loss 0.4165 (0.4095)	loss_x 0.4000 (0.3942)	loss_u 0.0165 (0.0153)	acc_x 87.5000 (86.0651)	lr 4.712526e-05
epoch [3/25][2500/4762]	time 0.136 (0.149)	data 0.001 (0.001)	eta 4:26:27	loss 0.2568 (0.4099)	loss_x 0.2501 (0.3947)	loss_u 0.0067 (0.0152)	acc_x 93.7500 (86.0550)	lr 4.712526e-05
epoch [3/25][2600/4762]	time 0.165 (0.149)	data 0.001 (0.001)	eta 4:26:25	loss 0.6299 (0.4096)	loss_x 0.6278 (0.3944)	loss_u 0.0020 (0.0152)	acc_x 75.0000 (86.0541)	lr 4.712526e-05
epoch [3/25][2700/4762]	time 0.207 (0.149)	data 0.001 (0.001)	eta 4:26:08	loss 0.2346 (0.4088)	loss_x 0.2283 (0.3936)	loss_u 0.0062 (0.0152)	acc_x 87.5000 (86.0891)	lr 4.712526e-05
epoch [3/25][2800/4762]	time 0.143 (0.149)	data 0.001 (0.001)	eta 4:25:48	loss 0.4946 (0.4091)	loss_x 0.4489 (0.3941)	loss_u 0.0457 (0.0151)	acc_x 78.1250 (86.0781)	lr 4.712526e-05
epoch [3/25][2900/4762]	time 0.155 (0.149)	data 0.001 (0.001)	eta 4:25:39	loss 0.2459 (0.4079)	loss_x 0.2443 (0.3928)	loss_u 0.0016 (0.0151)	acc_x 90.6250 (86.1293)	lr 4.712526e-05
epoch [3/25][3000/4762]	time 0.143 (0.149)	data 0.001 (0.001)	eta 4:25:19	loss 0.3561 (0.4078)	loss_x 0.3464 (0.3927)	loss_u 0.0097 (0.0151)	acc_x 81.2500 (86.1490)	lr 4.712526e-05
epoch [3/25][3100/4762]	time 0.139 (0.149)	data 0.001 (0.001)	eta 4:25:03	loss 0.3743 (0.4076)	loss_x 0.3687 (0.3926)	loss_u 0.0056 (0.0150)	acc_x 87.5000 (86.1764)	lr 4.712526e-05
epoch [3/25][3200/4762]	time 0.141 (0.149)	data 0.001 (0.001)	eta 4:24:46	loss 0.2108 (0.4069)	loss_x 0.2057 (0.3919)	loss_u 0.0050 (0.0150)	acc_x 90.6250 (86.2051)	lr 4.712526e-05
epoch [3/25][3300/4762]	time 0.183 (0.149)	data 0.001 (0.001)	eta 4:24:38	loss 0.2624 (0.4069)	loss_x 0.2374 (0.3920)	loss_u 0.0250 (0.0149)	acc_x 93.7500 (86.2150)	lr 4.712526e-05
epoch [3/25][3400/4762]	time 0.143 (0.150)	data 0.001 (0.001)	eta 4:24:26	loss 0.2742 (0.4063)	loss_x 0.2654 (0.3914)	loss_u 0.0088 (0.0149)	acc_x 87.5000 (86.2399)	lr 4.712526e-05
epoch [3/25][3500/4762]	time 0.169 (0.150)	data 0.001 (0.001)	eta 4:24:32	loss 0.2492 (0.4059)	loss_x 0.2397 (0.3910)	loss_u 0.0095 (0.0149)	acc_x 90.6250 (86.2482)	lr 4.712526e-05
epoch [3/25][3600/4762]	time 0.159 (0.150)	data 0.001 (0.001)	eta 4:24:10	loss 0.4120 (0.4063)	loss_x 0.4101 (0.3915)	loss_u 0.0019 (0.0148)	acc_x 90.6250 (86.2214)	lr 4.712526e-05
epoch [3/25][3700/4762]	time 0.142 (0.150)	data 0.001 (0.001)	eta 4:24:10	loss 0.4295 (0.4067)	loss_x 0.4267 (0.3918)	loss_u 0.0028 (0.0149)	acc_x 90.6250 (86.2331)	lr 4.712526e-05
epoch [3/25][3800/4762]	time 0.146 (0.150)	data 0.001 (0.001)	eta 4:23:53	loss 0.3134 (0.4062)	loss_x 0.2845 (0.3914)	loss_u 0.0289 (0.0148)	acc_x 90.6250 (86.2549)	lr 4.712526e-05
epoch [3/25][3900/4762]	time 0.190 (0.150)	data 0.001 (0.001)	eta 4:23:46	loss 0.3672 (0.4059)	loss_x 0.3393 (0.3910)	loss_u 0.0279 (0.0149)	acc_x 90.6250 (86.2492)	lr 4.712526e-05
epoch [3/25][4000/4762]	time 0.147 (0.150)	data 0.001 (0.001)	eta 4:23:28	loss 0.2185 (0.4057)	loss_x 0.2084 (0.3908)	loss_u 0.0101 (0.0149)	acc_x 93.7500 (86.2461)	lr 4.712526e-05
epoch [3/25][4100/4762]	time 0.154 (0.150)	data 0.001 (0.001)	eta 4:23:08	loss 0.2306 (0.4057)	loss_x 0.1866 (0.3908)	loss_u 0.0440 (0.0149)	acc_x 93.7500 (86.2416)	lr 4.712526e-05
epoch [3/25][4200/4762]	time 0.140 (0.150)	data 0.001 (0.001)	eta 4:22:51	loss 0.4700 (0.4052)	loss_x 0.4017 (0.3904)	loss_u 0.0683 (0.0149)	acc_x 84.3750 (86.2634)	lr 4.712526e-05
epoch [3/25][4300/4762]	time 0.137 (0.150)	data 0.001 (0.001)	eta 4:22:22	loss 0.3561 (0.4053)	loss_x 0.3499 (0.3904)	loss_u 0.0062 (0.0148)	acc_x 90.6250 (86.2580)	lr 4.712526e-05
epoch [3/25][4400/4762]	time 0.154 (0.150)	data 0.001 (0.001)	eta 4:22:07	loss 0.2047 (0.4048)	loss_x 0.1932 (0.3900)	loss_u 0.0115 (0.0148)	acc_x 93.7500 (86.2607)	lr 4.712526e-05
epoch [3/25][4500/4762]	time 0.183 (0.150)	data 0.001 (0.001)	eta 4:21:49	loss 0.4130 (0.4043)	loss_x 0.3521 (0.3895)	loss_u 0.0609 (0.0148)	acc_x 93.7500 (86.2764)	lr 4.712526e-05
epoch [3/25][4600/4762]	time 0.178 (0.150)	data 0.001 (0.001)	eta 4:21:33	loss 0.3988 (0.4040)	loss_x 0.3776 (0.3892)	loss_u 0.0212 (0.0148)	acc_x 84.3750 (86.2880)	lr 4.712526e-05
epoch [3/25][4700/4762]	time 0.151 (0.150)	data 0.001 (0.001)	eta 4:21:13	loss 0.2546 (0.4033)	loss_x 0.2405 (0.3885)	loss_u 0.0141 (0.0148)	acc_x 87.5000 (86.3132)	lr 4.712526e-05
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,862
* accuracy: 84.61%
* error: 15.39%
* macro_f1: 84.94%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,587	acc: 98.38%
* class: 1 (bicycle)	total: 3,475	correct: 2,889	acc: 83.14%
* class: 2 (bus)	total: 4,690	correct: 4,254	acc: 90.70%
* class: 3 (car)	total: 10,401	correct: 7,654	acc: 73.59%
* class: 4 (horse)	total: 4,691	correct: 4,574	acc: 97.51%
* class: 5 (knife)	total: 2,075	correct: 1,899	acc: 91.52%
* class: 6 (motorcycle)	total: 5,796	correct: 5,513	acc: 95.12%
* class: 7 (person)	total: 4,000	correct: 3,095	acc: 77.38%
* class: 8 (plant)	total: 4,549	correct: 3,949	acc: 86.81%
* class: 9 (skateboard)	total: 2,281	correct: 2,059	acc: 90.27%
* class: 10 (train)	total: 4,236	correct: 3,923	acc: 92.61%
* class: 11 (truck)	total: 5,548	correct: 3,466	acc: 62.47%
* average: 86.62%
epoch [4/25][100/4762]	time 0.139 (0.156)	data 0.001 (0.003)	eta 4:32:43	loss 0.4255 (0.4075)	loss_x 0.4111 (0.3940)	loss_u 0.0144 (0.0136)	acc_x 87.5000 (85.6250)	lr 1.036475e-03
epoch [4/25][200/4762]	time 0.169 (0.155)	data 0.001 (0.002)	eta 4:30:55	loss 0.3651 (0.4224)	loss_x 0.3617 (0.4067)	loss_u 0.0035 (0.0157)	acc_x 87.5000 (85.3906)	lr 1.036475e-03
epoch [4/25][300/4762]	time 0.145 (0.154)	data 0.001 (0.002)	eta 4:28:47	loss 0.3026 (0.4192)	loss_x 0.2934 (0.4035)	loss_u 0.0092 (0.0157)	acc_x 90.6250 (85.8021)	lr 1.036475e-03
epoch [4/25][400/4762]	time 0.146 (0.153)	data 0.001 (0.001)	eta 4:26:00	loss 0.5834 (0.4142)	loss_x 0.5540 (0.3992)	loss_u 0.0295 (0.0150)	acc_x 75.0000 (85.9766)	lr 1.036475e-03
epoch [4/25][500/4762]	time 0.138 (0.152)	data 0.001 (0.001)	eta 4:24:39	loss 0.3038 (0.4137)	loss_x 0.2957 (0.3991)	loss_u 0.0081 (0.0145)	acc_x 96.8750 (85.9562)	lr 1.036475e-03
epoch [4/25][600/4762]	time 0.153 (0.152)	data 0.001 (0.001)	eta 4:24:40	loss 0.6490 (0.4114)	loss_x 0.6347 (0.3966)	loss_u 0.0143 (0.0149)	acc_x 75.0000 (86.0312)	lr 1.036475e-03
epoch [4/25][700/4762]	time 0.182 (0.152)	data 0.001 (0.001)	eta 4:24:28	loss 0.4589 (0.4104)	loss_x 0.4583 (0.3957)	loss_u 0.0006 (0.0148)	acc_x 81.2500 (86.0536)	lr 1.036475e-03
epoch [4/25][800/4762]	time 0.157 (0.153)	data 0.001 (0.001)	eta 4:24:52	loss 0.1869 (0.4076)	loss_x 0.1800 (0.3927)	loss_u 0.0069 (0.0149)	acc_x 96.8750 (86.1328)	lr 1.036475e-03
epoch [4/25][900/4762]	time 0.139 (0.153)	data 0.001 (0.001)	eta 4:24:14	loss 0.4899 (0.4088)	loss_x 0.4537 (0.3939)	loss_u 0.0362 (0.0149)	acc_x 84.3750 (86.0938)	lr 1.036475e-03
epoch [4/25][1000/4762]	time 0.140 (0.152)	data 0.001 (0.001)	eta 4:23:22	loss 0.3814 (0.4077)	loss_x 0.3744 (0.3930)	loss_u 0.0070 (0.0147)	acc_x 90.6250 (86.1125)	lr 1.036475e-03
epoch [4/25][1100/4762]	time 0.144 (0.152)	data 0.001 (0.001)	eta 4:22:16	loss 0.3487 (0.4062)	loss_x 0.3344 (0.3917)	loss_u 0.0143 (0.0144)	acc_x 90.6250 (86.1818)	lr 1.036475e-03
epoch [4/25][1200/4762]	time 0.137 (0.152)	data 0.001 (0.001)	eta 4:21:34	loss 0.2337 (0.4044)	loss_x 0.2324 (0.3900)	loss_u 0.0013 (0.0144)	acc_x 90.6250 (86.2526)	lr 1.036475e-03
epoch [4/25][1300/4762]	time 0.143 (0.151)	data 0.001 (0.001)	eta 4:21:07	loss 0.3472 (0.4053)	loss_x 0.3464 (0.3906)	loss_u 0.0008 (0.0147)	acc_x 87.5000 (86.2260)	lr 1.036475e-03
epoch [4/25][1400/4762]	time 0.137 (0.151)	data 0.001 (0.001)	eta 4:20:39	loss 0.3338 (0.4044)	loss_x 0.3208 (0.3897)	loss_u 0.0130 (0.0148)	acc_x 90.6250 (86.2121)	lr 1.036475e-03
epoch [4/25][1500/4762]	time 0.138 (0.151)	data 0.001 (0.001)	eta 4:20:22	loss 0.3863 (0.4036)	loss_x 0.3817 (0.3890)	loss_u 0.0046 (0.0145)	acc_x 78.1250 (86.2313)	lr 1.036475e-03
epoch [4/25][1600/4762]	time 0.139 (0.151)	data 0.001 (0.001)	eta 4:19:31	loss 0.3448 (0.4021)	loss_x 0.3348 (0.3876)	loss_u 0.0100 (0.0145)	acc_x 90.6250 (86.2734)	lr 1.036475e-03
epoch [4/25][1700/4762]	time 0.162 (0.151)	data 0.001 (0.001)	eta 4:19:08	loss 0.4707 (0.4014)	loss_x 0.4527 (0.3869)	loss_u 0.0179 (0.0145)	acc_x 81.2500 (86.3033)	lr 1.036475e-03
epoch [4/25][1800/4762]	time 0.149 (0.151)	data 0.001 (0.001)	eta 4:19:19	loss 0.2797 (0.4020)	loss_x 0.2691 (0.3876)	loss_u 0.0106 (0.0145)	acc_x 90.6250 (86.2882)	lr 1.036475e-03
epoch [4/25][1900/4762]	time 0.165 (0.151)	data 0.001 (0.001)	eta 4:19:13	loss 0.4538 (0.4009)	loss_x 0.4219 (0.3864)	loss_u 0.0319 (0.0145)	acc_x 84.3750 (86.3569)	lr 1.036475e-03
epoch [4/25][2000/4762]	time 0.141 (0.151)	data 0.001 (0.001)	eta 4:18:27	loss 0.3386 (0.3998)	loss_x 0.3345 (0.3853)	loss_u 0.0041 (0.0145)	acc_x 93.7500 (86.3891)	lr 1.036475e-03
epoch [4/25][2100/4762]	time 0.140 (0.151)	data 0.001 (0.001)	eta 4:18:02	loss 0.3171 (0.3994)	loss_x 0.2908 (0.3850)	loss_u 0.0264 (0.0145)	acc_x 90.6250 (86.3914)	lr 1.036475e-03
epoch [4/25][2200/4762]	time 0.165 (0.151)	data 0.001 (0.001)	eta 4:17:46	loss 0.2493 (0.3994)	loss_x 0.2367 (0.3849)	loss_u 0.0126 (0.0145)	acc_x 90.6250 (86.3878)	lr 1.036475e-03
epoch [4/25][2300/4762]	time 0.137 (0.151)	data 0.001 (0.001)	eta 4:17:27	loss 0.6040 (0.3995)	loss_x 0.5893 (0.3852)	loss_u 0.0147 (0.0144)	acc_x 84.3750 (86.3913)	lr 1.036475e-03
epoch [4/25][2400/4762]	time 0.137 (0.151)	data 0.001 (0.001)	eta 4:17:14	loss 0.4351 (0.3997)	loss_x 0.4329 (0.3854)	loss_u 0.0022 (0.0143)	acc_x 87.5000 (86.3854)	lr 1.036475e-03
epoch [4/25][2500/4762]	time 0.143 (0.151)	data 0.001 (0.001)	eta 4:16:49	loss 0.3521 (0.3987)	loss_x 0.3483 (0.3845)	loss_u 0.0037 (0.0142)	acc_x 87.5000 (86.4213)	lr 1.036475e-03
epoch [4/25][2600/4762]	time 0.138 (0.151)	data 0.001 (0.001)	eta 4:16:33	loss 0.3296 (0.3979)	loss_x 0.3228 (0.3837)	loss_u 0.0067 (0.0142)	acc_x 87.5000 (86.4639)	lr 1.036475e-03
epoch [4/25][2700/4762]	time 0.169 (0.151)	data 0.001 (0.001)	eta 4:16:29	loss 0.6523 (0.3974)	loss_x 0.6314 (0.3831)	loss_u 0.0208 (0.0142)	acc_x 75.0000 (86.4803)	lr 1.036475e-03
epoch [4/25][2800/4762]	time 0.166 (0.151)	data 0.001 (0.001)	eta 4:16:22	loss 0.3224 (0.3973)	loss_x 0.2724 (0.3831)	loss_u 0.0500 (0.0142)	acc_x 93.7500 (86.4699)	lr 1.036475e-03
epoch [4/25][2900/4762]	time 0.148 (0.151)	data 0.001 (0.001)	eta 4:16:02	loss 0.1836 (0.3974)	loss_x 0.1835 (0.3831)	loss_u 0.0001 (0.0142)	acc_x 90.6250 (86.4580)	lr 1.036475e-03
epoch [4/25][3000/4762]	time 0.163 (0.151)	data 0.001 (0.001)	eta 4:15:42	loss 0.3282 (0.3977)	loss_x 0.3198 (0.3834)	loss_u 0.0084 (0.0142)	acc_x 90.6250 (86.4365)	lr 1.036475e-03
epoch [4/25][3100/4762]	time 0.150 (0.151)	data 0.001 (0.001)	eta 4:15:06	loss 0.4308 (0.3975)	loss_x 0.4052 (0.3832)	loss_u 0.0255 (0.0143)	acc_x 87.5000 (86.4446)	lr 1.036475e-03
epoch [4/25][3200/4762]	time 0.146 (0.150)	data 0.001 (0.001)	eta 4:14:39	loss 0.3496 (0.3977)	loss_x 0.3466 (0.3834)	loss_u 0.0031 (0.0143)	acc_x 87.5000 (86.4336)	lr 1.036475e-03
epoch [4/25][3300/4762]	time 0.181 (0.150)	data 0.001 (0.001)	eta 4:14:18	loss 0.3939 (0.3981)	loss_x 0.3793 (0.3837)	loss_u 0.0146 (0.0144)	acc_x 87.5000 (86.4441)	lr 1.036475e-03
epoch [4/25][3400/4762]	time 0.145 (0.150)	data 0.001 (0.001)	eta 4:14:03	loss 0.2750 (0.3980)	loss_x 0.2445 (0.3836)	loss_u 0.0306 (0.0144)	acc_x 93.7500 (86.4577)	lr 1.036475e-03
epoch [4/25][3500/4762]	time 0.150 (0.150)	data 0.001 (0.001)	eta 4:14:00	loss 0.2877 (0.3981)	loss_x 0.2779 (0.3837)	loss_u 0.0098 (0.0144)	acc_x 87.5000 (86.4589)	lr 1.036475e-03
epoch [4/25][3600/4762]	time 0.152 (0.151)	data 0.001 (0.001)	eta 4:13:46	loss 0.3855 (0.3976)	loss_x 0.3777 (0.3832)	loss_u 0.0078 (0.0143)	acc_x 87.5000 (86.4774)	lr 1.036475e-03
epoch [4/25][3700/4762]	time 0.150 (0.151)	data 0.001 (0.001)	eta 4:13:31	loss 0.4350 (0.3974)	loss_x 0.4243 (0.3831)	loss_u 0.0107 (0.0143)	acc_x 81.2500 (86.4924)	lr 1.036475e-03
epoch [4/25][3800/4762]	time 0.136 (0.150)	data 0.001 (0.001)	eta 4:13:14	loss 0.5051 (0.3970)	loss_x 0.4945 (0.3827)	loss_u 0.0105 (0.0143)	acc_x 81.2500 (86.5099)	lr 1.036475e-03
epoch [4/25][3900/4762]	time 0.156 (0.151)	data 0.001 (0.001)	eta 4:13:03	loss 0.4176 (0.3972)	loss_x 0.3919 (0.3829)	loss_u 0.0257 (0.0143)	acc_x 84.3750 (86.4968)	lr 1.036475e-03
epoch [4/25][4000/4762]	time 0.136 (0.150)	data 0.001 (0.001)	eta 4:12:34	loss 0.2104 (0.3968)	loss_x 0.1954 (0.3826)	loss_u 0.0149 (0.0143)	acc_x 90.6250 (86.5234)	lr 1.036475e-03
epoch [4/25][4100/4762]	time 0.148 (0.150)	data 0.001 (0.001)	eta 4:12:21	loss 0.1803 (0.3964)	loss_x 0.1645 (0.3822)	loss_u 0.0158 (0.0142)	acc_x 96.8750 (86.5373)	lr 1.036475e-03
epoch [4/25][4200/4762]	time 0.162 (0.150)	data 0.001 (0.001)	eta 4:12:08	loss 0.2871 (0.3962)	loss_x 0.2860 (0.3819)	loss_u 0.0011 (0.0143)	acc_x 87.5000 (86.5424)	lr 1.036475e-03
epoch [4/25][4300/4762]	time 0.161 (0.150)	data 0.001 (0.001)	eta 4:11:46	loss 0.7086 (0.3951)	loss_x 0.6927 (0.3809)	loss_u 0.0160 (0.0142)	acc_x 75.0000 (86.5712)	lr 1.036475e-03
epoch [4/25][4400/4762]	time 0.151 (0.150)	data 0.001 (0.001)	eta 4:11:29	loss 0.5003 (0.3952)	loss_x 0.4868 (0.3811)	loss_u 0.0135 (0.0142)	acc_x 81.2500 (86.5597)	lr 1.036475e-03
epoch [4/25][4500/4762]	time 0.137 (0.150)	data 0.001 (0.001)	eta 4:11:12	loss 0.3977 (0.3954)	loss_x 0.3426 (0.3812)	loss_u 0.0551 (0.0142)	acc_x 90.6250 (86.5569)	lr 1.036475e-03
epoch [4/25][4600/4762]	time 0.168 (0.150)	data 0.001 (0.001)	eta 4:10:56	loss 0.3147 (0.3951)	loss_x 0.3031 (0.3810)	loss_u 0.0116 (0.0141)	acc_x 90.6250 (86.5571)	lr 1.036475e-03
epoch [4/25][4700/4762]	time 0.141 (0.150)	data 0.001 (0.001)	eta 4:10:43	loss 0.2830 (0.3944)	loss_x 0.2743 (0.3804)	loss_u 0.0086 (0.0141)	acc_x 84.3750 (86.5831)	lr 1.036475e-03
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,907
* accuracy: 84.69%
* error: 15.31%
* macro_f1: 84.85%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,595	acc: 98.60%
* class: 1 (bicycle)	total: 3,475	correct: 2,955	acc: 85.04%
* class: 2 (bus)	total: 4,690	correct: 4,249	acc: 90.60%
* class: 3 (car)	total: 10,401	correct: 7,756	acc: 74.57%
* class: 4 (horse)	total: 4,691	correct: 4,581	acc: 97.66%
* class: 5 (knife)	total: 2,075	correct: 1,891	acc: 91.13%
* class: 6 (motorcycle)	total: 5,796	correct: 5,514	acc: 95.13%
* class: 7 (person)	total: 4,000	correct: 2,931	acc: 73.28%
* class: 8 (plant)	total: 4,549	correct: 3,961	acc: 87.07%
* class: 9 (skateboard)	total: 2,281	correct: 2,044	acc: 89.61%
* class: 10 (train)	total: 4,236	correct: 3,930	acc: 92.78%
* class: 11 (truck)	total: 5,548	correct: 3,500	acc: 63.09%
* average: 86.55%
epoch [5/25][100/4762]	time 0.175 (0.156)	data 0.001 (0.003)	eta 4:19:59	loss 0.1869 (0.3699)	loss_x 0.1754 (0.3569)	loss_u 0.0115 (0.0130)	acc_x 93.7500 (86.9062)	lr 2.894665e-03
epoch [5/25][200/4762]	time 0.152 (0.155)	data 0.001 (0.002)	eta 4:18:21	loss 0.3189 (0.3855)	loss_x 0.2928 (0.3728)	loss_u 0.0260 (0.0127)	acc_x 87.5000 (86.4688)	lr 2.894665e-03
epoch [5/25][300/4762]	time 0.138 (0.153)	data 0.001 (0.001)	eta 4:15:02	loss 0.3665 (0.3882)	loss_x 0.3587 (0.3740)	loss_u 0.0078 (0.0142)	acc_x 90.6250 (86.4479)	lr 2.894665e-03
epoch [5/25][400/4762]	time 0.136 (0.154)	data 0.001 (0.001)	eta 4:14:51	loss 0.4246 (0.3866)	loss_x 0.4163 (0.3729)	loss_u 0.0083 (0.0137)	acc_x 87.5000 (86.5859)	lr 2.894665e-03
epoch [5/25][500/4762]	time 0.167 (0.154)	data 0.001 (0.001)	eta 4:14:53	loss 0.3705 (0.3877)	loss_x 0.3671 (0.3747)	loss_u 0.0034 (0.0130)	acc_x 90.6250 (86.7000)	lr 2.894665e-03
epoch [5/25][600/4762]	time 0.148 (0.154)	data 0.001 (0.001)	eta 4:14:27	loss 0.3326 (0.3912)	loss_x 0.3248 (0.3783)	loss_u 0.0079 (0.0128)	acc_x 90.6250 (86.5833)	lr 2.894665e-03
epoch [5/25][700/4762]	time 0.153 (0.154)	data 0.001 (0.001)	eta 4:14:07	loss 0.3316 (0.3906)	loss_x 0.3248 (0.3776)	loss_u 0.0068 (0.0130)	acc_x 90.6250 (86.6875)	lr 2.894665e-03
epoch [5/25][800/4762]	time 0.143 (0.154)	data 0.001 (0.001)	eta 4:14:23	loss 0.2428 (0.3885)	loss_x 0.2225 (0.3758)	loss_u 0.0204 (0.0126)	acc_x 90.6250 (86.7305)	lr 2.894665e-03
epoch [5/25][900/4762]	time 0.141 (0.154)	data 0.001 (0.001)	eta 4:14:06	loss 0.3337 (0.3887)	loss_x 0.3254 (0.3759)	loss_u 0.0083 (0.0128)	acc_x 87.5000 (86.7708)	lr 2.894665e-03
epoch [5/25][1000/4762]	time 0.160 (0.154)	data 0.001 (0.001)	eta 4:14:00	loss 0.4584 (0.3896)	loss_x 0.4471 (0.3766)	loss_u 0.0113 (0.0129)	acc_x 81.2500 (86.7344)	lr 2.894665e-03
epoch [5/25][1100/4762]	time 0.147 (0.154)	data 0.001 (0.001)	eta 4:13:53	loss 0.3198 (0.3889)	loss_x 0.2972 (0.3759)	loss_u 0.0227 (0.0130)	acc_x 90.6250 (86.7812)	lr 2.894665e-03
epoch [5/25][1200/4762]	time 0.168 (0.154)	data 0.001 (0.001)	eta 4:13:44	loss 0.6577 (0.3903)	loss_x 0.6519 (0.3771)	loss_u 0.0058 (0.0132)	acc_x 81.2500 (86.7083)	lr 2.894665e-03
epoch [5/25][1300/4762]	time 0.140 (0.154)	data 0.001 (0.001)	eta 4:13:14	loss 0.5842 (0.3896)	loss_x 0.5638 (0.3763)	loss_u 0.0204 (0.0132)	acc_x 78.1250 (86.7861)	lr 2.894665e-03
epoch [5/25][1400/4762]	time 0.144 (0.154)	data 0.001 (0.001)	eta 4:13:26	loss 0.2147 (0.3908)	loss_x 0.2073 (0.3776)	loss_u 0.0074 (0.0132)	acc_x 96.8750 (86.7835)	lr 2.894665e-03
epoch [5/25][1500/4762]	time 0.143 (0.154)	data 0.001 (0.001)	eta 4:12:34	loss 0.5653 (0.3926)	loss_x 0.5428 (0.3795)	loss_u 0.0225 (0.0131)	acc_x 84.3750 (86.6958)	lr 2.894665e-03
epoch [5/25][1600/4762]	time 0.149 (0.154)	data 0.001 (0.001)	eta 4:12:12	loss 0.3448 (0.3921)	loss_x 0.2789 (0.3790)	loss_u 0.0659 (0.0131)	acc_x 87.5000 (86.6797)	lr 2.894665e-03
epoch [5/25][1700/4762]	time 0.148 (0.154)	data 0.001 (0.001)	eta 4:11:40	loss 0.4003 (0.3938)	loss_x 0.3786 (0.3808)	loss_u 0.0218 (0.0130)	acc_x 84.3750 (86.6250)	lr 2.894665e-03
epoch [5/25][1800/4762]	time 0.139 (0.154)	data 0.001 (0.001)	eta 4:11:58	loss 0.1810 (0.3938)	loss_x 0.1782 (0.3808)	loss_u 0.0029 (0.0129)	acc_x 90.6250 (86.6024)	lr 2.894665e-03
epoch [5/25][1900/4762]	time 0.176 (0.154)	data 0.001 (0.001)	eta 4:11:30	loss 0.4923 (0.3934)	loss_x 0.4784 (0.3804)	loss_u 0.0139 (0.0130)	acc_x 78.1250 (86.6036)	lr 2.894665e-03
epoch [5/25][2000/4762]	time 0.144 (0.154)	data 0.001 (0.001)	eta 4:11:00	loss 0.3694 (0.3936)	loss_x 0.3512 (0.3806)	loss_u 0.0182 (0.0130)	acc_x 87.5000 (86.5953)	lr 2.894665e-03
epoch [5/25][2100/4762]	time 0.136 (0.154)	data 0.001 (0.001)	eta 4:10:35	loss 0.4880 (0.3937)	loss_x 0.4588 (0.3807)	loss_u 0.0292 (0.0130)	acc_x 84.3750 (86.5670)	lr 2.894665e-03
epoch [5/25][2200/4762]	time 0.138 (0.153)	data 0.001 (0.001)	eta 4:10:00	loss 0.7425 (0.3942)	loss_x 0.7272 (0.3812)	loss_u 0.0153 (0.0130)	acc_x 75.0000 (86.5511)	lr 2.894665e-03
epoch [5/25][2300/4762]	time 0.168 (0.153)	data 0.001 (0.001)	eta 4:09:26	loss 0.2956 (0.3941)	loss_x 0.2922 (0.3811)	loss_u 0.0034 (0.0130)	acc_x 96.8750 (86.5720)	lr 2.894665e-03
epoch [5/25][2400/4762]	time 0.140 (0.153)	data 0.001 (0.001)	eta 4:09:08	loss 0.3882 (0.3947)	loss_x 0.3835 (0.3815)	loss_u 0.0048 (0.0132)	acc_x 87.5000 (86.5794)	lr 2.894665e-03
epoch [5/25][2500/4762]	time 0.140 (0.153)	data 0.001 (0.001)	eta 4:08:41	loss 0.3922 (0.3944)	loss_x 0.3885 (0.3812)	loss_u 0.0037 (0.0133)	acc_x 84.3750 (86.5775)	lr 2.894665e-03
epoch [5/25][2600/4762]	time 0.165 (0.153)	data 0.000 (0.001)	eta 4:08:32	loss 0.4946 (0.3942)	loss_x 0.4869 (0.3810)	loss_u 0.0076 (0.0132)	acc_x 84.3750 (86.5841)	lr 2.894665e-03
epoch [5/25][2700/4762]	time 0.167 (0.153)	data 0.001 (0.001)	eta 4:08:08	loss 0.5814 (0.3933)	loss_x 0.5776 (0.3801)	loss_u 0.0038 (0.0131)	acc_x 81.2500 (86.6111)	lr 2.894665e-03
epoch [5/25][2800/4762]	time 0.149 (0.153)	data 0.001 (0.001)	eta 4:07:59	loss 0.3370 (0.3925)	loss_x 0.3273 (0.3794)	loss_u 0.0097 (0.0131)	acc_x 90.6250 (86.6373)	lr 2.894665e-03
epoch [5/25][2900/4762]	time 0.162 (0.153)	data 0.001 (0.001)	eta 4:07:36	loss 0.2185 (0.3920)	loss_x 0.2124 (0.3789)	loss_u 0.0061 (0.0132)	acc_x 90.6250 (86.6530)	lr 2.894665e-03
epoch [5/25][3000/4762]	time 0.154 (0.153)	data 0.001 (0.001)	eta 4:07:13	loss 0.3585 (0.3915)	loss_x 0.3504 (0.3783)	loss_u 0.0081 (0.0133)	acc_x 84.3750 (86.6500)	lr 2.894665e-03
epoch [5/25][3100/4762]	time 0.153 (0.153)	data 0.001 (0.001)	eta 4:06:47	loss 0.2878 (0.3916)	loss_x 0.2863 (0.3783)	loss_u 0.0016 (0.0133)	acc_x 87.5000 (86.6522)	lr 2.894665e-03
epoch [5/25][3200/4762]	time 0.140 (0.153)	data 0.001 (0.001)	eta 4:06:28	loss 0.5606 (0.3906)	loss_x 0.5386 (0.3773)	loss_u 0.0221 (0.0133)	acc_x 84.3750 (86.6875)	lr 2.894665e-03
epoch [5/25][3300/4762]	time 0.151 (0.153)	data 0.001 (0.001)	eta 4:06:13	loss 0.5958 (0.3902)	loss_x 0.5652 (0.3768)	loss_u 0.0306 (0.0133)	acc_x 78.1250 (86.7045)	lr 2.894665e-03
epoch [5/25][3400/4762]	time 0.158 (0.153)	data 0.001 (0.001)	eta 4:05:53	loss 0.4531 (0.3902)	loss_x 0.4400 (0.3768)	loss_u 0.0131 (0.0134)	acc_x 84.3750 (86.6958)	lr 2.894665e-03
epoch [5/25][3500/4762]	time 0.154 (0.153)	data 0.001 (0.001)	eta 4:05:54	loss 0.2422 (0.3903)	loss_x 0.2289 (0.3769)	loss_u 0.0133 (0.0134)	acc_x 93.7500 (86.6902)	lr 2.894665e-03
epoch [5/25][3600/4762]	time 0.161 (0.153)	data 0.001 (0.001)	eta 4:05:43	loss 0.2577 (0.3904)	loss_x 0.2256 (0.3770)	loss_u 0.0321 (0.0134)	acc_x 93.7500 (86.6753)	lr 2.894665e-03
epoch [5/25][3700/4762]	time 0.161 (0.153)	data 0.001 (0.001)	eta 4:05:34	loss 0.6599 (0.3904)	loss_x 0.6344 (0.3770)	loss_u 0.0255 (0.0134)	acc_x 78.1250 (86.6588)	lr 2.894665e-03
epoch [5/25][3800/4762]	time 0.149 (0.153)	data 0.001 (0.001)	eta 4:05:16	loss 0.5907 (0.3903)	loss_x 0.5832 (0.3769)	loss_u 0.0075 (0.0134)	acc_x 81.2500 (86.6579)	lr 2.894665e-03
epoch [5/25][3900/4762]	time 0.142 (0.153)	data 0.003 (0.001)	eta 4:05:03	loss 0.4301 (0.3905)	loss_x 0.4290 (0.3772)	loss_u 0.0011 (0.0133)	acc_x 84.3750 (86.6514)	lr 2.894665e-03
epoch [5/25][4000/4762]	time 0.155 (0.153)	data 0.001 (0.001)	eta 4:04:46	loss 0.4853 (0.3904)	loss_x 0.4652 (0.3771)	loss_u 0.0200 (0.0133)	acc_x 84.3750 (86.6602)	lr 2.894665e-03
epoch [5/25][4100/4762]	time 0.172 (0.153)	data 0.001 (0.001)	eta 4:04:26	loss 0.3693 (0.3903)	loss_x 0.3543 (0.3770)	loss_u 0.0151 (0.0133)	acc_x 84.3750 (86.6502)	lr 2.894665e-03
epoch [5/25][4200/4762]	time 0.151 (0.153)	data 0.001 (0.001)	eta 4:04:03	loss 0.2840 (0.3902)	loss_x 0.2825 (0.3769)	loss_u 0.0015 (0.0132)	acc_x 93.7500 (86.6555)	lr 2.894665e-03
epoch [5/25][4300/4762]	time 0.156 (0.153)	data 0.001 (0.001)	eta 4:03:50	loss 0.2367 (0.3904)	loss_x 0.2307 (0.3772)	loss_u 0.0059 (0.0132)	acc_x 87.5000 (86.6533)	lr 2.894665e-03
epoch [5/25][4400/4762]	time 0.137 (0.153)	data 0.001 (0.001)	eta 4:03:29	loss 0.5597 (0.3906)	loss_x 0.5583 (0.3774)	loss_u 0.0014 (0.0132)	acc_x 81.2500 (86.6513)	lr 2.894665e-03
epoch [5/25][4500/4762]	time 0.177 (0.153)	data 0.001 (0.001)	eta 4:03:05	loss 0.3093 (0.3908)	loss_x 0.2851 (0.3776)	loss_u 0.0242 (0.0132)	acc_x 93.7500 (86.6569)	lr 2.894665e-03
epoch [5/25][4600/4762]	time 0.139 (0.153)	data 0.001 (0.001)	eta 4:02:53	loss 0.2583 (0.3912)	loss_x 0.2548 (0.3780)	loss_u 0.0034 (0.0132)	acc_x 90.6250 (86.6406)	lr 2.894665e-03
epoch [5/25][4700/4762]	time 0.145 (0.153)	data 0.001 (0.001)	eta 4:02:40	loss 0.5104 (0.3915)	loss_x 0.4974 (0.3782)	loss_u 0.0130 (0.0132)	acc_x 75.0000 (86.6243)	lr 2.894665e-03
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,619
* accuracy: 84.17%
* error: 15.83%
* macro_f1: 84.26%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,578	acc: 98.13%
* class: 1 (bicycle)	total: 3,475	correct: 2,935	acc: 84.46%
* class: 2 (bus)	total: 4,690	correct: 4,278	acc: 91.22%
* class: 3 (car)	total: 10,401	correct: 7,832	acc: 75.30%
* class: 4 (horse)	total: 4,691	correct: 4,590	acc: 97.85%
* class: 5 (knife)	total: 2,075	correct: 1,858	acc: 89.54%
* class: 6 (motorcycle)	total: 5,796	correct: 5,493	acc: 94.77%
* class: 7 (person)	total: 4,000	correct: 2,789	acc: 69.72%
* class: 8 (plant)	total: 4,549	correct: 3,865	acc: 84.96%
* class: 9 (skateboard)	total: 2,281	correct: 2,075	acc: 90.97%
* class: 10 (train)	total: 4,236	correct: 3,915	acc: 92.42%
* class: 11 (truck)	total: 5,548	correct: 3,411	acc: 61.48%
* average: 85.90%
epoch [6/25][100/4762]	time 0.147 (0.155)	data 0.001 (0.003)	eta 4:05:26	loss 0.6436 (0.3920)	loss_x 0.6407 (0.3788)	loss_u 0.0030 (0.0132)	acc_x 78.1250 (86.3125)	lr 2.138669e-03
epoch [6/25][200/4762]	time 0.163 (0.153)	data 0.001 (0.002)	eta 4:02:01	loss 0.1849 (0.3860)	loss_x 0.1767 (0.3728)	loss_u 0.0083 (0.0131)	acc_x 93.7500 (86.5625)	lr 2.138669e-03
epoch [6/25][300/4762]	time 0.142 (0.153)	data 0.001 (0.001)	eta 4:02:04	loss 0.4493 (0.3928)	loss_x 0.4356 (0.3798)	loss_u 0.0137 (0.0129)	acc_x 78.1250 (86.3646)	lr 2.138669e-03
epoch [6/25][400/4762]	time 0.182 (0.154)	data 0.001 (0.001)	eta 4:02:38	loss 0.4433 (0.3889)	loss_x 0.4413 (0.3758)	loss_u 0.0020 (0.0131)	acc_x 81.2500 (86.5391)	lr 2.138669e-03
epoch [6/25][500/4762]	time 0.149 (0.153)	data 0.000 (0.001)	eta 4:01:56	loss 0.2680 (0.3857)	loss_x 0.2658 (0.3728)	loss_u 0.0022 (0.0129)	acc_x 90.6250 (86.7500)	lr 2.138669e-03
epoch [6/25][600/4762]	time 0.142 (0.154)	data 0.001 (0.001)	eta 4:02:43	loss 0.4165 (0.3866)	loss_x 0.4062 (0.3736)	loss_u 0.0103 (0.0130)	acc_x 84.3750 (86.8177)	lr 2.138669e-03
epoch [6/25][700/4762]	time 0.181 (0.154)	data 0.001 (0.001)	eta 4:02:44	loss 0.4358 (0.3843)	loss_x 0.3772 (0.3711)	loss_u 0.0586 (0.0133)	acc_x 84.3750 (86.9241)	lr 2.138669e-03
epoch [6/25][800/4762]	time 0.144 (0.154)	data 0.001 (0.001)	eta 4:02:19	loss 0.5306 (0.3811)	loss_x 0.5199 (0.3680)	loss_u 0.0107 (0.0131)	acc_x 78.1250 (87.0117)	lr 2.138669e-03
epoch [6/25][900/4762]	time 0.194 (0.154)	data 0.001 (0.001)	eta 4:01:53	loss 0.5874 (0.3823)	loss_x 0.5759 (0.3693)	loss_u 0.0115 (0.0130)	acc_x 81.2500 (86.9514)	lr 2.138669e-03
epoch [6/25][1000/4762]	time 0.182 (0.154)	data 0.005 (0.001)	eta 4:01:30	loss 0.2889 (0.3830)	loss_x 0.2856 (0.3702)	loss_u 0.0033 (0.0128)	acc_x 87.5000 (86.9719)	lr 2.138669e-03
epoch [6/25][1100/4762]	time 0.147 (0.154)	data 0.001 (0.001)	eta 4:01:09	loss 0.3795 (0.3829)	loss_x 0.3678 (0.3701)	loss_u 0.0117 (0.0128)	acc_x 84.3750 (86.9858)	lr 2.138669e-03
epoch [6/25][1200/4762]	time 0.182 (0.154)	data 0.001 (0.001)	eta 4:01:03	loss 0.4231 (0.3829)	loss_x 0.4218 (0.3700)	loss_u 0.0013 (0.0130)	acc_x 81.2500 (86.9635)	lr 2.138669e-03
epoch [6/25][1300/4762]	time 0.150 (0.154)	data 0.001 (0.001)	eta 4:01:08	loss 0.2691 (0.3839)	loss_x 0.2664 (0.3707)	loss_u 0.0027 (0.0132)	acc_x 87.5000 (86.9255)	lr 2.138669e-03
epoch [6/25][1400/4762]	time 0.152 (0.154)	data 0.001 (0.001)	eta 4:00:42	loss 0.2486 (0.3841)	loss_x 0.2461 (0.3710)	loss_u 0.0026 (0.0131)	acc_x 90.6250 (86.9018)	lr 2.138669e-03
epoch [6/25][1500/4762]	time 0.146 (0.154)	data 0.001 (0.001)	eta 4:00:07	loss 0.4530 (0.3840)	loss_x 0.4483 (0.3709)	loss_u 0.0047 (0.0130)	acc_x 87.5000 (86.9250)	lr 2.138669e-03
epoch [6/25][1600/4762]	time 0.144 (0.153)	data 0.001 (0.001)	eta 3:59:20	loss 0.5226 (0.3839)	loss_x 0.5135 (0.3709)	loss_u 0.0091 (0.0130)	acc_x 78.1250 (86.9004)	lr 2.138669e-03
epoch [6/25][1700/4762]	time 0.160 (0.153)	data 0.001 (0.001)	eta 3:58:38	loss 0.3511 (0.3844)	loss_x 0.3461 (0.3715)	loss_u 0.0050 (0.0129)	acc_x 81.2500 (86.8842)	lr 2.138669e-03
epoch [6/25][1800/4762]	time 0.161 (0.153)	data 0.001 (0.001)	eta 3:58:36	loss 0.2162 (0.3861)	loss_x 0.1936 (0.3733)	loss_u 0.0226 (0.0128)	acc_x 93.7500 (86.8351)	lr 2.138669e-03
epoch [6/25][1900/4762]	time 0.136 (0.153)	data 0.001 (0.001)	eta 3:58:16	loss 0.4565 (0.3863)	loss_x 0.4459 (0.3736)	loss_u 0.0106 (0.0128)	acc_x 78.1250 (86.8174)	lr 2.138669e-03
epoch [6/25][2000/4762]	time 0.145 (0.153)	data 0.001 (0.001)	eta 3:57:49	loss 0.3042 (0.3848)	loss_x 0.3027 (0.3721)	loss_u 0.0015 (0.0128)	acc_x 90.6250 (86.8688)	lr 2.138669e-03
epoch [6/25][2100/4762]	time 0.144 (0.153)	data 0.001 (0.001)	eta 3:57:21	loss 0.3875 (0.3839)	loss_x 0.3627 (0.3712)	loss_u 0.0248 (0.0127)	acc_x 87.5000 (86.8958)	lr 2.138669e-03
epoch [6/25][2200/4762]	time 0.144 (0.153)	data 0.001 (0.001)	eta 3:56:54	loss 0.2628 (0.3840)	loss_x 0.2512 (0.3713)	loss_u 0.0116 (0.0128)	acc_x 90.6250 (86.9261)	lr 2.138669e-03
epoch [6/25][2300/4762]	time 0.148 (0.153)	data 0.001 (0.001)	eta 3:56:34	loss 0.3099 (0.3844)	loss_x 0.3006 (0.3714)	loss_u 0.0093 (0.0130)	acc_x 93.7500 (86.9185)	lr 2.138669e-03
epoch [6/25][2400/4762]	time 0.149 (0.153)	data 0.001 (0.001)	eta 3:56:07	loss 0.2261 (0.3857)	loss_x 0.2127 (0.3727)	loss_u 0.0134 (0.0130)	acc_x 96.8750 (86.8581)	lr 2.138669e-03
epoch [6/25][2500/4762]	time 0.148 (0.153)	data 0.001 (0.001)	eta 3:55:55	loss 0.4290 (0.3862)	loss_x 0.4199 (0.3732)	loss_u 0.0092 (0.0130)	acc_x 81.2500 (86.7963)	lr 2.138669e-03
epoch [6/25][2600/4762]	time 0.139 (0.153)	data 0.003 (0.001)	eta 3:55:38	loss 0.5384 (0.3868)	loss_x 0.5287 (0.3738)	loss_u 0.0097 (0.0129)	acc_x 84.3750 (86.7728)	lr 2.138669e-03
epoch [6/25][2700/4762]	time 0.144 (0.153)	data 0.001 (0.001)	eta 3:55:22	loss 0.4892 (0.3871)	loss_x 0.4841 (0.3742)	loss_u 0.0051 (0.0129)	acc_x 84.3750 (86.7627)	lr 2.138669e-03
epoch [6/25][2800/4762]	time 0.145 (0.153)	data 0.001 (0.001)	eta 3:55:04	loss 0.4131 (0.3868)	loss_x 0.4040 (0.3739)	loss_u 0.0091 (0.0129)	acc_x 87.5000 (86.7746)	lr 2.138669e-03
epoch [6/25][2900/4762]	time 0.138 (0.153)	data 0.001 (0.001)	eta 3:54:46	loss 0.5375 (0.3863)	loss_x 0.5365 (0.3733)	loss_u 0.0011 (0.0130)	acc_x 78.1250 (86.7996)	lr 2.138669e-03
epoch [6/25][3000/4762]	time 0.139 (0.152)	data 0.001 (0.001)	eta 3:54:20	loss 0.3357 (0.3856)	loss_x 0.3332 (0.3727)	loss_u 0.0025 (0.0130)	acc_x 84.3750 (86.8240)	lr 2.138669e-03
epoch [6/25][3100/4762]	time 0.138 (0.152)	data 0.001 (0.001)	eta 3:54:01	loss 0.3060 (0.3852)	loss_x 0.3032 (0.3723)	loss_u 0.0028 (0.0129)	acc_x 90.6250 (86.8337)	lr 2.138669e-03
epoch [6/25][3200/4762]	time 0.155 (0.152)	data 0.001 (0.001)	eta 3:53:39	loss 0.4397 (0.3854)	loss_x 0.4206 (0.3724)	loss_u 0.0191 (0.0130)	acc_x 87.5000 (86.8379)	lr 2.138669e-03
epoch [6/25][3300/4762]	time 0.141 (0.152)	data 0.001 (0.001)	eta 3:53:18	loss 0.2733 (0.3856)	loss_x 0.2659 (0.3726)	loss_u 0.0074 (0.0130)	acc_x 87.5000 (86.8381)	lr 2.138669e-03
epoch [6/25][3400/4762]	time 0.151 (0.152)	data 0.001 (0.001)	eta 3:52:56	loss 0.4943 (0.3864)	loss_x 0.4795 (0.3735)	loss_u 0.0148 (0.0129)	acc_x 84.3750 (86.8079)	lr 2.138669e-03
epoch [6/25][3500/4762]	time 0.145 (0.152)	data 0.001 (0.001)	eta 3:52:50	loss 0.3726 (0.3866)	loss_x 0.3718 (0.3737)	loss_u 0.0008 (0.0129)	acc_x 84.3750 (86.8054)	lr 2.138669e-03
epoch [6/25][3600/4762]	time 0.138 (0.152)	data 0.001 (0.001)	eta 3:52:39	loss 0.2379 (0.3866)	loss_x 0.2150 (0.3737)	loss_u 0.0229 (0.0129)	acc_x 93.7500 (86.8142)	lr 2.138669e-03
epoch [6/25][3700/4762]	time 0.161 (0.152)	data 0.001 (0.001)	eta 3:52:27	loss 0.1861 (0.3870)	loss_x 0.1718 (0.3741)	loss_u 0.0142 (0.0129)	acc_x 93.7500 (86.8066)	lr 2.138669e-03
epoch [6/25][3800/4762]	time 0.139 (0.152)	data 0.001 (0.001)	eta 3:52:07	loss 0.3028 (0.3867)	loss_x 0.2927 (0.3739)	loss_u 0.0101 (0.0129)	acc_x 93.7500 (86.8306)	lr 2.138669e-03
epoch [6/25][3900/4762]	time 0.158 (0.152)	data 0.001 (0.001)	eta 3:51:43	loss 0.3983 (0.3864)	loss_x 0.3878 (0.3736)	loss_u 0.0105 (0.0129)	acc_x 84.3750 (86.8221)	lr 2.138669e-03
epoch [6/25][4000/4762]	time 0.136 (0.152)	data 0.001 (0.001)	eta 3:51:24	loss 0.5625 (0.3865)	loss_x 0.5481 (0.3736)	loss_u 0.0145 (0.0129)	acc_x 84.3750 (86.8172)	lr 2.138669e-03
epoch [6/25][4100/4762]	time 0.141 (0.152)	data 0.001 (0.001)	eta 3:51:02	loss 0.3066 (0.3863)	loss_x 0.3039 (0.3734)	loss_u 0.0027 (0.0128)	acc_x 87.5000 (86.8232)	lr 2.138669e-03
epoch [6/25][4200/4762]	time 0.143 (0.152)	data 0.001 (0.001)	eta 3:50:46	loss 0.2854 (0.3866)	loss_x 0.2731 (0.3737)	loss_u 0.0123 (0.0128)	acc_x 90.6250 (86.8162)	lr 2.138669e-03
epoch [6/25][4300/4762]	time 0.158 (0.152)	data 0.001 (0.001)	eta 3:50:30	loss 0.4136 (0.3863)	loss_x 0.4092 (0.3735)	loss_u 0.0044 (0.0128)	acc_x 87.5000 (86.8103)	lr 2.138669e-03
epoch [6/25][4400/4762]	time 0.164 (0.152)	data 0.001 (0.001)	eta 3:50:14	loss 0.4662 (0.3869)	loss_x 0.4636 (0.3741)	loss_u 0.0026 (0.0128)	acc_x 78.1250 (86.7862)	lr 2.138669e-03
epoch [6/25][4500/4762]	time 0.166 (0.152)	data 0.001 (0.001)	eta 3:49:56	loss 0.4565 (0.3868)	loss_x 0.4536 (0.3739)	loss_u 0.0029 (0.0128)	acc_x 84.3750 (86.7972)	lr 2.138669e-03
epoch [6/25][4600/4762]	time 0.155 (0.152)	data 0.001 (0.001)	eta 3:49:38	loss 0.3518 (0.3869)	loss_x 0.3495 (0.3741)	loss_u 0.0023 (0.0128)	acc_x 87.5000 (86.7894)	lr 2.138669e-03
epoch [6/25][4700/4762]	time 0.152 (0.152)	data 0.001 (0.001)	eta 3:49:15	loss 0.4270 (0.3871)	loss_x 0.4196 (0.3743)	loss_u 0.0074 (0.0128)	acc_x 84.3750 (86.7799)	lr 2.138669e-03
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,919
* accuracy: 84.71%
* error: 15.29%
* macro_f1: 85.01%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,574	acc: 98.03%
* class: 1 (bicycle)	total: 3,475	correct: 2,944	acc: 84.72%
* class: 2 (bus)	total: 4,690	correct: 4,257	acc: 90.77%
* class: 3 (car)	total: 10,401	correct: 7,807	acc: 75.06%
* class: 4 (horse)	total: 4,691	correct: 4,575	acc: 97.53%
* class: 5 (knife)	total: 2,075	correct: 1,916	acc: 92.34%
* class: 6 (motorcycle)	total: 5,796	correct: 5,509	acc: 95.05%
* class: 7 (person)	total: 4,000	correct: 3,093	acc: 77.33%
* class: 8 (plant)	total: 4,549	correct: 3,819	acc: 83.95%
* class: 9 (skateboard)	total: 2,281	correct: 2,035	acc: 89.22%
* class: 10 (train)	total: 4,236	correct: 3,933	acc: 92.85%
* class: 11 (truck)	total: 5,548	correct: 3,457	acc: 62.31%
* average: 86.59%
epoch [7/25][100/4762]	time 0.154 (0.156)	data 0.001 (0.003)	eta 3:54:28	loss 0.3011 (0.3947)	loss_x 0.2983 (0.3832)	loss_u 0.0029 (0.0115)	acc_x 87.5000 (85.8750)	lr 1.855400e-04
epoch [7/25][200/4762]	time 0.160 (0.155)	data 0.001 (0.002)	eta 3:52:33	loss 0.3732 (0.3846)	loss_x 0.3668 (0.3730)	loss_u 0.0063 (0.0116)	acc_x 87.5000 (86.2500)	lr 1.855400e-04
epoch [7/25][300/4762]	time 0.167 (0.154)	data 0.001 (0.002)	eta 3:51:44	loss 0.3313 (0.3833)	loss_x 0.3280 (0.3717)	loss_u 0.0034 (0.0116)	acc_x 87.5000 (86.4479)	lr 1.855400e-04
epoch [7/25][400/4762]	time 0.170 (0.154)	data 0.001 (0.001)	eta 3:51:01	loss 0.2383 (0.3856)	loss_x 0.2352 (0.3735)	loss_u 0.0031 (0.0121)	acc_x 93.7500 (86.4297)	lr 1.855400e-04
epoch [7/25][500/4762]	time 0.139 (0.153)	data 0.001 (0.001)	eta 3:49:59	loss 0.2570 (0.3842)	loss_x 0.2550 (0.3725)	loss_u 0.0020 (0.0117)	acc_x 90.6250 (86.6250)	lr 1.855400e-04
epoch [7/25][600/4762]	time 0.141 (0.153)	data 0.001 (0.001)	eta 3:49:23	loss 0.3335 (0.3797)	loss_x 0.3327 (0.3682)	loss_u 0.0008 (0.0115)	acc_x 87.5000 (86.8333)	lr 1.855400e-04
epoch [7/25][700/4762]	time 0.137 (0.153)	data 0.001 (0.001)	eta 3:48:52	loss 0.3466 (0.3796)	loss_x 0.3371 (0.3680)	loss_u 0.0095 (0.0116)	acc_x 87.5000 (86.8929)	lr 1.855400e-04
epoch [7/25][800/4762]	time 0.151 (0.153)	data 0.001 (0.001)	eta 3:48:46	loss 0.3760 (0.3803)	loss_x 0.3583 (0.3683)	loss_u 0.0177 (0.0119)	acc_x 84.3750 (86.9180)	lr 1.855400e-04
epoch [7/25][900/4762]	time 0.168 (0.153)	data 0.001 (0.001)	eta 3:48:34	loss 0.4272 (0.3847)	loss_x 0.3608 (0.3724)	loss_u 0.0664 (0.0122)	acc_x 84.3750 (86.8194)	lr 1.855400e-04
epoch [7/25][1000/4762]	time 0.154 (0.153)	data 0.001 (0.001)	eta 3:48:17	loss 0.2600 (0.3863)	loss_x 0.2566 (0.3741)	loss_u 0.0034 (0.0123)	acc_x 90.6250 (86.7687)	lr 1.855400e-04
epoch [7/25][1100/4762]	time 0.151 (0.153)	data 0.001 (0.001)	eta 3:48:06	loss 0.5132 (0.3854)	loss_x 0.4850 (0.3730)	loss_u 0.0283 (0.0124)	acc_x 81.2500 (86.8523)	lr 1.855400e-04
epoch [7/25][1200/4762]	time 0.143 (0.153)	data 0.001 (0.001)	eta 3:47:53	loss 0.4311 (0.3845)	loss_x 0.4217 (0.3722)	loss_u 0.0094 (0.0123)	acc_x 81.2500 (86.8568)	lr 1.855400e-04
epoch [7/25][1300/4762]	time 0.148 (0.153)	data 0.001 (0.001)	eta 3:47:31	loss 0.5988 (0.3848)	loss_x 0.5694 (0.3726)	loss_u 0.0295 (0.0122)	acc_x 78.1250 (86.8534)	lr 1.855400e-04
epoch [7/25][1400/4762]	time 0.154 (0.153)	data 0.001 (0.001)	eta 3:47:39	loss 0.7177 (0.3855)	loss_x 0.7021 (0.3731)	loss_u 0.0156 (0.0123)	acc_x 68.7500 (86.7991)	lr 1.855400e-04
epoch [7/25][1500/4762]	time 0.142 (0.154)	data 0.001 (0.001)	eta 3:47:47	loss 0.2455 (0.3857)	loss_x 0.2357 (0.3733)	loss_u 0.0098 (0.0124)	acc_x 93.7500 (86.8208)	lr 1.855400e-04
epoch [7/25][1600/4762]	time 0.153 (0.154)	data 0.001 (0.001)	eta 3:47:26	loss 0.4727 (0.3861)	loss_x 0.4690 (0.3737)	loss_u 0.0037 (0.0124)	acc_x 81.2500 (86.8477)	lr 1.855400e-04
epoch [7/25][1700/4762]	time 0.136 (0.153)	data 0.001 (0.001)	eta 3:46:58	loss 0.4191 (0.3851)	loss_x 0.4165 (0.3727)	loss_u 0.0025 (0.0124)	acc_x 84.3750 (86.8640)	lr 1.855400e-04
epoch [7/25][1800/4762]	time 0.137 (0.154)	data 0.001 (0.001)	eta 3:47:02	loss 0.2900 (0.3848)	loss_x 0.2810 (0.3726)	loss_u 0.0090 (0.0123)	acc_x 96.8750 (86.8542)	lr 1.855400e-04
epoch [7/25][1900/4762]	time 0.151 (0.153)	data 0.001 (0.001)	eta 3:46:28	loss 0.4972 (0.3858)	loss_x 0.4926 (0.3736)	loss_u 0.0046 (0.0122)	acc_x 81.2500 (86.8405)	lr 1.855400e-04
epoch [7/25][2000/4762]	time 0.157 (0.153)	data 0.001 (0.001)	eta 3:46:09	loss 0.1498 (0.3857)	loss_x 0.1444 (0.3735)	loss_u 0.0053 (0.0122)	acc_x 100.0000 (86.8531)	lr 1.855400e-04
epoch [7/25][2100/4762]	time 0.143 (0.153)	data 0.001 (0.001)	eta 3:45:54	loss 0.3306 (0.3857)	loss_x 0.3145 (0.3735)	loss_u 0.0161 (0.0122)	acc_x 87.5000 (86.8438)	lr 1.855400e-04
epoch [7/25][2200/4762]	time 0.137 (0.153)	data 0.001 (0.001)	eta 3:45:35	loss 0.2581 (0.3855)	loss_x 0.2482 (0.3734)	loss_u 0.0099 (0.0122)	acc_x 90.6250 (86.8580)	lr 1.855400e-04
epoch [7/25][2300/4762]	time 0.138 (0.153)	data 0.001 (0.001)	eta 3:45:12	loss 0.4316 (0.3851)	loss_x 0.4117 (0.3730)	loss_u 0.0200 (0.0121)	acc_x 87.5000 (86.8804)	lr 1.855400e-04
epoch [7/25][2400/4762]	time 0.179 (0.153)	data 0.001 (0.001)	eta 3:44:54	loss 0.2796 (0.3851)	loss_x 0.2652 (0.3731)	loss_u 0.0144 (0.0121)	acc_x 90.6250 (86.8971)	lr 1.855400e-04
epoch [7/25][2500/4762]	time 0.147 (0.153)	data 0.001 (0.001)	eta 3:44:32	loss 0.3825 (0.3856)	loss_x 0.3669 (0.3735)	loss_u 0.0155 (0.0121)	acc_x 87.5000 (86.8538)	lr 1.855400e-04
epoch [7/25][2600/4762]	time 0.154 (0.153)	data 0.001 (0.001)	eta 3:44:16	loss 0.5065 (0.3853)	loss_x 0.4251 (0.3733)	loss_u 0.0814 (0.0120)	acc_x 87.5000 (86.8245)	lr 1.855400e-04
epoch [7/25][2700/4762]	time 0.163 (0.153)	data 0.001 (0.001)	eta 3:44:04	loss 0.4033 (0.3853)	loss_x 0.3920 (0.3732)	loss_u 0.0113 (0.0121)	acc_x 87.5000 (86.8322)	lr 1.855400e-04
epoch [7/25][2800/4762]	time 0.163 (0.153)	data 0.001 (0.001)	eta 3:43:49	loss 0.4703 (0.3852)	loss_x 0.4610 (0.3731)	loss_u 0.0094 (0.0120)	acc_x 78.1250 (86.8493)	lr 1.855400e-04
epoch [7/25][2900/4762]	time 0.146 (0.153)	data 0.001 (0.001)	eta 3:43:28	loss 0.3375 (0.3854)	loss_x 0.3356 (0.3735)	loss_u 0.0020 (0.0120)	acc_x 87.5000 (86.8103)	lr 1.855400e-04
epoch [7/25][3000/4762]	time 0.149 (0.153)	data 0.001 (0.001)	eta 3:43:12	loss 0.1449 (0.3850)	loss_x 0.1414 (0.3730)	loss_u 0.0036 (0.0120)	acc_x 96.8750 (86.8281)	lr 1.855400e-04
epoch [7/25][3100/4762]	time 0.138 (0.153)	data 0.001 (0.001)	eta 3:42:59	loss 0.5701 (0.3840)	loss_x 0.5675 (0.3719)	loss_u 0.0025 (0.0120)	acc_x 78.1250 (86.8478)	lr 1.855400e-04
epoch [7/25][3200/4762]	time 0.152 (0.153)	data 0.001 (0.001)	eta 3:42:34	loss 0.5508 (0.3841)	loss_x 0.5478 (0.3722)	loss_u 0.0030 (0.0119)	acc_x 84.3750 (86.8281)	lr 1.855400e-04
epoch [7/25][3300/4762]	time 0.136 (0.153)	data 0.001 (0.001)	eta 3:42:05	loss 0.3941 (0.3840)	loss_x 0.3927 (0.3721)	loss_u 0.0015 (0.0119)	acc_x 84.3750 (86.8125)	lr 1.855400e-04
epoch [7/25][3400/4762]	time 0.175 (0.153)	data 0.001 (0.001)	eta 3:41:52	loss 0.5527 (0.3838)	loss_x 0.5495 (0.3719)	loss_u 0.0032 (0.0118)	acc_x 81.2500 (86.8235)	lr 1.855400e-04
epoch [7/25][3500/4762]	time 0.162 (0.153)	data 0.001 (0.001)	eta 3:41:49	loss 0.2992 (0.3833)	loss_x 0.2780 (0.3714)	loss_u 0.0212 (0.0119)	acc_x 90.6250 (86.8268)	lr 1.855400e-04
epoch [7/25][3600/4762]	time 0.139 (0.153)	data 0.001 (0.001)	eta 3:41:33	loss 0.2881 (0.3838)	loss_x 0.2782 (0.3719)	loss_u 0.0099 (0.0119)	acc_x 93.7500 (86.8047)	lr 1.855400e-04
epoch [7/25][3700/4762]	time 0.140 (0.153)	data 0.001 (0.001)	eta 3:41:11	loss 0.2099 (0.3838)	loss_x 0.1949 (0.3719)	loss_u 0.0150 (0.0119)	acc_x 90.6250 (86.8167)	lr 1.855400e-04
epoch [7/25][3800/4762]	time 0.139 (0.153)	data 0.001 (0.001)	eta 3:40:50	loss 0.4479 (0.3839)	loss_x 0.3711 (0.3720)	loss_u 0.0768 (0.0119)	acc_x 84.3750 (86.8117)	lr 1.855400e-04
epoch [7/25][3900/4762]	time 0.140 (0.153)	data 0.001 (0.001)	eta 3:40:21	loss 0.2229 (0.3842)	loss_x 0.2199 (0.3722)	loss_u 0.0030 (0.0119)	acc_x 93.7500 (86.7901)	lr 1.855400e-04
epoch [7/25][4000/4762]	time 0.146 (0.153)	data 0.001 (0.001)	eta 3:40:09	loss 0.3665 (0.3846)	loss_x 0.3517 (0.3727)	loss_u 0.0148 (0.0119)	acc_x 84.3750 (86.7695)	lr 1.855400e-04
epoch [7/25][4100/4762]	time 0.136 (0.153)	data 0.001 (0.001)	eta 3:39:47	loss 0.5542 (0.3852)	loss_x 0.5524 (0.3734)	loss_u 0.0018 (0.0119)	acc_x 71.8750 (86.7401)	lr 1.855400e-04
epoch [7/25][4200/4762]	time 0.144 (0.153)	data 0.001 (0.001)	eta 3:39:23	loss 0.2258 (0.3850)	loss_x 0.2029 (0.3731)	loss_u 0.0229 (0.0119)	acc_x 90.6250 (86.7515)	lr 1.855400e-04
epoch [7/25][4300/4762]	time 0.179 (0.153)	data 0.001 (0.001)	eta 3:39:06	loss 0.2234 (0.3849)	loss_x 0.1829 (0.3730)	loss_u 0.0404 (0.0119)	acc_x 90.6250 (86.7624)	lr 1.855400e-04
epoch [7/25][4400/4762]	time 0.136 (0.152)	data 0.000 (0.001)	eta 3:38:40	loss 0.3609 (0.3846)	loss_x 0.3602 (0.3727)	loss_u 0.0007 (0.0118)	acc_x 84.3750 (86.7649)	lr 1.855400e-04
epoch [7/25][4500/4762]	time 0.145 (0.152)	data 0.001 (0.001)	eta 3:38:20	loss 0.5518 (0.3841)	loss_x 0.5443 (0.3723)	loss_u 0.0075 (0.0118)	acc_x 81.2500 (86.7972)	lr 1.855400e-04
epoch [7/25][4600/4762]	time 0.144 (0.152)	data 0.001 (0.001)	eta 3:38:00	loss 0.3120 (0.3843)	loss_x 0.3054 (0.3723)	loss_u 0.0066 (0.0119)	acc_x 90.6250 (86.7976)	lr 1.855400e-04
epoch [7/25][4700/4762]	time 0.140 (0.152)	data 0.001 (0.001)	eta 3:37:38	loss 0.4648 (0.3844)	loss_x 0.4485 (0.3725)	loss_u 0.0163 (0.0119)	acc_x 81.2500 (86.7939)	lr 1.855400e-04
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,836
* accuracy: 84.56%
* error: 15.44%
* macro_f1: 84.90%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,574	acc: 98.03%
* class: 1 (bicycle)	total: 3,475	correct: 2,974	acc: 85.58%
* class: 2 (bus)	total: 4,690	correct: 4,236	acc: 90.32%
* class: 3 (car)	total: 10,401	correct: 7,597	acc: 73.04%
* class: 4 (horse)	total: 4,691	correct: 4,591	acc: 97.87%
* class: 5 (knife)	total: 2,075	correct: 1,858	acc: 89.54%
* class: 6 (motorcycle)	total: 5,796	correct: 5,502	acc: 94.93%
* class: 7 (person)	total: 4,000	correct: 3,156	acc: 78.90%
* class: 8 (plant)	total: 4,549	correct: 3,854	acc: 84.72%
* class: 9 (skateboard)	total: 2,281	correct: 2,047	acc: 89.74%
* class: 10 (train)	total: 4,236	correct: 3,900	acc: 92.07%
* class: 11 (truck)	total: 5,548	correct: 3,547	acc: 63.93%
* average: 86.56%
epoch [8/25][100/4762]	time 0.156 (0.155)	data 0.001 (0.003)	eta 3:40:40	loss 0.5320 (0.3980)	loss_x 0.5232 (0.3849)	loss_u 0.0088 (0.0131)	acc_x 90.6250 (86.0312)	lr 6.962598e-04
epoch [8/25][200/4762]	time 0.154 (0.154)	data 0.001 (0.002)	eta 3:40:07	loss 0.4346 (0.3804)	loss_x 0.4288 (0.3689)	loss_u 0.0058 (0.0115)	acc_x 81.2500 (86.9531)	lr 6.962598e-04
epoch [8/25][300/4762]	time 0.147 (0.154)	data 0.001 (0.002)	eta 3:39:23	loss 0.6886 (0.3765)	loss_x 0.6844 (0.3655)	loss_u 0.0042 (0.0110)	acc_x 75.0000 (87.0000)	lr 6.962598e-04
epoch [8/25][400/4762]	time 0.171 (0.155)	data 0.001 (0.001)	eta 3:39:56	loss 0.2988 (0.3738)	loss_x 0.2948 (0.3630)	loss_u 0.0040 (0.0108)	acc_x 90.6250 (87.1094)	lr 6.962598e-04
epoch [8/25][500/4762]	time 0.140 (0.154)	data 0.001 (0.001)	eta 3:38:48	loss 0.5920 (0.3741)	loss_x 0.5893 (0.3633)	loss_u 0.0027 (0.0108)	acc_x 81.2500 (87.0812)	lr 6.962598e-04
epoch [8/25][600/4762]	time 0.152 (0.154)	data 0.001 (0.001)	eta 3:37:53	loss 0.1483 (0.3757)	loss_x 0.1123 (0.3649)	loss_u 0.0360 (0.0108)	acc_x 100.0000 (87.0156)	lr 6.962598e-04
epoch [8/25][700/4762]	time 0.144 (0.153)	data 0.001 (0.001)	eta 3:37:12	loss 0.3555 (0.3763)	loss_x 0.3474 (0.3654)	loss_u 0.0081 (0.0109)	acc_x 90.6250 (87.0223)	lr 6.962598e-04
epoch [8/25][800/4762]	time 0.141 (0.154)	data 0.001 (0.001)	eta 3:37:46	loss 0.3906 (0.3778)	loss_x 0.3722 (0.3666)	loss_u 0.0184 (0.0112)	acc_x 84.3750 (87.0117)	lr 6.962598e-04
epoch [8/25][900/4762]	time 0.147 (0.154)	data 0.001 (0.001)	eta 3:37:26	loss 0.4379 (0.3784)	loss_x 0.4334 (0.3672)	loss_u 0.0045 (0.0112)	acc_x 84.3750 (87.1319)	lr 6.962598e-04
epoch [8/25][1000/4762]	time 0.151 (0.154)	data 0.001 (0.001)	eta 3:37:22	loss 0.2812 (0.3781)	loss_x 0.2552 (0.3667)	loss_u 0.0260 (0.0114)	acc_x 90.6250 (87.1094)	lr 6.962598e-04
epoch [8/25][1100/4762]	time 0.144 (0.154)	data 0.001 (0.001)	eta 3:36:50	loss 0.4403 (0.3798)	loss_x 0.4189 (0.3685)	loss_u 0.0213 (0.0113)	acc_x 81.2500 (87.0085)	lr 6.962598e-04
epoch [8/25][1200/4762]	time 0.143 (0.153)	data 0.001 (0.001)	eta 3:35:57	loss 0.3895 (0.3797)	loss_x 0.3848 (0.3684)	loss_u 0.0047 (0.0114)	acc_x 81.2500 (86.9818)	lr 6.962598e-04
epoch [8/25][1300/4762]	time 0.144 (0.153)	data 0.001 (0.001)	eta 3:35:33	loss 0.2424 (0.3810)	loss_x 0.2401 (0.3695)	loss_u 0.0023 (0.0115)	acc_x 87.5000 (86.9591)	lr 6.962598e-04
epoch [8/25][1400/4762]	time 0.167 (0.153)	data 0.001 (0.001)	eta 3:35:31	loss 0.3447 (0.3806)	loss_x 0.3229 (0.3692)	loss_u 0.0218 (0.0114)	acc_x 90.6250 (86.9598)	lr 6.962598e-04
epoch [8/25][1500/4762]	time 0.172 (0.154)	data 0.001 (0.001)	eta 3:35:50	loss 0.2914 (0.3805)	loss_x 0.2474 (0.3691)	loss_u 0.0439 (0.0114)	acc_x 93.7500 (86.9813)	lr 6.962598e-04
epoch [8/25][1600/4762]	time 0.157 (0.154)	data 0.001 (0.001)	eta 3:35:54	loss 0.2856 (0.3805)	loss_x 0.2652 (0.3692)	loss_u 0.0204 (0.0114)	acc_x 96.8750 (86.9785)	lr 6.962598e-04
epoch [8/25][1700/4762]	time 0.138 (0.154)	data 0.001 (0.001)	eta 3:35:16	loss 0.4461 (0.3805)	loss_x 0.4304 (0.3691)	loss_u 0.0158 (0.0114)	acc_x 90.6250 (87.0000)	lr 6.962598e-04
epoch [8/25][1800/4762]	time 0.188 (0.154)	data 0.001 (0.001)	eta 3:35:17	loss 0.4590 (0.3810)	loss_x 0.4521 (0.3695)	loss_u 0.0070 (0.0115)	acc_x 90.6250 (86.9844)	lr 6.962598e-04
epoch [8/25][1900/4762]	time 0.159 (0.154)	data 0.001 (0.001)	eta 3:34:57	loss 0.4040 (0.3817)	loss_x 0.4027 (0.3702)	loss_u 0.0013 (0.0116)	acc_x 87.5000 (86.9424)	lr 6.962598e-04
epoch [8/25][2000/4762]	time 0.157 (0.154)	data 0.001 (0.001)	eta 3:34:30	loss 0.5494 (0.3809)	loss_x 0.5393 (0.3693)	loss_u 0.0101 (0.0115)	acc_x 78.1250 (86.9969)	lr 6.962598e-04
epoch [8/25][2100/4762]	time 0.142 (0.154)	data 0.001 (0.001)	eta 3:33:55	loss 0.2604 (0.3810)	loss_x 0.2553 (0.3695)	loss_u 0.0051 (0.0115)	acc_x 90.6250 (87.0179)	lr 6.962598e-04
epoch [8/25][2200/4762]	time 0.139 (0.153)	data 0.001 (0.001)	eta 3:33:35	loss 0.4628 (0.3817)	loss_x 0.4622 (0.3702)	loss_u 0.0005 (0.0115)	acc_x 81.2500 (87.0071)	lr 6.962598e-04
epoch [8/25][2300/4762]	time 0.161 (0.154)	data 0.001 (0.001)	eta 3:33:25	loss 0.4078 (0.3823)	loss_x 0.4049 (0.3708)	loss_u 0.0030 (0.0115)	acc_x 87.5000 (86.9606)	lr 6.962598e-04
epoch [8/25][2400/4762]	time 0.203 (0.154)	data 0.001 (0.001)	eta 3:33:22	loss 0.5792 (0.3820)	loss_x 0.5281 (0.3705)	loss_u 0.0511 (0.0115)	acc_x 71.8750 (86.9740)	lr 6.962598e-04
epoch [8/25][2500/4762]	time 0.168 (0.154)	data 0.001 (0.001)	eta 3:33:10	loss 0.2660 (0.3815)	loss_x 0.2445 (0.3699)	loss_u 0.0215 (0.0116)	acc_x 93.7500 (87.0000)	lr 6.962598e-04
epoch [8/25][2600/4762]	time 0.158 (0.154)	data 0.001 (0.001)	eta 3:32:53	loss 0.2974 (0.3816)	loss_x 0.2927 (0.3700)	loss_u 0.0047 (0.0115)	acc_x 90.6250 (86.9784)	lr 6.962598e-04
epoch [8/25][2700/4762]	time 0.142 (0.153)	data 0.001 (0.001)	eta 3:32:22	loss 0.5293 (0.3818)	loss_x 0.5236 (0.3703)	loss_u 0.0056 (0.0115)	acc_x 81.2500 (86.9734)	lr 6.962598e-04
epoch [8/25][2800/4762]	time 0.148 (0.153)	data 0.001 (0.001)	eta 3:32:07	loss 0.1985 (0.3822)	loss_x 0.1793 (0.3708)	loss_u 0.0192 (0.0115)	acc_x 90.6250 (86.9621)	lr 6.962598e-04
epoch [8/25][2900/4762]	time 0.149 (0.153)	data 0.001 (0.001)	eta 3:31:50	loss 0.1960 (0.3829)	loss_x 0.1920 (0.3714)	loss_u 0.0040 (0.0115)	acc_x 93.7500 (86.9386)	lr 6.962598e-04
epoch [8/25][3000/4762]	time 0.153 (0.153)	data 0.001 (0.001)	eta 3:31:24	loss 0.3805 (0.3823)	loss_x 0.3771 (0.3709)	loss_u 0.0035 (0.0114)	acc_x 84.3750 (86.9542)	lr 6.962598e-04
epoch [8/25][3100/4762]	time 0.170 (0.153)	data 0.001 (0.001)	eta 3:31:07	loss 0.5749 (0.3819)	loss_x 0.5635 (0.3705)	loss_u 0.0113 (0.0114)	acc_x 78.1250 (86.9677)	lr 6.962598e-04
epoch [8/25][3200/4762]	time 0.137 (0.153)	data 0.001 (0.001)	eta 3:30:44	loss 0.5704 (0.3828)	loss_x 0.5691 (0.3714)	loss_u 0.0013 (0.0114)	acc_x 84.3750 (86.9443)	lr 6.962598e-04
epoch [8/25][3300/4762]	time 0.148 (0.153)	data 0.001 (0.001)	eta 3:30:28	loss 0.1590 (0.3822)	loss_x 0.1554 (0.3708)	loss_u 0.0035 (0.0114)	acc_x 93.7500 (86.9640)	lr 6.962598e-04
epoch [8/25][3400/4762]	time 0.149 (0.153)	data 0.001 (0.001)	eta 3:30:12	loss 0.4117 (0.3822)	loss_x 0.4096 (0.3709)	loss_u 0.0021 (0.0113)	acc_x 84.3750 (86.9550)	lr 6.962598e-04
epoch [8/25][3500/4762]	time 0.138 (0.153)	data 0.001 (0.001)	eta 3:30:09	loss 0.2433 (0.3825)	loss_x 0.2360 (0.3712)	loss_u 0.0074 (0.0113)	acc_x 90.6250 (86.9357)	lr 6.962598e-04
epoch [8/25][3600/4762]	time 0.184 (0.153)	data 0.001 (0.001)	eta 3:29:46	loss 0.3136 (0.3818)	loss_x 0.3099 (0.3706)	loss_u 0.0038 (0.0113)	acc_x 96.8750 (86.9696)	lr 6.962598e-04
epoch [8/25][3700/4762]	time 0.137 (0.153)	data 0.001 (0.001)	eta 3:29:23	loss 0.4843 (0.3815)	loss_x 0.4737 (0.3703)	loss_u 0.0106 (0.0113)	acc_x 81.2500 (86.9916)	lr 6.962598e-04
epoch [8/25][3800/4762]	time 0.157 (0.153)	data 0.001 (0.001)	eta 3:29:09	loss 0.2629 (0.3815)	loss_x 0.2512 (0.3702)	loss_u 0.0117 (0.0113)	acc_x 87.5000 (86.9868)	lr 6.962598e-04
epoch [8/25][3900/4762]	time 0.150 (0.153)	data 0.001 (0.001)	eta 3:28:52	loss 0.4443 (0.3817)	loss_x 0.4434 (0.3705)	loss_u 0.0008 (0.0112)	acc_x 84.3750 (86.9808)	lr 6.962598e-04
epoch [8/25][4000/4762]	time 0.152 (0.153)	data 0.001 (0.001)	eta 3:28:33	loss 0.5338 (0.3822)	loss_x 0.5306 (0.3710)	loss_u 0.0032 (0.0112)	acc_x 84.3750 (86.9719)	lr 6.962598e-04
epoch [8/25][4100/4762]	time 0.143 (0.153)	data 0.001 (0.001)	eta 3:28:15	loss 0.5745 (0.3820)	loss_x 0.5655 (0.3708)	loss_u 0.0090 (0.0112)	acc_x 78.1250 (86.9733)	lr 6.962598e-04
epoch [8/25][4200/4762]	time 0.148 (0.153)	data 0.001 (0.001)	eta 3:27:59	loss 0.2753 (0.3822)	loss_x 0.2593 (0.3709)	loss_u 0.0160 (0.0112)	acc_x 90.6250 (86.9643)	lr 6.962598e-04
epoch [8/25][4300/4762]	time 0.139 (0.153)	data 0.001 (0.001)	eta 3:27:42	loss 0.1997 (0.3814)	loss_x 0.1947 (0.3702)	loss_u 0.0050 (0.0112)	acc_x 93.7500 (86.9818)	lr 6.962598e-04
epoch [8/25][4400/4762]	time 0.160 (0.153)	data 0.001 (0.001)	eta 3:27:26	loss 0.2589 (0.3815)	loss_x 0.2318 (0.3704)	loss_u 0.0271 (0.0112)	acc_x 93.7500 (86.9830)	lr 6.962598e-04
epoch [8/25][4500/4762]	time 0.137 (0.153)	data 0.001 (0.001)	eta 3:27:03	loss 0.2235 (0.3816)	loss_x 0.2057 (0.3704)	loss_u 0.0178 (0.0112)	acc_x 90.6250 (86.9875)	lr 6.962598e-04
epoch [8/25][4600/4762]	time 0.152 (0.153)	data 0.001 (0.001)	eta 3:26:44	loss 0.2681 (0.3817)	loss_x 0.2621 (0.3704)	loss_u 0.0060 (0.0112)	acc_x 93.7500 (86.9803)	lr 6.962598e-04
epoch [8/25][4700/4762]	time 0.144 (0.153)	data 0.001 (0.001)	eta 3:26:23	loss 0.6027 (0.3815)	loss_x 0.5941 (0.3703)	loss_u 0.0086 (0.0112)	acc_x 87.5000 (86.9860)	lr 6.962598e-04
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,880
* accuracy: 84.64%
* error: 15.36%
* macro_f1: 84.84%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,589	acc: 98.44%
* class: 1 (bicycle)	total: 3,475	correct: 2,924	acc: 84.14%
* class: 2 (bus)	total: 4,690	correct: 4,260	acc: 90.83%
* class: 3 (car)	total: 10,401	correct: 7,859	acc: 75.56%
* class: 4 (horse)	total: 4,691	correct: 4,579	acc: 97.61%
* class: 5 (knife)	total: 2,075	correct: 1,849	acc: 89.11%
* class: 6 (motorcycle)	total: 5,796	correct: 5,507	acc: 95.01%
* class: 7 (person)	total: 4,000	correct: 3,133	acc: 78.33%
* class: 8 (plant)	total: 4,549	correct: 3,790	acc: 83.32%
* class: 9 (skateboard)	total: 2,281	correct: 2,036	acc: 89.26%
* class: 10 (train)	total: 4,236	correct: 3,935	acc: 92.89%
* class: 11 (truck)	total: 5,548	correct: 3,419	acc: 61.63%
* average: 86.34%
epoch [9/25][100/4762]	time 0.141 (0.155)	data 0.001 (0.004)	eta 3:28:48	loss 0.2533 (0.3845)	loss_x 0.2422 (0.3712)	loss_u 0.0111 (0.0134)	acc_x 93.7500 (86.7188)	lr 2.713525e-03
epoch [9/25][200/4762]	time 0.157 (0.154)	data 0.001 (0.002)	eta 3:26:42	loss 0.3632 (0.3760)	loss_x 0.3432 (0.3638)	loss_u 0.0200 (0.0122)	acc_x 90.6250 (87.2188)	lr 2.713525e-03
epoch [9/25][300/4762]	time 0.157 (0.153)	data 0.001 (0.002)	eta 3:25:43	loss 0.3165 (0.3756)	loss_x 0.3014 (0.3642)	loss_u 0.0151 (0.0113)	acc_x 84.3750 (87.2188)	lr 2.713525e-03
epoch [9/25][400/4762]	time 0.168 (0.153)	data 0.001 (0.002)	eta 3:25:20	loss 0.2205 (0.3758)	loss_x 0.2089 (0.3647)	loss_u 0.0116 (0.0111)	acc_x 93.7500 (87.3438)	lr 2.713525e-03
epoch [9/25][500/4762]	time 0.147 (0.153)	data 0.001 (0.001)	eta 3:25:08	loss 0.4555 (0.3758)	loss_x 0.4514 (0.3650)	loss_u 0.0042 (0.0108)	acc_x 81.2500 (87.2500)	lr 2.713525e-03
epoch [9/25][600/4762]	time 0.143 (0.153)	data 0.001 (0.001)	eta 3:24:36	loss 0.3992 (0.3758)	loss_x 0.3955 (0.3652)	loss_u 0.0037 (0.0106)	acc_x 81.2500 (87.1979)	lr 2.713525e-03
epoch [9/25][700/4762]	time 0.147 (0.153)	data 0.001 (0.001)	eta 3:24:23	loss 0.2700 (0.3750)	loss_x 0.2599 (0.3644)	loss_u 0.0102 (0.0105)	acc_x 96.8750 (87.2723)	lr 2.713525e-03
epoch [9/25][800/4762]	time 0.150 (0.153)	data 0.001 (0.001)	eta 3:24:20	loss 0.5612 (0.3761)	loss_x 0.5605 (0.3653)	loss_u 0.0007 (0.0108)	acc_x 78.1250 (87.1797)	lr 2.713525e-03
epoch [9/25][900/4762]	time 0.193 (0.153)	data 0.001 (0.001)	eta 3:24:32	loss 0.3823 (0.3746)	loss_x 0.3297 (0.3638)	loss_u 0.0526 (0.0108)	acc_x 87.5000 (87.2083)	lr 2.713525e-03
epoch [9/25][1000/4762]	time 0.140 (0.153)	data 0.001 (0.001)	eta 3:24:22	loss 0.5412 (0.3753)	loss_x 0.5355 (0.3645)	loss_u 0.0056 (0.0108)	acc_x 84.3750 (87.2313)	lr 2.713525e-03
epoch [9/25][1100/4762]	time 0.162 (0.153)	data 0.001 (0.001)	eta 3:24:07	loss 0.3914 (0.3760)	loss_x 0.3770 (0.3653)	loss_u 0.0144 (0.0107)	acc_x 87.5000 (87.2188)	lr 2.713525e-03
epoch [9/25][1200/4762]	time 0.156 (0.153)	data 0.001 (0.001)	eta 3:23:57	loss 0.1785 (0.3765)	loss_x 0.1760 (0.3658)	loss_u 0.0025 (0.0107)	acc_x 93.7500 (87.2083)	lr 2.713525e-03
epoch [9/25][1300/4762]	time 0.140 (0.153)	data 0.001 (0.001)	eta 3:23:27	loss 0.3328 (0.3747)	loss_x 0.3160 (0.3638)	loss_u 0.0167 (0.0108)	acc_x 84.3750 (87.2548)	lr 2.713525e-03
epoch [9/25][1400/4762]	time 0.164 (0.153)	data 0.001 (0.001)	eta 3:23:14	loss 0.5484 (0.3732)	loss_x 0.5465 (0.3625)	loss_u 0.0019 (0.0107)	acc_x 84.3750 (87.2969)	lr 2.713525e-03
epoch [9/25][1500/4762]	time 0.174 (0.153)	data 0.001 (0.001)	eta 3:23:14	loss 0.1981 (0.3738)	loss_x 0.1884 (0.3631)	loss_u 0.0096 (0.0107)	acc_x 93.7500 (87.2938)	lr 2.713525e-03
epoch [9/25][1600/4762]	time 0.152 (0.154)	data 0.001 (0.001)	eta 3:23:18	loss 0.4244 (0.3753)	loss_x 0.4111 (0.3645)	loss_u 0.0133 (0.0107)	acc_x 84.3750 (87.2227)	lr 2.713525e-03
epoch [9/25][1700/4762]	time 0.149 (0.154)	data 0.001 (0.001)	eta 3:23:21	loss 0.4804 (0.3744)	loss_x 0.4799 (0.3636)	loss_u 0.0005 (0.0108)	acc_x 87.5000 (87.2794)	lr 2.713525e-03
epoch [9/25][1800/4762]	time 0.156 (0.154)	data 0.001 (0.001)	eta 3:23:42	loss 0.2999 (0.3736)	loss_x 0.2979 (0.3629)	loss_u 0.0020 (0.0107)	acc_x 90.6250 (87.3003)	lr 2.713525e-03
epoch [9/25][1900/4762]	time 0.140 (0.155)	data 0.001 (0.001)	eta 3:23:34	loss 0.5080 (0.3738)	loss_x 0.4930 (0.3631)	loss_u 0.0149 (0.0107)	acc_x 75.0000 (87.2845)	lr 2.713525e-03
epoch [9/25][2000/4762]	time 0.151 (0.155)	data 0.001 (0.001)	eta 3:23:21	loss 0.3838 (0.3753)	loss_x 0.3820 (0.3645)	loss_u 0.0018 (0.0108)	acc_x 84.3750 (87.2500)	lr 2.713525e-03
epoch [9/25][2100/4762]	time 0.147 (0.154)	data 0.001 (0.001)	eta 3:22:51	loss 0.3457 (0.3746)	loss_x 0.3442 (0.3639)	loss_u 0.0016 (0.0107)	acc_x 81.2500 (87.2872)	lr 2.713525e-03
epoch [9/25][2200/4762]	time 0.152 (0.154)	data 0.001 (0.001)	eta 3:22:16	loss 0.3549 (0.3751)	loss_x 0.3490 (0.3643)	loss_u 0.0059 (0.0107)	acc_x 93.7500 (87.2599)	lr 2.713525e-03
epoch [9/25][2300/4762]	time 0.148 (0.154)	data 0.001 (0.001)	eta 3:21:48	loss 0.1642 (0.3759)	loss_x 0.1395 (0.3652)	loss_u 0.0247 (0.0107)	acc_x 96.8750 (87.2269)	lr 2.713525e-03
epoch [9/25][2400/4762]	time 0.159 (0.154)	data 0.001 (0.001)	eta 3:21:24	loss 0.4284 (0.3755)	loss_x 0.4209 (0.3648)	loss_u 0.0076 (0.0107)	acc_x 87.5000 (87.2695)	lr 2.713525e-03
epoch [9/25][2500/4762]	time 0.145 (0.154)	data 0.001 (0.001)	eta 3:20:59	loss 0.4722 (0.3770)	loss_x 0.4644 (0.3662)	loss_u 0.0079 (0.0108)	acc_x 87.5000 (87.1937)	lr 2.713525e-03
epoch [9/25][2600/4762]	time 0.160 (0.154)	data 0.001 (0.001)	eta 3:20:40	loss 0.2611 (0.3766)	loss_x 0.2442 (0.3658)	loss_u 0.0168 (0.0108)	acc_x 90.6250 (87.2284)	lr 2.713525e-03
epoch [9/25][2700/4762]	time 0.152 (0.154)	data 0.001 (0.001)	eta 3:20:17	loss 0.3688 (0.3776)	loss_x 0.3389 (0.3667)	loss_u 0.0299 (0.0109)	acc_x 87.5000 (87.1921)	lr 2.713525e-03
epoch [9/25][2800/4762]	time 0.139 (0.153)	data 0.001 (0.001)	eta 3:19:48	loss 0.3405 (0.3772)	loss_x 0.3339 (0.3664)	loss_u 0.0067 (0.0109)	acc_x 84.3750 (87.1998)	lr 2.713525e-03
epoch [9/25][2900/4762]	time 0.154 (0.153)	data 0.001 (0.001)	eta 3:19:29	loss 0.3224 (0.3769)	loss_x 0.3094 (0.3661)	loss_u 0.0129 (0.0109)	acc_x 87.5000 (87.2101)	lr 2.713525e-03
epoch [9/25][3000/4762]	time 0.189 (0.153)	data 0.001 (0.001)	eta 3:19:10	loss 0.2793 (0.3769)	loss_x 0.2742 (0.3660)	loss_u 0.0052 (0.0109)	acc_x 87.5000 (87.2021)	lr 2.713525e-03
epoch [9/25][3100/4762]	time 0.157 (0.153)	data 0.001 (0.001)	eta 3:18:50	loss 0.3946 (0.3771)	loss_x 0.3898 (0.3662)	loss_u 0.0049 (0.0109)	acc_x 87.5000 (87.1855)	lr 2.713525e-03
epoch [9/25][3200/4762]	time 0.146 (0.153)	data 0.001 (0.001)	eta 3:18:26	loss 0.6825 (0.3775)	loss_x 0.6611 (0.3666)	loss_u 0.0213 (0.0109)	acc_x 84.3750 (87.1729)	lr 2.713525e-03
epoch [9/25][3300/4762]	time 0.153 (0.153)	data 0.001 (0.001)	eta 3:18:09	loss 0.3131 (0.3779)	loss_x 0.3108 (0.3670)	loss_u 0.0023 (0.0110)	acc_x 93.7500 (87.1686)	lr 2.713525e-03
epoch [9/25][3400/4762]	time 0.157 (0.153)	data 0.001 (0.001)	eta 3:17:59	loss 0.2922 (0.3777)	loss_x 0.2894 (0.3668)	loss_u 0.0028 (0.0109)	acc_x 84.3750 (87.1562)	lr 2.713525e-03
epoch [9/25][3500/4762]	time 0.157 (0.153)	data 0.001 (0.001)	eta 3:17:58	loss 0.4489 (0.3783)	loss_x 0.4404 (0.3674)	loss_u 0.0085 (0.0109)	acc_x 81.2500 (87.1321)	lr 2.713525e-03
epoch [9/25][3600/4762]	time 0.149 (0.153)	data 0.001 (0.001)	eta 3:17:44	loss 0.3249 (0.3789)	loss_x 0.3214 (0.3681)	loss_u 0.0036 (0.0108)	acc_x 90.6250 (87.1172)	lr 2.713525e-03
epoch [9/25][3700/4762]	time 0.152 (0.153)	data 0.001 (0.001)	eta 3:17:28	loss 0.5411 (0.3791)	loss_x 0.5388 (0.3683)	loss_u 0.0023 (0.0108)	acc_x 84.3750 (87.0861)	lr 2.713525e-03
epoch [9/25][3800/4762]	time 0.146 (0.153)	data 0.001 (0.001)	eta 3:17:13	loss 0.2175 (0.3795)	loss_x 0.2003 (0.3688)	loss_u 0.0172 (0.0107)	acc_x 96.8750 (87.0551)	lr 2.713525e-03
epoch [9/25][3900/4762]	time 0.153 (0.153)	data 0.001 (0.001)	eta 3:16:54	loss 0.5562 (0.3801)	loss_x 0.5483 (0.3693)	loss_u 0.0079 (0.0107)	acc_x 87.5000 (87.0264)	lr 2.713525e-03
epoch [9/25][4000/4762]	time 0.145 (0.153)	data 0.001 (0.001)	eta 3:16:36	loss 0.3774 (0.3801)	loss_x 0.3703 (0.3694)	loss_u 0.0071 (0.0107)	acc_x 87.5000 (87.0133)	lr 2.713525e-03
epoch [9/25][4100/4762]	time 0.146 (0.153)	data 0.001 (0.001)	eta 3:16:21	loss 0.3622 (0.3801)	loss_x 0.3517 (0.3694)	loss_u 0.0106 (0.0107)	acc_x 84.3750 (87.0091)	lr 2.713525e-03
epoch [9/25][4200/4762]	time 0.140 (0.153)	data 0.001 (0.001)	eta 3:16:07	loss 0.3569 (0.3805)	loss_x 0.3301 (0.3698)	loss_u 0.0268 (0.0107)	acc_x 90.6250 (86.9903)	lr 2.713525e-03
epoch [9/25][4300/4762]	time 0.141 (0.153)	data 0.001 (0.001)	eta 3:15:42	loss 0.3721 (0.3799)	loss_x 0.3696 (0.3693)	loss_u 0.0025 (0.0106)	acc_x 84.3750 (87.0196)	lr 2.713525e-03
epoch [9/25][4400/4762]	time 0.157 (0.153)	data 0.001 (0.001)	eta 3:15:21	loss 0.3998 (0.3797)	loss_x 0.3886 (0.3690)	loss_u 0.0112 (0.0107)	acc_x 84.3750 (87.0284)	lr 2.713525e-03
epoch [9/25][4500/4762]	time 0.153 (0.153)	data 0.001 (0.001)	eta 3:15:03	loss 0.3868 (0.3803)	loss_x 0.3846 (0.3696)	loss_u 0.0022 (0.0107)	acc_x 84.3750 (87.0090)	lr 2.713525e-03
epoch [9/25][4600/4762]	time 0.150 (0.153)	data 0.001 (0.001)	eta 3:14:45	loss 0.4442 (0.3803)	loss_x 0.4339 (0.3696)	loss_u 0.0103 (0.0107)	acc_x 84.3750 (87.0095)	lr 2.713525e-03
epoch [9/25][4700/4762]	time 0.152 (0.153)	data 0.001 (0.001)	eta 3:14:27	loss 0.2324 (0.3797)	loss_x 0.2083 (0.3690)	loss_u 0.0240 (0.0107)	acc_x 90.6250 (87.0339)	lr 2.713525e-03
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,750
* accuracy: 84.40%
* error: 15.60%
* macro_f1: 84.67%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,575	acc: 98.05%
* class: 1 (bicycle)	total: 3,475	correct: 2,907	acc: 83.65%
* class: 2 (bus)	total: 4,690	correct: 4,271	acc: 91.07%
* class: 3 (car)	total: 10,401	correct: 7,681	acc: 73.85%
* class: 4 (horse)	total: 4,691	correct: 4,586	acc: 97.76%
* class: 5 (knife)	total: 2,075	correct: 1,901	acc: 91.61%
* class: 6 (motorcycle)	total: 5,796	correct: 5,529	acc: 95.39%
* class: 7 (person)	total: 4,000	correct: 3,092	acc: 77.30%
* class: 8 (plant)	total: 4,549	correct: 3,883	acc: 85.36%
* class: 9 (skateboard)	total: 2,281	correct: 2,031	acc: 89.04%
* class: 10 (train)	total: 4,236	correct: 3,922	acc: 92.59%
* class: 11 (truck)	total: 5,548	correct: 3,372	acc: 60.78%
* average: 86.37%
epoch [10/25][100/4762]	time 0.138 (0.156)	data 0.001 (0.004)	eta 3:17:44	loss 0.6911 (0.3956)	loss_x 0.6866 (0.3845)	loss_u 0.0045 (0.0111)	acc_x 71.8750 (85.9375)	lr 2.456136e-03
epoch [10/25][200/4762]	time 0.144 (0.154)	data 0.001 (0.002)	eta 3:14:34	loss 0.4096 (0.3940)	loss_x 0.4075 (0.3825)	loss_u 0.0022 (0.0116)	acc_x 84.3750 (86.2969)	lr 2.456136e-03
epoch [10/25][300/4762]	time 0.178 (0.153)	data 0.001 (0.002)	eta 3:13:24	loss 0.3456 (0.3828)	loss_x 0.3375 (0.3711)	loss_u 0.0081 (0.0117)	acc_x 90.6250 (86.8229)	lr 2.456136e-03
epoch [10/25][400/4762]	time 0.148 (0.153)	data 0.001 (0.002)	eta 3:12:53	loss 0.3492 (0.3824)	loss_x 0.3251 (0.3713)	loss_u 0.0240 (0.0111)	acc_x 90.6250 (86.9922)	lr 2.456136e-03
epoch [10/25][500/4762]	time 0.165 (0.153)	data 0.001 (0.001)	eta 3:12:25	loss 0.3312 (0.3812)	loss_x 0.3167 (0.3699)	loss_u 0.0146 (0.0113)	acc_x 90.6250 (87.1000)	lr 2.456136e-03
epoch [10/25][600/4762]	time 0.139 (0.152)	data 0.001 (0.001)	eta 3:11:57	loss 0.4937 (0.3803)	loss_x 0.4806 (0.3685)	loss_u 0.0131 (0.0117)	acc_x 81.2500 (87.0573)	lr 2.456136e-03
epoch [10/25][700/4762]	time 0.164 (0.153)	data 0.001 (0.001)	eta 3:11:52	loss 0.3850 (0.3802)	loss_x 0.3770 (0.3687)	loss_u 0.0080 (0.0115)	acc_x 90.6250 (87.1518)	lr 2.456136e-03
epoch [10/25][800/4762]	time 0.138 (0.152)	data 0.001 (0.001)	eta 3:11:18	loss 0.2863 (0.3808)	loss_x 0.2838 (0.3692)	loss_u 0.0025 (0.0116)	acc_x 93.7500 (87.1133)	lr 2.456136e-03
epoch [10/25][900/4762]	time 0.140 (0.152)	data 0.001 (0.001)	eta 3:10:57	loss 0.5540 (0.3806)	loss_x 0.5478 (0.3693)	loss_u 0.0062 (0.0114)	acc_x 78.1250 (87.0347)	lr 2.456136e-03
epoch [10/25][1000/4762]	time 0.159 (0.152)	data 0.001 (0.001)	eta 3:10:58	loss 0.3803 (0.3789)	loss_x 0.3786 (0.3676)	loss_u 0.0018 (0.0112)	acc_x 84.3750 (87.0687)	lr 2.456136e-03
epoch [10/25][1100/4762]	time 0.152 (0.153)	data 0.001 (0.001)	eta 3:10:54	loss 0.2665 (0.3784)	loss_x 0.2577 (0.3674)	loss_u 0.0088 (0.0110)	acc_x 90.6250 (87.0341)	lr 2.456136e-03
epoch [10/25][1200/4762]	time 0.173 (0.153)	data 0.002 (0.001)	eta 3:10:49	loss 0.3196 (0.3788)	loss_x 0.3180 (0.3680)	loss_u 0.0016 (0.0108)	acc_x 87.5000 (86.9766)	lr 2.456136e-03
epoch [10/25][1300/4762]	time 0.177 (0.153)	data 0.001 (0.001)	eta 3:10:30	loss 0.4469 (0.3806)	loss_x 0.4409 (0.3695)	loss_u 0.0060 (0.0111)	acc_x 84.3750 (86.9111)	lr 2.456136e-03
epoch [10/25][1400/4762]	time 0.156 (0.153)	data 0.001 (0.001)	eta 3:10:08	loss 0.2107 (0.3793)	loss_x 0.2065 (0.3680)	loss_u 0.0042 (0.0113)	acc_x 96.8750 (86.9955)	lr 2.456136e-03
epoch [10/25][1500/4762]	time 0.169 (0.153)	data 0.016 (0.001)	eta 3:09:53	loss 0.4380 (0.3796)	loss_x 0.4291 (0.3683)	loss_u 0.0089 (0.0114)	acc_x 84.3750 (86.9792)	lr 2.456136e-03
epoch [10/25][1600/4762]	time 0.155 (0.153)	data 0.001 (0.001)	eta 3:09:48	loss 0.3304 (0.3793)	loss_x 0.3091 (0.3679)	loss_u 0.0213 (0.0114)	acc_x 90.6250 (86.9766)	lr 2.456136e-03
epoch [10/25][1700/4762]	time 0.140 (0.153)	data 0.001 (0.001)	eta 3:09:48	loss 0.3104 (0.3805)	loss_x 0.3050 (0.3692)	loss_u 0.0054 (0.0113)	acc_x 87.5000 (86.9375)	lr 2.456136e-03
epoch [10/25][1800/4762]	time 0.167 (0.153)	data 0.001 (0.001)	eta 3:10:07	loss 0.2766 (0.3805)	loss_x 0.2743 (0.3692)	loss_u 0.0022 (0.0113)	acc_x 81.2500 (86.9531)	lr 2.456136e-03
epoch [10/25][1900/4762]	time 0.138 (0.153)	data 0.001 (0.001)	eta 3:09:54	loss 0.4524 (0.3809)	loss_x 0.4462 (0.3697)	loss_u 0.0063 (0.0112)	acc_x 84.3750 (86.9260)	lr 2.456136e-03
epoch [10/25][2000/4762]	time 0.151 (0.153)	data 0.001 (0.001)	eta 3:09:38	loss 0.4203 (0.3807)	loss_x 0.3431 (0.3695)	loss_u 0.0772 (0.0112)	acc_x 90.6250 (86.9266)	lr 2.456136e-03
epoch [10/25][2100/4762]	time 0.140 (0.153)	data 0.001 (0.001)	eta 3:09:30	loss 0.4143 (0.3800)	loss_x 0.4043 (0.3688)	loss_u 0.0100 (0.0112)	acc_x 78.1250 (86.9464)	lr 2.456136e-03
epoch [10/25][2200/4762]	time 0.140 (0.153)	data 0.001 (0.001)	eta 3:09:15	loss 0.3725 (0.3803)	loss_x 0.3682 (0.3691)	loss_u 0.0043 (0.0112)	acc_x 93.7500 (86.9545)	lr 2.456136e-03
epoch [10/25][2300/4762]	time 0.153 (0.153)	data 0.001 (0.001)	eta 3:08:57	loss 0.4156 (0.3806)	loss_x 0.3908 (0.3694)	loss_u 0.0248 (0.0113)	acc_x 87.5000 (86.9606)	lr 2.456136e-03
epoch [10/25][2400/4762]	time 0.194 (0.153)	data 0.001 (0.001)	eta 3:08:25	loss 0.3384 (0.3806)	loss_x 0.3241 (0.3694)	loss_u 0.0143 (0.0113)	acc_x 84.3750 (86.9753)	lr 2.456136e-03
epoch [10/25][2500/4762]	time 0.152 (0.153)	data 0.001 (0.001)	eta 3:08:09	loss 0.3230 (0.3805)	loss_x 0.3192 (0.3692)	loss_u 0.0038 (0.0113)	acc_x 87.5000 (86.9613)	lr 2.456136e-03
epoch [10/25][2600/4762]	time 0.153 (0.153)	data 0.001 (0.001)	eta 3:07:45	loss 0.2547 (0.3803)	loss_x 0.2433 (0.3690)	loss_u 0.0114 (0.0112)	acc_x 93.7500 (86.9832)	lr 2.456136e-03
epoch [10/25][2700/4762]	time 0.160 (0.153)	data 0.001 (0.001)	eta 3:07:20	loss 0.4457 (0.3814)	loss_x 0.4355 (0.3700)	loss_u 0.0102 (0.0114)	acc_x 87.5000 (86.9352)	lr 2.456136e-03
epoch [10/25][2800/4762]	time 0.140 (0.153)	data 0.001 (0.001)	eta 3:07:04	loss 0.3325 (0.3805)	loss_x 0.3255 (0.3692)	loss_u 0.0070 (0.0113)	acc_x 84.3750 (86.9531)	lr 2.456136e-03
epoch [10/25][2900/4762]	time 0.148 (0.153)	data 0.003 (0.001)	eta 3:06:47	loss 0.1978 (0.3802)	loss_x 0.1889 (0.3689)	loss_u 0.0089 (0.0113)	acc_x 93.7500 (86.9547)	lr 2.456136e-03
epoch [10/25][3000/4762]	time 0.145 (0.153)	data 0.001 (0.001)	eta 3:06:31	loss 0.3056 (0.3801)	loss_x 0.2928 (0.3689)	loss_u 0.0128 (0.0112)	acc_x 90.6250 (86.9583)	lr 2.456136e-03
epoch [10/25][3100/4762]	time 0.158 (0.153)	data 0.001 (0.001)	eta 3:06:11	loss 0.2444 (0.3799)	loss_x 0.2280 (0.3687)	loss_u 0.0164 (0.0112)	acc_x 93.7500 (86.9819)	lr 2.456136e-03
epoch [10/25][3200/4762]	time 0.166 (0.153)	data 0.001 (0.001)	eta 3:05:50	loss 0.1615 (0.3806)	loss_x 0.1599 (0.3693)	loss_u 0.0016 (0.0112)	acc_x 96.8750 (86.9541)	lr 2.456136e-03
epoch [10/25][3300/4762]	time 0.150 (0.153)	data 0.001 (0.001)	eta 3:05:34	loss 0.2173 (0.3806)	loss_x 0.2054 (0.3694)	loss_u 0.0120 (0.0112)	acc_x 96.8750 (86.9536)	lr 2.456136e-03
epoch [10/25][3400/4762]	time 0.166 (0.153)	data 0.001 (0.001)	eta 3:05:18	loss 0.3543 (0.3809)	loss_x 0.3492 (0.3697)	loss_u 0.0051 (0.0112)	acc_x 90.6250 (86.9476)	lr 2.456136e-03
epoch [10/25][3500/4762]	time 0.186 (0.153)	data 0.001 (0.001)	eta 3:05:12	loss 0.3644 (0.3811)	loss_x 0.3567 (0.3698)	loss_u 0.0078 (0.0112)	acc_x 78.1250 (86.9366)	lr 2.456136e-03
epoch [10/25][3600/4762]	time 0.167 (0.153)	data 0.001 (0.001)	eta 3:04:51	loss 0.4784 (0.3814)	loss_x 0.4708 (0.3702)	loss_u 0.0076 (0.0112)	acc_x 84.3750 (86.9141)	lr 2.456136e-03
epoch [10/25][3700/4762]	time 0.138 (0.153)	data 0.001 (0.001)	eta 3:04:42	loss 0.4040 (0.3808)	loss_x 0.3920 (0.3696)	loss_u 0.0120 (0.0112)	acc_x 84.3750 (86.9400)	lr 2.456136e-03
epoch [10/25][3800/4762]	time 0.144 (0.153)	data 0.001 (0.001)	eta 3:04:22	loss 0.4520 (0.3807)	loss_x 0.4447 (0.3696)	loss_u 0.0073 (0.0112)	acc_x 81.2500 (86.9276)	lr 2.456136e-03
epoch [10/25][3900/4762]	time 0.149 (0.153)	data 0.001 (0.001)	eta 3:04:04	loss 0.4280 (0.3806)	loss_x 0.4073 (0.3695)	loss_u 0.0207 (0.0112)	acc_x 87.5000 (86.9311)	lr 2.456136e-03
epoch [10/25][4000/4762]	time 0.167 (0.153)	data 0.001 (0.001)	eta 3:03:43	loss 0.5558 (0.3806)	loss_x 0.5546 (0.3695)	loss_u 0.0012 (0.0111)	acc_x 87.5000 (86.9352)	lr 2.456136e-03
epoch [10/25][4100/4762]	time 0.148 (0.153)	data 0.001 (0.001)	eta 3:03:26	loss 0.2541 (0.3805)	loss_x 0.2450 (0.3694)	loss_u 0.0091 (0.0111)	acc_x 93.7500 (86.9413)	lr 2.456136e-03
epoch [10/25][4200/4762]	time 0.171 (0.153)	data 0.001 (0.001)	eta 3:03:12	loss 0.4578 (0.3802)	loss_x 0.4560 (0.3691)	loss_u 0.0018 (0.0111)	acc_x 87.5000 (86.9539)	lr 2.456136e-03
epoch [10/25][4300/4762]	time 0.164 (0.153)	data 0.001 (0.001)	eta 3:02:57	loss 0.5703 (0.3802)	loss_x 0.5683 (0.3690)	loss_u 0.0020 (0.0111)	acc_x 84.3750 (86.9440)	lr 2.456136e-03
epoch [10/25][4400/4762]	time 0.179 (0.153)	data 0.001 (0.001)	eta 3:02:44	loss 0.3383 (0.3802)	loss_x 0.3296 (0.3690)	loss_u 0.0087 (0.0112)	acc_x 87.5000 (86.9467)	lr 2.456136e-03
epoch [10/25][4500/4762]	time 0.144 (0.153)	data 0.001 (0.001)	eta 3:02:31	loss 0.2963 (0.3801)	loss_x 0.2871 (0.3689)	loss_u 0.0093 (0.0112)	acc_x 90.6250 (86.9597)	lr 2.456136e-03
epoch [10/25][4600/4762]	time 0.141 (0.153)	data 0.001 (0.001)	eta 3:02:14	loss 0.4709 (0.3791)	loss_x 0.4589 (0.3679)	loss_u 0.0120 (0.0112)	acc_x 81.2500 (86.9891)	lr 2.456136e-03
epoch [10/25][4700/4762]	time 0.166 (0.153)	data 0.001 (0.001)	eta 3:02:01	loss 0.4247 (0.3793)	loss_x 0.3924 (0.3681)	loss_u 0.0323 (0.0112)	acc_x 87.5000 (86.9767)	lr 2.456136e-03
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,944
* accuracy: 84.75%
* error: 15.25%
* macro_f1: 84.91%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,573	acc: 98.00%
* class: 1 (bicycle)	total: 3,475	correct: 2,890	acc: 83.17%
* class: 2 (bus)	total: 4,690	correct: 4,196	acc: 89.47%
* class: 3 (car)	total: 10,401	correct: 7,943	acc: 76.37%
* class: 4 (horse)	total: 4,691	correct: 4,589	acc: 97.83%
* class: 5 (knife)	total: 2,075	correct: 1,861	acc: 89.69%
* class: 6 (motorcycle)	total: 5,796	correct: 5,531	acc: 95.43%
* class: 7 (person)	total: 4,000	correct: 3,002	acc: 75.05%
* class: 8 (plant)	total: 4,549	correct: 3,898	acc: 85.69%
* class: 9 (skateboard)	total: 2,281	correct: 2,074	acc: 90.93%
* class: 10 (train)	total: 4,236	correct: 3,956	acc: 93.39%
* class: 11 (truck)	total: 5,548	correct: 3,431	acc: 61.84%
* average: 86.40%
epoch [11/25][100/4762]	time 0.159 (0.153)	data 0.001 (0.003)	eta 3:01:20	loss 0.4721 (0.3577)	loss_x 0.4359 (0.3423)	loss_u 0.0362 (0.0154)	acc_x 90.6250 (88.2500)	lr 4.065471e-04
epoch [11/25][200/4762]	time 0.137 (0.151)	data 0.001 (0.002)	eta 2:59:09	loss 0.2121 (0.3685)	loss_x 0.2055 (0.3553)	loss_u 0.0066 (0.0132)	acc_x 87.5000 (87.4375)	lr 4.065471e-04
epoch [11/25][300/4762]	time 0.175 (0.151)	data 0.003 (0.002)	eta 2:59:06	loss 0.3049 (0.3693)	loss_x 0.3002 (0.3568)	loss_u 0.0047 (0.0125)	acc_x 90.6250 (87.4271)	lr 4.065471e-04
epoch [11/25][400/4762]	time 0.152 (0.151)	data 0.001 (0.001)	eta 2:59:09	loss 0.3848 (0.3662)	loss_x 0.3727 (0.3541)	loss_u 0.0121 (0.0122)	acc_x 84.3750 (87.6406)	lr 4.065471e-04
epoch [11/25][500/4762]	time 0.139 (0.152)	data 0.001 (0.001)	eta 2:59:53	loss 0.6027 (0.3698)	loss_x 0.5940 (0.3579)	loss_u 0.0087 (0.0119)	acc_x 84.3750 (87.4250)	lr 4.065471e-04
epoch [11/25][600/4762]	time 0.159 (0.153)	data 0.001 (0.001)	eta 3:00:09	loss 0.3996 (0.3716)	loss_x 0.3917 (0.3601)	loss_u 0.0079 (0.0115)	acc_x 90.6250 (87.3438)	lr 4.065471e-04
epoch [11/25][700/4762]	time 0.145 (0.152)	data 0.001 (0.001)	eta 2:59:27	loss 0.5209 (0.3726)	loss_x 0.5118 (0.3610)	loss_u 0.0091 (0.0116)	acc_x 84.3750 (87.3661)	lr 4.065471e-04
epoch [11/25][800/4762]	time 0.142 (0.152)	data 0.001 (0.001)	eta 2:58:54	loss 0.3085 (0.3727)	loss_x 0.3062 (0.3613)	loss_u 0.0024 (0.0114)	acc_x 87.5000 (87.3594)	lr 4.065471e-04
epoch [11/25][900/4762]	time 0.202 (0.152)	data 0.001 (0.001)	eta 2:58:22	loss 0.4866 (0.3740)	loss_x 0.4806 (0.3627)	loss_u 0.0059 (0.0113)	acc_x 87.5000 (87.3194)	lr 4.065471e-04
epoch [11/25][1000/4762]	time 0.138 (0.152)	data 0.001 (0.001)	eta 2:58:21	loss 0.5662 (0.3762)	loss_x 0.5649 (0.3649)	loss_u 0.0013 (0.0113)	acc_x 81.2500 (87.2500)	lr 4.065471e-04
epoch [11/25][1100/4762]	time 0.137 (0.152)	data 0.001 (0.001)	eta 2:58:25	loss 0.6221 (0.3753)	loss_x 0.6141 (0.3639)	loss_u 0.0080 (0.0114)	acc_x 75.0000 (87.2443)	lr 4.065471e-04
epoch [11/25][1200/4762]	time 0.143 (0.153)	data 0.001 (0.001)	eta 2:58:34	loss 0.3159 (0.3761)	loss_x 0.3076 (0.3650)	loss_u 0.0083 (0.0111)	acc_x 87.5000 (87.2240)	lr 4.065471e-04
epoch [11/25][1300/4762]	time 0.155 (0.153)	data 0.001 (0.001)	eta 2:58:22	loss 0.2432 (0.3755)	loss_x 0.2276 (0.3643)	loss_u 0.0157 (0.0113)	acc_x 90.6250 (87.1947)	lr 4.065471e-04
epoch [11/25][1400/4762]	time 0.148 (0.153)	data 0.001 (0.001)	eta 2:58:17	loss 0.4514 (0.3750)	loss_x 0.4440 (0.3637)	loss_u 0.0074 (0.0113)	acc_x 84.3750 (87.2299)	lr 4.065471e-04
epoch [11/25][1500/4762]	time 0.138 (0.153)	data 0.001 (0.001)	eta 2:58:12	loss 0.3561 (0.3760)	loss_x 0.3548 (0.3649)	loss_u 0.0013 (0.0112)	acc_x 84.3750 (87.1646)	lr 4.065471e-04
epoch [11/25][1600/4762]	time 0.150 (0.153)	data 0.001 (0.001)	eta 2:58:07	loss 0.2142 (0.3757)	loss_x 0.2067 (0.3646)	loss_u 0.0076 (0.0112)	acc_x 90.6250 (87.1992)	lr 4.065471e-04
epoch [11/25][1700/4762]	time 0.139 (0.153)	data 0.001 (0.001)	eta 2:57:43	loss 0.5383 (0.3748)	loss_x 0.5017 (0.3637)	loss_u 0.0366 (0.0111)	acc_x 81.2500 (87.2040)	lr 4.065471e-04
epoch [11/25][1800/4762]	time 0.136 (0.153)	data 0.001 (0.001)	eta 2:57:58	loss 0.2722 (0.3746)	loss_x 0.2706 (0.3636)	loss_u 0.0016 (0.0109)	acc_x 96.8750 (87.2118)	lr 4.065471e-04
epoch [11/25][1900/4762]	time 0.185 (0.154)	data 0.001 (0.001)	eta 2:57:54	loss 0.5667 (0.3748)	loss_x 0.5574 (0.3640)	loss_u 0.0093 (0.0108)	acc_x 78.1250 (87.2171)	lr 4.065471e-04
epoch [11/25][2000/4762]	time 0.180 (0.154)	data 0.001 (0.001)	eta 2:57:45	loss 0.5173 (0.3754)	loss_x 0.5142 (0.3646)	loss_u 0.0031 (0.0108)	acc_x 84.3750 (87.1906)	lr 4.065471e-04
epoch [11/25][2100/4762]	time 0.200 (0.154)	data 0.001 (0.001)	eta 2:57:40	loss 0.3792 (0.3747)	loss_x 0.3765 (0.3640)	loss_u 0.0028 (0.0107)	acc_x 90.6250 (87.1964)	lr 4.065471e-04
epoch [11/25][2200/4762]	time 0.154 (0.154)	data 0.001 (0.001)	eta 2:57:31	loss 0.4199 (0.3745)	loss_x 0.4112 (0.3638)	loss_u 0.0087 (0.0106)	acc_x 90.6250 (87.2060)	lr 4.065471e-04
epoch [11/25][2300/4762]	time 0.165 (0.154)	data 0.001 (0.001)	eta 2:57:09	loss 0.2830 (0.3738)	loss_x 0.2600 (0.3632)	loss_u 0.0230 (0.0107)	acc_x 84.3750 (87.2174)	lr 4.065471e-04
epoch [11/25][2400/4762]	time 0.182 (0.154)	data 0.001 (0.001)	eta 2:56:49	loss 0.2815 (0.3746)	loss_x 0.2708 (0.3640)	loss_u 0.0108 (0.0106)	acc_x 87.5000 (87.1953)	lr 4.065471e-04
epoch [11/25][2500/4762]	time 0.155 (0.154)	data 0.001 (0.001)	eta 2:56:32	loss 0.2876 (0.3745)	loss_x 0.2759 (0.3638)	loss_u 0.0117 (0.0107)	acc_x 87.5000 (87.2175)	lr 4.065471e-04
epoch [11/25][2600/4762]	time 0.149 (0.154)	data 0.001 (0.001)	eta 2:56:14	loss 0.2290 (0.3750)	loss_x 0.2185 (0.3643)	loss_u 0.0106 (0.0107)	acc_x 93.7500 (87.1935)	lr 4.065471e-04
epoch [11/25][2700/4762]	time 0.157 (0.153)	data 0.001 (0.001)	eta 2:55:45	loss 0.4862 (0.3762)	loss_x 0.4744 (0.3656)	loss_u 0.0119 (0.0107)	acc_x 81.2500 (87.1285)	lr 4.065471e-04
epoch [11/25][2800/4762]	time 0.141 (0.153)	data 0.001 (0.001)	eta 2:55:25	loss 0.2436 (0.3757)	loss_x 0.2398 (0.3651)	loss_u 0.0037 (0.0106)	acc_x 90.6250 (87.1596)	lr 4.065471e-04
epoch [11/25][2900/4762]	time 0.138 (0.153)	data 0.001 (0.001)	eta 2:55:02	loss 0.5457 (0.3750)	loss_x 0.5399 (0.3644)	loss_u 0.0059 (0.0106)	acc_x 87.5000 (87.1886)	lr 4.065471e-04
epoch [11/25][3000/4762]	time 0.181 (0.153)	data 0.001 (0.001)	eta 2:54:47	loss 0.3446 (0.3753)	loss_x 0.3421 (0.3647)	loss_u 0.0024 (0.0106)	acc_x 90.6250 (87.1792)	lr 4.065471e-04
epoch [11/25][3100/4762]	time 0.143 (0.153)	data 0.001 (0.001)	eta 2:54:30	loss 0.4490 (0.3755)	loss_x 0.4370 (0.3650)	loss_u 0.0119 (0.0106)	acc_x 81.2500 (87.1774)	lr 4.065471e-04
epoch [11/25][3200/4762]	time 0.167 (0.153)	data 0.001 (0.001)	eta 2:54:15	loss 0.2178 (0.3763)	loss_x 0.2125 (0.3657)	loss_u 0.0053 (0.0106)	acc_x 93.7500 (87.1533)	lr 4.065471e-04
epoch [11/25][3300/4762]	time 0.155 (0.153)	data 0.001 (0.001)	eta 2:53:54	loss 0.4086 (0.3761)	loss_x 0.4013 (0.3655)	loss_u 0.0072 (0.0106)	acc_x 81.2500 (87.1439)	lr 4.065471e-04
epoch [11/25][3400/4762]	time 0.151 (0.153)	data 0.002 (0.001)	eta 2:53:37	loss 0.4721 (0.3759)	loss_x 0.4593 (0.3654)	loss_u 0.0128 (0.0106)	acc_x 84.3750 (87.1471)	lr 4.065471e-04
epoch [11/25][3500/4762]	time 0.164 (0.153)	data 0.001 (0.001)	eta 2:53:31	loss 0.2535 (0.3761)	loss_x 0.2510 (0.3655)	loss_u 0.0025 (0.0106)	acc_x 93.7500 (87.1357)	lr 4.065471e-04
epoch [11/25][3600/4762]	time 0.178 (0.153)	data 0.001 (0.001)	eta 2:53:15	loss 0.3430 (0.3761)	loss_x 0.3224 (0.3655)	loss_u 0.0206 (0.0106)	acc_x 90.6250 (87.1380)	lr 4.065471e-04
epoch [11/25][3700/4762]	time 0.165 (0.153)	data 0.001 (0.001)	eta 2:52:57	loss 0.3010 (0.3758)	loss_x 0.2959 (0.3652)	loss_u 0.0051 (0.0106)	acc_x 84.3750 (87.1512)	lr 4.065471e-04
epoch [11/25][3800/4762]	time 0.172 (0.153)	data 0.001 (0.001)	eta 2:52:38	loss 0.3967 (0.3757)	loss_x 0.3808 (0.3652)	loss_u 0.0159 (0.0106)	acc_x 81.2500 (87.1612)	lr 4.065471e-04
epoch [11/25][3900/4762]	time 0.145 (0.153)	data 0.001 (0.001)	eta 2:52:15	loss 0.1801 (0.3754)	loss_x 0.1746 (0.3649)	loss_u 0.0056 (0.0105)	acc_x 93.7500 (87.1482)	lr 4.065471e-04
epoch [11/25][4000/4762]	time 0.141 (0.153)	data 0.001 (0.001)	eta 2:52:00	loss 0.3041 (0.3755)	loss_x 0.2943 (0.3650)	loss_u 0.0098 (0.0105)	acc_x 90.6250 (87.1297)	lr 4.065471e-04
epoch [11/25][4100/4762]	time 0.137 (0.153)	data 0.001 (0.001)	eta 2:51:46	loss 0.2716 (0.3749)	loss_x 0.2649 (0.3644)	loss_u 0.0067 (0.0105)	acc_x 87.5000 (87.1410)	lr 4.065471e-04
epoch [11/25][4200/4762]	time 0.158 (0.153)	data 0.001 (0.001)	eta 2:51:27	loss 0.5674 (0.3749)	loss_x 0.5477 (0.3644)	loss_u 0.0196 (0.0105)	acc_x 78.1250 (87.1458)	lr 4.065471e-04
epoch [11/25][4300/4762]	time 0.139 (0.153)	data 0.001 (0.001)	eta 2:51:09	loss 0.6607 (0.3752)	loss_x 0.6535 (0.3647)	loss_u 0.0073 (0.0105)	acc_x 71.8750 (87.1410)	lr 4.065471e-04
epoch [11/25][4400/4762]	time 0.156 (0.153)	data 0.003 (0.001)	eta 2:50:52	loss 0.4028 (0.3757)	loss_x 0.4022 (0.3652)	loss_u 0.0006 (0.0105)	acc_x 84.3750 (87.1477)	lr 4.065471e-04
epoch [11/25][4500/4762]	time 0.174 (0.153)	data 0.001 (0.001)	eta 2:50:35	loss 0.4567 (0.3755)	loss_x 0.4553 (0.3650)	loss_u 0.0014 (0.0105)	acc_x 87.5000 (87.1556)	lr 4.065471e-04
epoch [11/25][4600/4762]	time 0.141 (0.153)	data 0.001 (0.001)	eta 2:50:19	loss 0.4989 (0.3752)	loss_x 0.4944 (0.3647)	loss_u 0.0045 (0.0106)	acc_x 78.1250 (87.1739)	lr 4.065471e-04
epoch [11/25][4700/4762]	time 0.137 (0.153)	data 0.001 (0.001)	eta 2:49:58	loss 0.6014 (0.3757)	loss_x 0.5996 (0.3652)	loss_u 0.0018 (0.0105)	acc_x 78.1250 (87.1549)	lr 4.065471e-04
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,762
* accuracy: 84.43%
* error: 15.57%
* macro_f1: 84.47%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,589	acc: 98.44%
* class: 1 (bicycle)	total: 3,475	correct: 2,924	acc: 84.14%
* class: 2 (bus)	total: 4,690	correct: 4,266	acc: 90.96%
* class: 3 (car)	total: 10,401	correct: 7,830	acc: 75.28%
* class: 4 (horse)	total: 4,691	correct: 4,579	acc: 97.61%
* class: 5 (knife)	total: 2,075	correct: 1,896	acc: 91.37%
* class: 6 (motorcycle)	total: 5,796	correct: 5,497	acc: 94.84%
* class: 7 (person)	total: 4,000	correct: 2,840	acc: 71.00%
* class: 8 (plant)	total: 4,549	correct: 3,910	acc: 85.95%
* class: 9 (skateboard)	total: 2,281	correct: 2,056	acc: 90.14%
* class: 10 (train)	total: 4,236	correct: 3,929	acc: 92.75%
* class: 11 (truck)	total: 5,548	correct: 3,446	acc: 62.11%
* average: 86.22%
epoch [12/25][100/4762]	time 0.137 (0.152)	data 0.001 (0.003)	eta 2:49:08	loss 0.2919 (0.3835)	loss_x 0.2777 (0.3726)	loss_u 0.0143 (0.0109)	acc_x 90.6250 (87.4062)	lr 4.065471e-04
epoch [12/25][200/4762]	time 0.144 (0.152)	data 0.001 (0.002)	eta 2:47:53	loss 0.1499 (0.3813)	loss_x 0.1451 (0.3712)	loss_u 0.0047 (0.0101)	acc_x 96.8750 (87.0625)	lr 4.065471e-04
epoch [12/25][300/4762]	time 0.138 (0.153)	data 0.001 (0.002)	eta 2:48:47	loss 0.4329 (0.3772)	loss_x 0.4237 (0.3670)	loss_u 0.0092 (0.0102)	acc_x 87.5000 (87.2500)	lr 4.065471e-04
epoch [12/25][400/4762]	time 0.157 (0.153)	data 0.001 (0.002)	eta 2:48:54	loss 0.6530 (0.3765)	loss_x 0.5300 (0.3657)	loss_u 0.1230 (0.0109)	acc_x 87.5000 (87.3672)	lr 4.065471e-04
epoch [12/25][500/4762]	time 0.137 (0.152)	data 0.001 (0.001)	eta 2:47:58	loss 0.2707 (0.3771)	loss_x 0.2667 (0.3658)	loss_u 0.0040 (0.0113)	acc_x 84.3750 (87.2687)	lr 4.065471e-04
epoch [12/25][600/4762]	time 0.142 (0.152)	data 0.001 (0.001)	eta 2:47:26	loss 0.1010 (0.3787)	loss_x 0.0905 (0.3673)	loss_u 0.0104 (0.0114)	acc_x 96.8750 (87.2500)	lr 4.065471e-04
epoch [12/25][700/4762]	time 0.189 (0.152)	data 0.001 (0.001)	eta 2:47:26	loss 0.6520 (0.3773)	loss_x 0.6374 (0.3660)	loss_u 0.0146 (0.0114)	acc_x 78.1250 (87.1920)	lr 4.065471e-04
epoch [12/25][800/4762]	time 0.150 (0.153)	data 0.001 (0.001)	eta 2:47:33	loss 0.2168 (0.3770)	loss_x 0.2067 (0.3656)	loss_u 0.0101 (0.0114)	acc_x 87.5000 (87.2031)	lr 4.065471e-04
epoch [12/25][900/4762]	time 0.153 (0.152)	data 0.015 (0.001)	eta 2:46:58	loss 0.3730 (0.3761)	loss_x 0.3687 (0.3648)	loss_u 0.0043 (0.0114)	acc_x 84.3750 (87.1910)	lr 4.065471e-04
epoch [12/25][1000/4762]	time 0.170 (0.152)	data 0.001 (0.001)	eta 2:46:50	loss 0.5263 (0.3776)	loss_x 0.5163 (0.3662)	loss_u 0.0100 (0.0114)	acc_x 75.0000 (87.0563)	lr 4.065471e-04
epoch [12/25][1100/4762]	time 0.169 (0.153)	data 0.001 (0.001)	eta 2:47:08	loss 0.2635 (0.3777)	loss_x 0.2438 (0.3663)	loss_u 0.0197 (0.0114)	acc_x 90.6250 (87.0483)	lr 4.065471e-04
epoch [12/25][1200/4762]	time 0.190 (0.153)	data 0.001 (0.001)	eta 2:47:14	loss 0.4155 (0.3781)	loss_x 0.4086 (0.3668)	loss_u 0.0069 (0.0113)	acc_x 81.2500 (87.0755)	lr 4.065471e-04
epoch [12/25][1300/4762]	time 0.165 (0.153)	data 0.001 (0.001)	eta 2:47:09	loss 0.5391 (0.3780)	loss_x 0.5330 (0.3668)	loss_u 0.0062 (0.0112)	acc_x 75.0000 (87.0721)	lr 4.065471e-04
epoch [12/25][1400/4762]	time 0.137 (0.154)	data 0.001 (0.001)	eta 2:47:03	loss 0.1818 (0.3775)	loss_x 0.1726 (0.3663)	loss_u 0.0092 (0.0112)	acc_x 93.7500 (87.0915)	lr 4.065471e-04
epoch [12/25][1500/4762]	time 0.141 (0.154)	data 0.001 (0.001)	eta 2:46:49	loss 0.6925 (0.3792)	loss_x 0.6828 (0.3680)	loss_u 0.0097 (0.0112)	acc_x 75.0000 (87.0500)	lr 4.065471e-04
epoch [12/25][1600/4762]	time 0.140 (0.153)	data 0.001 (0.001)	eta 2:46:21	loss 0.2845 (0.3791)	loss_x 0.2741 (0.3680)	loss_u 0.0105 (0.0111)	acc_x 90.6250 (87.0801)	lr 4.065471e-04
epoch [12/25][1700/4762]	time 0.165 (0.153)	data 0.001 (0.001)	eta 2:45:57	loss 0.2402 (0.3785)	loss_x 0.2236 (0.3675)	loss_u 0.0166 (0.0110)	acc_x 90.6250 (87.1103)	lr 4.065471e-04
epoch [12/25][1800/4762]	time 0.152 (0.153)	data 0.001 (0.001)	eta 2:45:45	loss 0.4990 (0.3793)	loss_x 0.4574 (0.3683)	loss_u 0.0416 (0.0110)	acc_x 84.3750 (87.1007)	lr 4.065471e-04
epoch [12/25][1900/4762]	time 0.152 (0.153)	data 0.001 (0.001)	eta 2:45:09	loss 0.2946 (0.3779)	loss_x 0.2883 (0.3670)	loss_u 0.0063 (0.0109)	acc_x 84.3750 (87.1299)	lr 4.065471e-04
epoch [12/25][2000/4762]	time 0.145 (0.153)	data 0.001 (0.001)	eta 2:44:35	loss 0.4003 (0.3773)	loss_x 0.3896 (0.3664)	loss_u 0.0107 (0.0109)	acc_x 84.3750 (87.1578)	lr 4.065471e-04
epoch [12/25][2100/4762]	time 0.164 (0.153)	data 0.001 (0.001)	eta 2:44:21	loss 0.3753 (0.3774)	loss_x 0.3700 (0.3666)	loss_u 0.0053 (0.0108)	acc_x 84.3750 (87.1637)	lr 4.065471e-04
epoch [12/25][2200/4762]	time 0.153 (0.153)	data 0.001 (0.001)	eta 2:44:06	loss 0.1885 (0.3766)	loss_x 0.1830 (0.3658)	loss_u 0.0055 (0.0108)	acc_x 90.6250 (87.1662)	lr 4.065471e-04
epoch [12/25][2300/4762]	time 0.179 (0.153)	data 0.001 (0.001)	eta 2:43:54	loss 0.3063 (0.3758)	loss_x 0.2938 (0.3651)	loss_u 0.0125 (0.0107)	acc_x 87.5000 (87.1929)	lr 4.065471e-04
epoch [12/25][2400/4762]	time 0.160 (0.153)	data 0.001 (0.001)	eta 2:43:52	loss 0.4125 (0.3757)	loss_x 0.4078 (0.3651)	loss_u 0.0047 (0.0106)	acc_x 81.2500 (87.1940)	lr 4.065471e-04
epoch [12/25][2500/4762]	time 0.149 (0.153)	data 0.001 (0.001)	eta 2:43:45	loss 0.4285 (0.3748)	loss_x 0.3972 (0.3640)	loss_u 0.0313 (0.0108)	acc_x 84.3750 (87.2262)	lr 4.065471e-04
epoch [12/25][2600/4762]	time 0.144 (0.153)	data 0.001 (0.001)	eta 2:43:29	loss 0.7214 (0.3747)	loss_x 0.7156 (0.3639)	loss_u 0.0058 (0.0108)	acc_x 81.2500 (87.2356)	lr 4.065471e-04
epoch [12/25][2700/4762]	time 0.140 (0.153)	data 0.001 (0.001)	eta 2:43:12	loss 0.4044 (0.3751)	loss_x 0.3901 (0.3644)	loss_u 0.0143 (0.0107)	acc_x 84.3750 (87.2269)	lr 4.065471e-04
epoch [12/25][2800/4762]	time 0.137 (0.153)	data 0.001 (0.001)	eta 2:42:47	loss 0.5395 (0.3745)	loss_x 0.5265 (0.3639)	loss_u 0.0130 (0.0107)	acc_x 75.0000 (87.2444)	lr 4.065471e-04
epoch [12/25][2900/4762]	time 0.140 (0.153)	data 0.001 (0.001)	eta 2:42:28	loss 0.3449 (0.3744)	loss_x 0.3443 (0.3637)	loss_u 0.0006 (0.0106)	acc_x 84.3750 (87.2381)	lr 4.065471e-04
epoch [12/25][3000/4762]	time 0.173 (0.153)	data 0.001 (0.001)	eta 2:42:07	loss 0.4793 (0.3750)	loss_x 0.4679 (0.3644)	loss_u 0.0114 (0.0106)	acc_x 78.1250 (87.2083)	lr 4.065471e-04
epoch [12/25][3100/4762]	time 0.136 (0.153)	data 0.001 (0.001)	eta 2:41:47	loss 0.4486 (0.3748)	loss_x 0.4422 (0.3643)	loss_u 0.0064 (0.0105)	acc_x 81.2500 (87.2228)	lr 4.065471e-04
epoch [12/25][3200/4762]	time 0.158 (0.153)	data 0.001 (0.001)	eta 2:41:28	loss 0.3887 (0.3745)	loss_x 0.3710 (0.3640)	loss_u 0.0178 (0.0105)	acc_x 90.6250 (87.2246)	lr 4.065471e-04
epoch [12/25][3300/4762]	time 0.139 (0.153)	data 0.001 (0.001)	eta 2:41:11	loss 0.3037 (0.3743)	loss_x 0.2991 (0.3638)	loss_u 0.0046 (0.0105)	acc_x 90.6250 (87.2424)	lr 4.065471e-04
epoch [12/25][3400/4762]	time 0.142 (0.153)	data 0.001 (0.001)	eta 2:40:53	loss 0.3673 (0.3744)	loss_x 0.3585 (0.3640)	loss_u 0.0088 (0.0105)	acc_x 84.3750 (87.2316)	lr 4.065471e-04
epoch [12/25][3500/4762]	time 0.175 (0.153)	data 0.001 (0.001)	eta 2:40:46	loss 0.4685 (0.3744)	loss_x 0.4651 (0.3639)	loss_u 0.0034 (0.0105)	acc_x 90.6250 (87.2152)	lr 4.065471e-04
epoch [12/25][3600/4762]	time 0.141 (0.153)	data 0.001 (0.001)	eta 2:40:29	loss 0.4722 (0.3749)	loss_x 0.4682 (0.3644)	loss_u 0.0040 (0.0105)	acc_x 84.3750 (87.1832)	lr 4.065471e-04
epoch [12/25][3700/4762]	time 0.203 (0.153)	data 0.001 (0.001)	eta 2:40:08	loss 0.2689 (0.3741)	loss_x 0.2376 (0.3636)	loss_u 0.0313 (0.0105)	acc_x 90.6250 (87.2086)	lr 4.065471e-04
epoch [12/25][3800/4762]	time 0.145 (0.153)	data 0.001 (0.001)	eta 2:39:48	loss 0.5058 (0.3744)	loss_x 0.5006 (0.3639)	loss_u 0.0052 (0.0105)	acc_x 71.8750 (87.2056)	lr 4.065471e-04
epoch [12/25][3900/4762]	time 0.143 (0.152)	data 0.001 (0.001)	eta 2:39:28	loss 0.6496 (0.3750)	loss_x 0.6405 (0.3645)	loss_u 0.0091 (0.0105)	acc_x 75.0000 (87.1883)	lr 4.065471e-04
epoch [12/25][4000/4762]	time 0.140 (0.152)	data 0.001 (0.001)	eta 2:39:14	loss 0.3046 (0.3752)	loss_x 0.2931 (0.3647)	loss_u 0.0115 (0.0104)	acc_x 90.6250 (87.1805)	lr 4.065471e-04
epoch [12/25][4100/4762]	time 0.155 (0.153)	data 0.001 (0.001)	eta 2:39:01	loss 0.5497 (0.3751)	loss_x 0.5367 (0.3647)	loss_u 0.0130 (0.0104)	acc_x 81.2500 (87.1867)	lr 4.065471e-04
epoch [12/25][4200/4762]	time 0.158 (0.152)	data 0.001 (0.001)	eta 2:38:42	loss 0.2018 (0.3755)	loss_x 0.1975 (0.3651)	loss_u 0.0043 (0.0104)	acc_x 93.7500 (87.1741)	lr 4.065471e-04
epoch [12/25][4300/4762]	time 0.143 (0.152)	data 0.001 (0.001)	eta 2:38:25	loss 0.5080 (0.3764)	loss_x 0.5052 (0.3659)	loss_u 0.0028 (0.0105)	acc_x 84.3750 (87.1468)	lr 4.065471e-04
epoch [12/25][4400/4762]	time 0.154 (0.152)	data 0.001 (0.001)	eta 2:38:09	loss 0.6047 (0.3759)	loss_x 0.5976 (0.3654)	loss_u 0.0071 (0.0105)	acc_x 81.2500 (87.1648)	lr 4.065471e-04
epoch [12/25][4500/4762]	time 0.164 (0.152)	data 0.001 (0.001)	eta 2:37:51	loss 0.2925 (0.3753)	loss_x 0.2893 (0.3649)	loss_u 0.0032 (0.0105)	acc_x 90.6250 (87.1792)	lr 4.065471e-04
epoch [12/25][4600/4762]	time 0.164 (0.152)	data 0.002 (0.001)	eta 2:37:33	loss 0.3363 (0.3754)	loss_x 0.3301 (0.3649)	loss_u 0.0062 (0.0105)	acc_x 87.5000 (87.1726)	lr 4.065471e-04
epoch [12/25][4700/4762]	time 0.156 (0.152)	data 0.001 (0.001)	eta 2:37:20	loss 0.5374 (0.3755)	loss_x 0.5280 (0.3650)	loss_u 0.0094 (0.0105)	acc_x 78.1250 (87.1609)	lr 4.065471e-04
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,747
* accuracy: 84.40%
* error: 15.60%
* macro_f1: 84.56%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,590	acc: 98.46%
* class: 1 (bicycle)	total: 3,475	correct: 2,926	acc: 84.20%
* class: 2 (bus)	total: 4,690	correct: 4,235	acc: 90.30%
* class: 3 (car)	total: 10,401	correct: 7,724	acc: 74.26%
* class: 4 (horse)	total: 4,691	correct: 4,583	acc: 97.70%
* class: 5 (knife)	total: 2,075	correct: 1,886	acc: 90.89%
* class: 6 (motorcycle)	total: 5,796	correct: 5,520	acc: 95.24%
* class: 7 (person)	total: 4,000	correct: 3,051	acc: 76.28%
* class: 8 (plant)	total: 4,549	correct: 3,829	acc: 84.17%
* class: 9 (skateboard)	total: 2,281	correct: 2,036	acc: 89.26%
* class: 10 (train)	total: 4,236	correct: 3,923	acc: 92.61%
* class: 11 (truck)	total: 5,548	correct: 3,444	acc: 62.08%
* average: 86.29%
epoch [13/25][100/4762]	time 0.145 (0.155)	data 0.001 (0.003)	eta 2:39:34	loss 0.2692 (0.3742)	loss_x 0.2552 (0.3638)	loss_u 0.0139 (0.0104)	acc_x 93.7500 (87.5312)	lr 2.456136e-03
epoch [13/25][200/4762]	time 0.172 (0.153)	data 0.001 (0.002)	eta 2:37:24	loss 0.5457 (0.3885)	loss_x 0.5294 (0.3781)	loss_u 0.0163 (0.0104)	acc_x 81.2500 (86.7656)	lr 2.456136e-03
epoch [13/25][300/4762]	time 0.166 (0.153)	data 0.004 (0.002)	eta 2:37:01	loss 0.4971 (0.3864)	loss_x 0.4841 (0.3758)	loss_u 0.0130 (0.0105)	acc_x 84.3750 (86.9167)	lr 2.456136e-03
epoch [13/25][400/4762]	time 0.140 (0.153)	data 0.001 (0.001)	eta 2:36:21	loss 0.3630 (0.3867)	loss_x 0.3615 (0.3761)	loss_u 0.0015 (0.0105)	acc_x 90.6250 (86.8359)	lr 2.456136e-03
epoch [13/25][500/4762]	time 0.154 (0.153)	data 0.001 (0.001)	eta 2:36:47	loss 0.1951 (0.3800)	loss_x 0.1691 (0.3697)	loss_u 0.0260 (0.0103)	acc_x 93.7500 (87.1063)	lr 2.456136e-03
epoch [13/25][600/4762]	time 0.141 (0.153)	data 0.001 (0.001)	eta 2:36:04	loss 0.4118 (0.3793)	loss_x 0.3981 (0.3690)	loss_u 0.0137 (0.0103)	acc_x 75.0000 (86.9896)	lr 2.456136e-03
epoch [13/25][700/4762]	time 0.159 (0.153)	data 0.001 (0.001)	eta 2:35:49	loss 0.3261 (0.3808)	loss_x 0.2886 (0.3704)	loss_u 0.0375 (0.0104)	acc_x 93.7500 (86.9330)	lr 2.456136e-03
epoch [13/25][800/4762]	time 0.147 (0.153)	data 0.001 (0.001)	eta 2:35:37	loss 0.1827 (0.3779)	loss_x 0.1675 (0.3678)	loss_u 0.0151 (0.0102)	acc_x 87.5000 (87.0312)	lr 2.456136e-03
epoch [13/25][900/4762]	time 0.139 (0.153)	data 0.001 (0.001)	eta 2:35:11	loss 0.3868 (0.3767)	loss_x 0.3669 (0.3666)	loss_u 0.0199 (0.0101)	acc_x 87.5000 (87.0139)	lr 2.456136e-03
epoch [13/25][1000/4762]	time 0.153 (0.153)	data 0.001 (0.001)	eta 2:34:49	loss 0.1879 (0.3766)	loss_x 0.1847 (0.3664)	loss_u 0.0032 (0.0101)	acc_x 96.8750 (86.9406)	lr 2.456136e-03
epoch [13/25][1100/4762]	time 0.156 (0.153)	data 0.001 (0.001)	eta 2:34:46	loss 0.2606 (0.3779)	loss_x 0.2519 (0.3674)	loss_u 0.0087 (0.0105)	acc_x 93.7500 (86.8665)	lr 2.456136e-03
epoch [13/25][1200/4762]	time 0.137 (0.153)	data 0.001 (0.001)	eta 2:34:38	loss 0.6650 (0.3762)	loss_x 0.6601 (0.3657)	loss_u 0.0048 (0.0105)	acc_x 78.1250 (86.9479)	lr 2.456136e-03
epoch [13/25][1300/4762]	time 0.156 (0.153)	data 0.001 (0.001)	eta 2:34:26	loss 0.5969 (0.3761)	loss_x 0.5679 (0.3656)	loss_u 0.0290 (0.0105)	acc_x 71.8750 (86.9423)	lr 2.456136e-03
epoch [13/25][1400/4762]	time 0.141 (0.153)	data 0.001 (0.001)	eta 2:34:04	loss 0.3565 (0.3767)	loss_x 0.3524 (0.3661)	loss_u 0.0041 (0.0106)	acc_x 84.3750 (86.9330)	lr 2.456136e-03
epoch [13/25][1500/4762]	time 0.137 (0.153)	data 0.001 (0.001)	eta 2:33:50	loss 0.3252 (0.3759)	loss_x 0.3119 (0.3651)	loss_u 0.0132 (0.0108)	acc_x 90.6250 (86.9708)	lr 2.456136e-03
epoch [13/25][1600/4762]	time 0.173 (0.153)	data 0.001 (0.001)	eta 2:33:50	loss 0.2080 (0.3762)	loss_x 0.1780 (0.3655)	loss_u 0.0300 (0.0107)	acc_x 93.7500 (86.9512)	lr 2.456136e-03
epoch [13/25][1700/4762]	time 0.187 (0.153)	data 0.001 (0.001)	eta 2:33:28	loss 0.1603 (0.3746)	loss_x 0.1532 (0.3639)	loss_u 0.0071 (0.0107)	acc_x 96.8750 (87.0294)	lr 2.456136e-03
epoch [13/25][1800/4762]	time 0.159 (0.153)	data 0.001 (0.001)	eta 2:33:33	loss 0.5611 (0.3749)	loss_x 0.5599 (0.3642)	loss_u 0.0012 (0.0107)	acc_x 81.2500 (87.0451)	lr 2.456136e-03
epoch [13/25][1900/4762]	time 0.142 (0.153)	data 0.001 (0.001)	eta 2:33:15	loss 0.3121 (0.3742)	loss_x 0.3043 (0.3636)	loss_u 0.0078 (0.0107)	acc_x 87.5000 (87.0658)	lr 2.456136e-03
epoch [13/25][2000/4762]	time 0.199 (0.153)	data 0.002 (0.001)	eta 2:32:59	loss 0.5819 (0.3750)	loss_x 0.5680 (0.3643)	loss_u 0.0139 (0.0106)	acc_x 81.2500 (87.0469)	lr 2.456136e-03
epoch [13/25][2100/4762]	time 0.175 (0.153)	data 0.001 (0.001)	eta 2:32:50	loss 0.4656 (0.3759)	loss_x 0.4529 (0.3653)	loss_u 0.0126 (0.0106)	acc_x 84.3750 (87.0134)	lr 2.456136e-03
epoch [13/25][2200/4762]	time 0.150 (0.153)	data 0.001 (0.001)	eta 2:32:38	loss 0.3079 (0.3753)	loss_x 0.3044 (0.3647)	loss_u 0.0035 (0.0106)	acc_x 87.5000 (87.0710)	lr 2.456136e-03
epoch [13/25][2300/4762]	time 0.136 (0.153)	data 0.001 (0.001)	eta 2:32:19	loss 0.2289 (0.3737)	loss_x 0.2250 (0.3631)	loss_u 0.0038 (0.0106)	acc_x 90.6250 (87.1332)	lr 2.456136e-03
epoch [13/25][2400/4762]	time 0.153 (0.153)	data 0.001 (0.001)	eta 2:32:13	loss 0.2516 (0.3735)	loss_x 0.2471 (0.3629)	loss_u 0.0045 (0.0106)	acc_x 90.6250 (87.1458)	lr 2.456136e-03
epoch [13/25][2500/4762]	time 0.137 (0.154)	data 0.001 (0.001)	eta 2:32:07	loss 0.2090 (0.3736)	loss_x 0.2015 (0.3630)	loss_u 0.0075 (0.0106)	acc_x 93.7500 (87.1350)	lr 2.456136e-03
epoch [13/25][2600/4762]	time 0.167 (0.154)	data 0.001 (0.001)	eta 2:31:56	loss 0.2876 (0.3739)	loss_x 0.2587 (0.3634)	loss_u 0.0289 (0.0105)	acc_x 93.7500 (87.1190)	lr 2.456136e-03
epoch [13/25][2700/4762]	time 0.165 (0.154)	data 0.001 (0.001)	eta 2:31:36	loss 0.3993 (0.3745)	loss_x 0.3787 (0.3639)	loss_u 0.0207 (0.0105)	acc_x 87.5000 (87.1065)	lr 2.456136e-03
epoch [13/25][2800/4762]	time 0.141 (0.154)	data 0.001 (0.001)	eta 2:31:19	loss 0.5496 (0.3747)	loss_x 0.5412 (0.3643)	loss_u 0.0084 (0.0105)	acc_x 84.3750 (87.1105)	lr 2.456136e-03
epoch [13/25][2900/4762]	time 0.137 (0.154)	data 0.001 (0.001)	eta 2:31:03	loss 0.3784 (0.3746)	loss_x 0.3723 (0.3642)	loss_u 0.0061 (0.0105)	acc_x 87.5000 (87.1293)	lr 2.456136e-03
epoch [13/25][3000/4762]	time 0.150 (0.153)	data 0.001 (0.001)	eta 2:30:33	loss 0.2245 (0.3746)	loss_x 0.2160 (0.3640)	loss_u 0.0085 (0.0105)	acc_x 93.7500 (87.1396)	lr 2.456136e-03
epoch [13/25][3100/4762]	time 0.166 (0.153)	data 0.001 (0.001)	eta 2:30:13	loss 0.3569 (0.3744)	loss_x 0.3508 (0.3638)	loss_u 0.0061 (0.0106)	acc_x 84.3750 (87.1623)	lr 2.456136e-03
epoch [13/25][3200/4762]	time 0.146 (0.153)	data 0.001 (0.001)	eta 2:29:59	loss 0.2549 (0.3745)	loss_x 0.2518 (0.3639)	loss_u 0.0031 (0.0106)	acc_x 90.6250 (87.1582)	lr 2.456136e-03
epoch [13/25][3300/4762]	time 0.169 (0.153)	data 0.001 (0.001)	eta 2:29:43	loss 0.4623 (0.3742)	loss_x 0.4462 (0.3637)	loss_u 0.0161 (0.0105)	acc_x 78.1250 (87.1771)	lr 2.456136e-03
epoch [13/25][3400/4762]	time 0.176 (0.153)	data 0.001 (0.001)	eta 2:29:28	loss 0.2627 (0.3737)	loss_x 0.2596 (0.3632)	loss_u 0.0031 (0.0105)	acc_x 93.7500 (87.2086)	lr 2.456136e-03
epoch [13/25][3500/4762]	time 0.151 (0.153)	data 0.001 (0.001)	eta 2:29:17	loss 0.6631 (0.3739)	loss_x 0.6404 (0.3634)	loss_u 0.0227 (0.0105)	acc_x 75.0000 (87.2054)	lr 2.456136e-03
epoch [13/25][3600/4762]	time 0.155 (0.153)	data 0.001 (0.001)	eta 2:29:00	loss 0.1835 (0.3739)	loss_x 0.1726 (0.3633)	loss_u 0.0109 (0.0106)	acc_x 93.7500 (87.2205)	lr 2.456136e-03
epoch [13/25][3700/4762]	time 0.162 (0.153)	data 0.001 (0.001)	eta 2:28:43	loss 0.3092 (0.3747)	loss_x 0.3043 (0.3642)	loss_u 0.0049 (0.0105)	acc_x 96.8750 (87.1858)	lr 2.456136e-03
epoch [13/25][3800/4762]	time 0.166 (0.153)	data 0.001 (0.001)	eta 2:28:25	loss 0.2919 (0.3744)	loss_x 0.2859 (0.3639)	loss_u 0.0060 (0.0106)	acc_x 90.6250 (87.1842)	lr 2.456136e-03
epoch [13/25][3900/4762]	time 0.146 (0.153)	data 0.001 (0.001)	eta 2:28:11	loss 0.3486 (0.3745)	loss_x 0.3379 (0.3640)	loss_u 0.0107 (0.0105)	acc_x 87.5000 (87.1643)	lr 2.456136e-03
epoch [13/25][4000/4762]	time 0.138 (0.153)	data 0.001 (0.001)	eta 2:27:54	loss 0.3619 (0.3747)	loss_x 0.3522 (0.3642)	loss_u 0.0097 (0.0105)	acc_x 90.6250 (87.1570)	lr 2.456136e-03
epoch [13/25][4100/4762]	time 0.143 (0.153)	data 0.001 (0.001)	eta 2:27:40	loss 0.6101 (0.3750)	loss_x 0.6026 (0.3646)	loss_u 0.0075 (0.0104)	acc_x 75.0000 (87.1448)	lr 2.456136e-03
epoch [13/25][4200/4762]	time 0.144 (0.153)	data 0.001 (0.001)	eta 2:27:21	loss 0.2918 (0.3754)	loss_x 0.2870 (0.3649)	loss_u 0.0048 (0.0106)	acc_x 87.5000 (87.1362)	lr 2.456136e-03
epoch [13/25][4300/4762]	time 0.138 (0.153)	data 0.001 (0.001)	eta 2:27:05	loss 0.5251 (0.3760)	loss_x 0.5190 (0.3654)	loss_u 0.0062 (0.0106)	acc_x 81.2500 (87.1192)	lr 2.456136e-03
epoch [13/25][4400/4762]	time 0.137 (0.153)	data 0.001 (0.001)	eta 2:26:47	loss 0.4186 (0.3751)	loss_x 0.4166 (0.3645)	loss_u 0.0019 (0.0106)	acc_x 87.5000 (87.1435)	lr 2.456136e-03
epoch [13/25][4500/4762]	time 0.139 (0.153)	data 0.001 (0.001)	eta 2:26:33	loss 0.5014 (0.3754)	loss_x 0.4889 (0.3647)	loss_u 0.0125 (0.0106)	acc_x 87.5000 (87.1278)	lr 2.456136e-03
epoch [13/25][4600/4762]	time 0.139 (0.153)	data 0.001 (0.001)	eta 2:26:16	loss 0.3717 (0.3752)	loss_x 0.3643 (0.3645)	loss_u 0.0073 (0.0106)	acc_x 90.6250 (87.1359)	lr 2.456136e-03
epoch [13/25][4700/4762]	time 0.151 (0.153)	data 0.001 (0.001)	eta 2:25:58	loss 0.3462 (0.3754)	loss_x 0.3303 (0.3648)	loss_u 0.0158 (0.0106)	acc_x 87.5000 (87.1390)	lr 2.456136e-03
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,922
* accuracy: 84.72%
* error: 15.28%
* macro_f1: 84.96%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,580	acc: 98.19%
* class: 1 (bicycle)	total: 3,475	correct: 2,900	acc: 83.45%
* class: 2 (bus)	total: 4,690	correct: 4,209	acc: 89.74%
* class: 3 (car)	total: 10,401	correct: 7,896	acc: 75.92%
* class: 4 (horse)	total: 4,691	correct: 4,589	acc: 97.83%
* class: 5 (knife)	total: 2,075	correct: 1,824	acc: 87.90%
* class: 6 (motorcycle)	total: 5,796	correct: 5,519	acc: 95.22%
* class: 7 (person)	total: 4,000	correct: 3,127	acc: 78.17%
* class: 8 (plant)	total: 4,549	correct: 3,881	acc: 85.32%
* class: 9 (skateboard)	total: 2,281	correct: 2,073	acc: 90.88%
* class: 10 (train)	total: 4,236	correct: 3,916	acc: 92.45%
* class: 11 (truck)	total: 5,548	correct: 3,408	acc: 61.43%
* average: 86.37%
epoch [14/25][100/4762]	time 0.147 (0.153)	data 0.001 (0.003)	eta 2:25:03	loss 0.5222 (0.3809)	loss_x 0.5202 (0.3720)	loss_u 0.0020 (0.0090)	acc_x 84.3750 (86.4688)	lr 2.713525e-03
epoch [14/25][200/4762]	time 0.141 (0.152)	data 0.001 (0.002)	eta 2:24:18	loss 0.3801 (0.3688)	loss_x 0.3648 (0.3601)	loss_u 0.0153 (0.0087)	acc_x 87.5000 (87.2969)	lr 2.713525e-03
epoch [14/25][300/4762]	time 0.172 (0.151)	data 0.001 (0.001)	eta 2:23:26	loss 0.4660 (0.3755)	loss_x 0.4518 (0.3667)	loss_u 0.0142 (0.0088)	acc_x 78.1250 (87.1354)	lr 2.713525e-03
epoch [14/25][400/4762]	time 0.176 (0.152)	data 0.001 (0.001)	eta 2:23:17	loss 0.1988 (0.3751)	loss_x 0.1972 (0.3660)	loss_u 0.0016 (0.0091)	acc_x 93.7500 (87.2500)	lr 2.713525e-03
epoch [14/25][500/4762]	time 0.138 (0.151)	data 0.001 (0.001)	eta 2:22:35	loss 0.7119 (0.3726)	loss_x 0.7079 (0.3637)	loss_u 0.0040 (0.0090)	acc_x 78.1250 (87.3187)	lr 2.713525e-03
epoch [14/25][600/4762]	time 0.137 (0.151)	data 0.001 (0.001)	eta 2:22:33	loss 0.2891 (0.3706)	loss_x 0.2766 (0.3615)	loss_u 0.0125 (0.0091)	acc_x 93.7500 (87.3490)	lr 2.713525e-03
epoch [14/25][700/4762]	time 0.148 (0.151)	data 0.006 (0.001)	eta 2:22:14	loss 0.2023 (0.3711)	loss_x 0.1959 (0.3618)	loss_u 0.0064 (0.0093)	acc_x 93.7500 (87.3973)	lr 2.713525e-03
epoch [14/25][800/4762]	time 0.138 (0.151)	data 0.001 (0.001)	eta 2:21:57	loss 0.2009 (0.3716)	loss_x 0.1909 (0.3624)	loss_u 0.0100 (0.0093)	acc_x 93.7500 (87.3359)	lr 2.713525e-03
epoch [14/25][900/4762]	time 0.148 (0.151)	data 0.001 (0.001)	eta 2:21:47	loss 0.3761 (0.3721)	loss_x 0.3757 (0.3629)	loss_u 0.0004 (0.0092)	acc_x 90.6250 (87.3229)	lr 2.713525e-03
epoch [14/25][1000/4762]	time 0.136 (0.151)	data 0.001 (0.001)	eta 2:21:19	loss 0.6745 (0.3706)	loss_x 0.6678 (0.3612)	loss_u 0.0067 (0.0094)	acc_x 78.1250 (87.3906)	lr 2.713525e-03
epoch [14/25][1100/4762]	time 0.157 (0.151)	data 0.001 (0.001)	eta 2:21:00	loss 0.4282 (0.3711)	loss_x 0.3904 (0.3617)	loss_u 0.0378 (0.0094)	acc_x 90.6250 (87.3409)	lr 2.713525e-03
epoch [14/25][1200/4762]	time 0.148 (0.151)	data 0.001 (0.001)	eta 2:21:08	loss 0.2170 (0.3695)	loss_x 0.2120 (0.3602)	loss_u 0.0050 (0.0092)	acc_x 90.6250 (87.3672)	lr 2.713525e-03
epoch [14/25][1300/4762]	time 0.153 (0.152)	data 0.001 (0.001)	eta 2:21:09	loss 0.5255 (0.3712)	loss_x 0.5163 (0.3618)	loss_u 0.0092 (0.0094)	acc_x 90.6250 (87.2812)	lr 2.713525e-03
epoch [14/25][1400/4762]	time 0.150 (0.152)	data 0.001 (0.001)	eta 2:21:04	loss 0.4874 (0.3701)	loss_x 0.4868 (0.3606)	loss_u 0.0006 (0.0094)	acc_x 84.3750 (87.3371)	lr 2.713525e-03
epoch [14/25][1500/4762]	time 0.139 (0.152)	data 0.001 (0.001)	eta 2:20:51	loss 0.4755 (0.3708)	loss_x 0.4643 (0.3613)	loss_u 0.0112 (0.0096)	acc_x 84.3750 (87.3063)	lr 2.713525e-03
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,881
* accuracy: 84.64%
* error: 15.36%
* macro_f1: 84.83%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,586	acc: 98.35%
* class: 1 (bicycle)	total: 3,475	correct: 2,867	acc: 82.50%
* class: 2 (bus)	total: 4,690	correct: 4,248	acc: 90.58%
* class: 3 (car)	total: 10,401	correct: 7,878	acc: 75.74%
* class: 4 (horse)	total: 4,691	correct: 4,575	acc: 97.53%
* class: 5 (knife)	total: 2,075	correct: 1,860	acc: 89.64%
* class: 6 (motorcycle)	total: 5,796	correct: 5,513	acc: 95.12%
* class: 7 (person)	total: 4,000	correct: 3,058	acc: 76.45%
* class: 8 (plant)	total: 4,549	correct: 3,901	acc: 85.76%
* class: 9 (skateboard)	total: 2,281	correct: 2,066	acc: 90.57%
* class: 10 (train)	total: 4,236	correct: 3,943	acc: 93.08%
* class: 11 (truck)	total: 5,548	correct: 3,386	acc: 61.03%
* average: 86.36%
epoch [14/25][1600/4762]	time 0.158 (0.152)	data 0.001 (0.001)	eta 2:20:41	loss 0.2530 (0.3717)	loss_x 0.2497 (0.3622)	loss_u 0.0033 (0.0096)	acc_x 90.6250 (87.2500)	lr 2.713525e-03
epoch [14/25][1700/4762]	time 0.137 (0.152)	data 0.001 (0.001)	eta 2:20:23	loss 0.2936 (0.3711)	loss_x 0.2754 (0.3614)	loss_u 0.0182 (0.0097)	acc_x 87.5000 (87.2684)	lr 2.713525e-03
epoch [14/25][1800/4762]	time 0.136 (0.152)	data 0.001 (0.001)	eta 2:20:14	loss 0.4576 (0.3722)	loss_x 0.4521 (0.3625)	loss_u 0.0055 (0.0097)	acc_x 84.3750 (87.2205)	lr 2.713525e-03
epoch [14/25][1900/4762]	time 0.141 (0.152)	data 0.001 (0.001)	eta 2:19:54	loss 0.4175 (0.3721)	loss_x 0.4143 (0.3624)	loss_u 0.0032 (0.0097)	acc_x 87.5000 (87.2418)	lr 2.713525e-03
epoch [14/25][2000/4762]	time 0.143 (0.152)	data 0.001 (0.001)	eta 2:19:36	loss 0.4482 (0.3719)	loss_x 0.4424 (0.3621)	loss_u 0.0058 (0.0098)	acc_x 81.2500 (87.2438)	lr 2.713525e-03
epoch [14/25][2100/4762]	time 0.137 (0.152)	data 0.001 (0.001)	eta 2:19:24	loss 0.2593 (0.3729)	loss_x 0.2396 (0.3631)	loss_u 0.0197 (0.0098)	acc_x 90.6250 (87.1935)	lr 2.713525e-03
epoch [14/25][2200/4762]	time 0.139 (0.152)	data 0.001 (0.001)	eta 2:19:12	loss 0.6269 (0.3730)	loss_x 0.6048 (0.3633)	loss_u 0.0221 (0.0097)	acc_x 81.2500 (87.1832)	lr 2.713525e-03
epoch [14/25][2300/4762]	time 0.189 (0.152)	data 0.001 (0.001)	eta 2:19:02	loss 0.7326 (0.3732)	loss_x 0.7190 (0.3634)	loss_u 0.0136 (0.0098)	acc_x 78.1250 (87.2065)	lr 2.713525e-03
epoch [14/25][2400/4762]	time 0.151 (0.152)	data 0.001 (0.001)	eta 2:18:50	loss 0.4498 (0.3737)	loss_x 0.4459 (0.3638)	loss_u 0.0040 (0.0098)	acc_x 87.5000 (87.1927)	lr 2.713525e-03
epoch [14/25][2500/4762]	time 0.137 (0.152)	data 0.001 (0.001)	eta 2:18:37	loss 0.5332 (0.3746)	loss_x 0.5306 (0.3647)	loss_u 0.0025 (0.0098)	acc_x 81.2500 (87.1637)	lr 2.713525e-03
epoch [14/25][2600/4762]	time 0.166 (0.152)	data 0.001 (0.001)	eta 2:18:27	loss 0.3145 (0.3737)	loss_x 0.3026 (0.3637)	loss_u 0.0119 (0.0100)	acc_x 93.7500 (87.2200)	lr 2.713525e-03
epoch [14/25][2700/4762]	time 0.137 (0.152)	data 0.001 (0.001)	eta 2:18:13	loss 0.2259 (0.3740)	loss_x 0.2216 (0.3640)	loss_u 0.0043 (0.0099)	acc_x 93.7500 (87.1991)	lr 2.713525e-03
epoch [14/25][2800/4762]	time 0.138 (0.152)	data 0.001 (0.001)	eta 2:17:57	loss 0.3622 (0.3737)	loss_x 0.3614 (0.3637)	loss_u 0.0009 (0.0100)	acc_x 87.5000 (87.2109)	lr 2.713525e-03
epoch [14/25][2900/4762]	time 0.136 (0.152)	data 0.001 (0.001)	eta 2:17:40	loss 0.4889 (0.3736)	loss_x 0.4591 (0.3635)	loss_u 0.0298 (0.0100)	acc_x 87.5000 (87.2188)	lr 2.713525e-03
epoch [14/25][3000/4762]	time 0.139 (0.152)	data 0.000 (0.001)	eta 2:17:21	loss 0.4183 (0.3736)	loss_x 0.4121 (0.3635)	loss_u 0.0061 (0.0101)	acc_x 84.3750 (87.2260)	lr 2.713525e-03
epoch [14/25][3100/4762]	time 0.148 (0.152)	data 0.001 (0.001)	eta 2:17:02	loss 0.2606 (0.3737)	loss_x 0.2490 (0.3636)	loss_u 0.0116 (0.0101)	acc_x 93.7500 (87.2208)	lr 2.713525e-03
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,668
* accuracy: 84.26%
* error: 15.74%
* macro_f1: 84.27%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,575	acc: 98.05%
* class: 1 (bicycle)	total: 3,475	correct: 2,892	acc: 83.22%
* class: 2 (bus)	total: 4,690	correct: 4,266	acc: 90.96%
* class: 3 (car)	total: 10,401	correct: 7,745	acc: 74.46%
* class: 4 (horse)	total: 4,691	correct: 4,568	acc: 97.38%
* class: 5 (knife)	total: 2,075	correct: 1,855	acc: 89.40%
* class: 6 (motorcycle)	total: 5,796	correct: 5,522	acc: 95.27%
* class: 7 (person)	total: 4,000	correct: 2,917	acc: 72.92%
* class: 8 (plant)	total: 4,549	correct: 3,916	acc: 86.08%
* class: 9 (skateboard)	total: 2,281	correct: 2,072	acc: 90.84%
* class: 10 (train)	total: 4,236	correct: 3,902	acc: 92.12%
* class: 11 (truck)	total: 5,548	correct: 3,438	acc: 61.97%
* average: 86.06%
epoch [14/25][3200/4762]	time 0.149 (0.152)	data 0.001 (0.001)	eta 2:16:43	loss 0.4938 (0.3735)	loss_x 0.4919 (0.3634)	loss_u 0.0019 (0.0101)	acc_x 84.3750 (87.2236)	lr 2.713525e-03
epoch [14/25][3300/4762]	time 0.147 (0.152)	data 0.001 (0.001)	eta 2:16:31	loss 0.4574 (0.3731)	loss_x 0.4548 (0.3630)	loss_u 0.0025 (0.0101)	acc_x 81.2500 (87.2424)	lr 2.713525e-03
epoch [14/25][3400/4762]	time 0.150 (0.152)	data 0.001 (0.001)	eta 2:16:13	loss 0.2105 (0.3735)	loss_x 0.1988 (0.3635)	loss_u 0.0116 (0.0100)	acc_x 93.7500 (87.2270)	lr 2.713525e-03
epoch [14/25][3500/4762]	time 0.143 (0.152)	data 0.001 (0.001)	eta 2:16:10	loss 0.3790 (0.3738)	loss_x 0.3533 (0.3638)	loss_u 0.0256 (0.0100)	acc_x 84.3750 (87.1929)	lr 2.713525e-03
epoch [14/25][3600/4762]	time 0.142 (0.152)	data 0.001 (0.001)	eta 2:16:00	loss 0.4496 (0.3739)	loss_x 0.4235 (0.3639)	loss_u 0.0261 (0.0100)	acc_x 81.2500 (87.2031)	lr 2.713525e-03
epoch [14/25][3700/4762]	time 0.149 (0.152)	data 0.001 (0.001)	eta 2:15:48	loss 0.2979 (0.3733)	loss_x 0.2974 (0.3633)	loss_u 0.0005 (0.0100)	acc_x 90.6250 (87.2289)	lr 2.713525e-03
epoch [14/25][3800/4762]	time 0.160 (0.153)	data 0.001 (0.001)	eta 2:15:45	loss 0.3231 (0.3729)	loss_x 0.3190 (0.3629)	loss_u 0.0041 (0.0100)	acc_x 87.5000 (87.2442)	lr 2.713525e-03
epoch [14/25][3900/4762]	time 0.186 (0.153)	data 0.001 (0.001)	eta 2:15:35	loss 0.6642 (0.3727)	loss_x 0.6618 (0.3628)	loss_u 0.0024 (0.0100)	acc_x 78.1250 (87.2596)	lr 2.713525e-03
epoch [14/25][4000/4762]	time 0.155 (0.153)	data 0.001 (0.001)	eta 2:15:24	loss 0.4039 (0.3731)	loss_x 0.4020 (0.3632)	loss_u 0.0019 (0.0100)	acc_x 90.6250 (87.2500)	lr 2.713525e-03
epoch [14/25][4100/4762]	time 0.149 (0.153)	data 0.001 (0.001)	eta 2:15:09	loss 0.2841 (0.3728)	loss_x 0.2717 (0.3629)	loss_u 0.0124 (0.0099)	acc_x 93.7500 (87.2713)	lr 2.713525e-03
epoch [14/25][4200/4762]	time 0.140 (0.153)	data 0.001 (0.001)	eta 2:14:53	loss 0.4332 (0.3728)	loss_x 0.4294 (0.3629)	loss_u 0.0038 (0.0099)	acc_x 90.6250 (87.2842)	lr 2.713525e-03
epoch [14/25][4300/4762]	time 0.138 (0.153)	data 0.001 (0.001)	eta 2:14:37	loss 0.1941 (0.3729)	loss_x 0.1910 (0.3629)	loss_u 0.0031 (0.0099)	acc_x 93.7500 (87.2863)	lr 2.713525e-03
epoch [14/25][4400/4762]	time 0.152 (0.153)	data 0.001 (0.001)	eta 2:14:21	loss 0.3828 (0.3727)	loss_x 0.3768 (0.3628)	loss_u 0.0061 (0.0099)	acc_x 87.5000 (87.2891)	lr 2.713525e-03
epoch [14/25][4500/4762]	time 0.136 (0.153)	data 0.001 (0.001)	eta 2:14:07	loss 0.4371 (0.3722)	loss_x 0.4262 (0.3623)	loss_u 0.0109 (0.0099)	acc_x 87.5000 (87.3118)	lr 2.713525e-03
epoch [14/25][4600/4762]	time 0.142 (0.153)	data 0.001 (0.001)	eta 2:13:50	loss 0.3226 (0.3720)	loss_x 0.3079 (0.3620)	loss_u 0.0147 (0.0099)	acc_x 90.6250 (87.3118)	lr 2.713525e-03
epoch [14/25][4700/4762]	time 0.174 (0.153)	data 0.001 (0.001)	eta 2:13:38	loss 0.2577 (0.3722)	loss_x 0.2373 (0.3623)	loss_u 0.0203 (0.0099)	acc_x 90.6250 (87.2959)	lr 2.713525e-03
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,889
* accuracy: 84.66%
* error: 15.34%
* macro_f1: 84.75%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,580	acc: 98.19%
* class: 1 (bicycle)	total: 3,475	correct: 2,930	acc: 84.32%
* class: 2 (bus)	total: 4,690	correct: 4,237	acc: 90.34%
* class: 3 (car)	total: 10,401	correct: 7,818	acc: 75.17%
* class: 4 (horse)	total: 4,691	correct: 4,585	acc: 97.74%
* class: 5 (knife)	total: 2,075	correct: 1,867	acc: 89.98%
* class: 6 (motorcycle)	total: 5,796	correct: 5,533	acc: 95.46%
* class: 7 (person)	total: 4,000	correct: 2,913	acc: 72.83%
* class: 8 (plant)	total: 4,549	correct: 3,975	acc: 87.38%
* class: 9 (skateboard)	total: 2,281	correct: 2,060	acc: 90.31%
* class: 10 (train)	total: 4,236	correct: 3,937	acc: 92.94%
* class: 11 (truck)	total: 5,548	correct: 3,454	acc: 62.26%
* average: 86.41%
epoch [15/25][100/4762]	time 0.157 (0.156)	data 0.001 (0.003)	eta 2:15:34	loss 0.4049 (0.3675)	loss_x 0.4025 (0.3585)	loss_u 0.0023 (0.0089)	acc_x 90.6250 (87.6250)	lr 6.962598e-04
epoch [15/25][200/4762]	time 0.174 (0.154)	data 0.001 (0.002)	eta 2:14:07	loss 0.2228 (0.3740)	loss_x 0.2052 (0.3652)	loss_u 0.0176 (0.0087)	acc_x 90.6250 (87.1719)	lr 6.962598e-04
epoch [15/25][300/4762]	time 0.166 (0.154)	data 0.000 (0.002)	eta 2:13:45	loss 0.2647 (0.3765)	loss_x 0.2560 (0.3679)	loss_u 0.0087 (0.0085)	acc_x 90.6250 (87.0208)	lr 6.962598e-04
epoch [15/25][400/4762]	time 0.153 (0.153)	data 0.001 (0.001)	eta 2:12:55	loss 0.2312 (0.3669)	loss_x 0.2288 (0.3582)	loss_u 0.0024 (0.0087)	acc_x 90.6250 (87.4062)	lr 6.962598e-04
epoch [15/25][500/4762]	time 0.179 (0.154)	data 0.001 (0.001)	eta 2:13:22	loss 0.4416 (0.3640)	loss_x 0.4346 (0.3554)	loss_u 0.0069 (0.0086)	acc_x 90.6250 (87.5438)	lr 6.962598e-04
epoch [15/25][600/4762]	time 0.145 (0.154)	data 0.001 (0.001)	eta 2:13:12	loss 0.4993 (0.3641)	loss_x 0.4867 (0.3552)	loss_u 0.0125 (0.0090)	acc_x 78.1250 (87.4583)	lr 6.962598e-04
epoch [15/25][700/4762]	time 0.206 (0.155)	data 0.001 (0.001)	eta 2:13:13	loss 0.3519 (0.3637)	loss_x 0.3289 (0.3544)	loss_u 0.0229 (0.0093)	acc_x 87.5000 (87.5000)	lr 6.962598e-04
epoch [15/25][800/4762]	time 0.176 (0.156)	data 0.001 (0.001)	eta 2:14:11	loss 0.4390 (0.3651)	loss_x 0.4304 (0.3559)	loss_u 0.0086 (0.0092)	acc_x 84.3750 (87.3906)	lr 6.962598e-04
epoch [15/25][900/4762]	time 0.141 (0.157)	data 0.001 (0.001)	eta 2:14:38	loss 0.3241 (0.3655)	loss_x 0.3212 (0.3563)	loss_u 0.0029 (0.0092)	acc_x 93.7500 (87.4271)	lr 6.962598e-04
epoch [15/25][1000/4762]	time 0.141 (0.156)	data 0.001 (0.001)	eta 2:13:46	loss 0.2132 (0.3645)	loss_x 0.2046 (0.3552)	loss_u 0.0086 (0.0093)	acc_x 96.8750 (87.4938)	lr 6.962598e-04
epoch [15/25][1100/4762]	time 0.159 (0.156)	data 0.001 (0.001)	eta 2:13:24	loss 0.3808 (0.3650)	loss_x 0.3572 (0.3556)	loss_u 0.0236 (0.0095)	acc_x 90.6250 (87.5028)	lr 6.962598e-04
epoch [15/25][1200/4762]	time 0.143 (0.156)	data 0.002 (0.001)	eta 2:13:06	loss 0.6147 (0.3667)	loss_x 0.6028 (0.3571)	loss_u 0.0118 (0.0095)	acc_x 78.1250 (87.4219)	lr 6.962598e-04
epoch [15/25][1300/4762]	time 0.138 (0.156)	data 0.001 (0.001)	eta 2:12:41	loss 0.3283 (0.3647)	loss_x 0.3168 (0.3550)	loss_u 0.0115 (0.0097)	acc_x 87.5000 (87.4760)	lr 6.962598e-04
epoch [15/25][1400/4762]	time 0.141 (0.156)	data 0.001 (0.001)	eta 2:12:16	loss 0.6021 (0.3652)	loss_x 0.5994 (0.3555)	loss_u 0.0027 (0.0097)	acc_x 81.2500 (87.4777)	lr 6.962598e-04
epoch [15/25][1500/4762]	time 0.137 (0.155)	data 0.001 (0.001)	eta 2:11:49	loss 0.3187 (0.3664)	loss_x 0.3143 (0.3567)	loss_u 0.0044 (0.0097)	acc_x 93.7500 (87.4562)	lr 6.962598e-04
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,760
* accuracy: 84.42%
* error: 15.58%
* macro_f1: 84.45%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,585	acc: 98.33%
* class: 1 (bicycle)	total: 3,475	correct: 2,903	acc: 83.54%
* class: 2 (bus)	total: 4,690	correct: 4,260	acc: 90.83%
* class: 3 (car)	total: 10,401	correct: 7,903	acc: 75.98%
* class: 4 (horse)	total: 4,691	correct: 4,581	acc: 97.66%
* class: 5 (knife)	total: 2,075	correct: 1,906	acc: 91.86%
* class: 6 (motorcycle)	total: 5,796	correct: 5,518	acc: 95.20%
* class: 7 (person)	total: 4,000	correct: 2,907	acc: 72.67%
* class: 8 (plant)	total: 4,549	correct: 3,939	acc: 86.59%
* class: 9 (skateboard)	total: 2,281	correct: 2,041	acc: 89.48%
* class: 10 (train)	total: 4,236	correct: 3,950	acc: 93.25%
* class: 11 (truck)	total: 5,548	correct: 3,267	acc: 58.89%
* average: 86.19%
epoch [15/25][1600/4762]	time 0.149 (0.155)	data 0.001 (0.001)	eta 2:11:17	loss 0.1855 (0.3660)	loss_x 0.1638 (0.3563)	loss_u 0.0217 (0.0097)	acc_x 100.0000 (87.4609)	lr 6.962598e-04
epoch [15/25][1700/4762]	time 0.183 (0.155)	data 0.001 (0.001)	eta 2:10:48	loss 0.4830 (0.3664)	loss_x 0.4750 (0.3568)	loss_u 0.0080 (0.0096)	acc_x 81.2500 (87.4393)	lr 6.962598e-04
epoch [15/25][1800/4762]	time 0.209 (0.155)	data 0.001 (0.001)	eta 2:10:40	loss 0.3001 (0.3665)	loss_x 0.2899 (0.3569)	loss_u 0.0102 (0.0096)	acc_x 90.6250 (87.4323)	lr 6.962598e-04
epoch [15/25][1900/4762]	time 0.144 (0.155)	data 0.001 (0.001)	eta 2:10:21	loss 0.3290 (0.3669)	loss_x 0.3239 (0.3572)	loss_u 0.0051 (0.0096)	acc_x 87.5000 (87.4112)	lr 6.962598e-04
epoch [15/25][2000/4762]	time 0.147 (0.155)	data 0.001 (0.001)	eta 2:10:04	loss 0.5742 (0.3677)	loss_x 0.5572 (0.3581)	loss_u 0.0170 (0.0095)	acc_x 84.3750 (87.3922)	lr 6.962598e-04
epoch [15/25][2100/4762]	time 0.142 (0.155)	data 0.001 (0.001)	eta 2:09:42	loss 0.3416 (0.3672)	loss_x 0.3394 (0.3577)	loss_u 0.0022 (0.0095)	acc_x 87.5000 (87.4241)	lr 6.962598e-04
epoch [15/25][2200/4762]	time 0.146 (0.155)	data 0.001 (0.001)	eta 2:09:26	loss 0.3776 (0.3679)	loss_x 0.3761 (0.3584)	loss_u 0.0016 (0.0096)	acc_x 93.7500 (87.4261)	lr 6.962598e-04
epoch [15/25][2300/4762]	time 0.154 (0.155)	data 0.001 (0.001)	eta 2:09:11	loss 0.3567 (0.3675)	loss_x 0.3558 (0.3580)	loss_u 0.0008 (0.0095)	acc_x 93.7500 (87.4361)	lr 6.962598e-04
epoch [15/25][2400/4762]	time 0.142 (0.155)	data 0.001 (0.001)	eta 2:08:54	loss 0.5756 (0.3676)	loss_x 0.5601 (0.3581)	loss_u 0.0155 (0.0095)	acc_x 81.2500 (87.4362)	lr 6.962598e-04
epoch [15/25][2500/4762]	time 0.154 (0.155)	data 0.001 (0.001)	eta 2:08:49	loss 0.2395 (0.3684)	loss_x 0.2387 (0.3587)	loss_u 0.0008 (0.0096)	acc_x 90.6250 (87.4100)	lr 6.962598e-04
epoch [15/25][2600/4762]	time 0.147 (0.155)	data 0.001 (0.001)	eta 2:08:32	loss 0.1408 (0.3686)	loss_x 0.1379 (0.3589)	loss_u 0.0029 (0.0096)	acc_x 100.0000 (87.4038)	lr 6.962598e-04
epoch [15/25][2700/4762]	time 0.153 (0.155)	data 0.001 (0.001)	eta 2:08:09	loss 0.2969 (0.3682)	loss_x 0.2879 (0.3586)	loss_u 0.0090 (0.0096)	acc_x 93.7500 (87.4236)	lr 6.962598e-04
epoch [15/25][2800/4762]	time 0.154 (0.155)	data 0.001 (0.001)	eta 2:07:52	loss 0.2602 (0.3682)	loss_x 0.2591 (0.3584)	loss_u 0.0011 (0.0097)	acc_x 90.6250 (87.4163)	lr 6.962598e-04
epoch [15/25][2900/4762]	time 0.139 (0.155)	data 0.001 (0.001)	eta 2:07:39	loss 0.2045 (0.3693)	loss_x 0.1999 (0.3595)	loss_u 0.0046 (0.0098)	acc_x 93.7500 (87.3815)	lr 6.962598e-04
epoch [15/25][3000/4762]	time 0.164 (0.155)	data 0.001 (0.001)	eta 2:07:24	loss 0.3040 (0.3694)	loss_x 0.2707 (0.3596)	loss_u 0.0333 (0.0098)	acc_x 96.8750 (87.3844)	lr 6.962598e-04
epoch [15/25][3100/4762]	time 0.164 (0.155)	data 0.001 (0.001)	eta 2:07:11	loss 0.4927 (0.3692)	loss_x 0.4924 (0.3595)	loss_u 0.0003 (0.0098)	acc_x 87.5000 (87.4022)	lr 6.962598e-04
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,848
* accuracy: 84.58%
* error: 15.42%
* macro_f1: 84.85%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,589	acc: 98.44%
* class: 1 (bicycle)	total: 3,475	correct: 2,905	acc: 83.60%
* class: 2 (bus)	total: 4,690	correct: 4,246	acc: 90.53%
* class: 3 (car)	total: 10,401	correct: 7,721	acc: 74.23%
* class: 4 (horse)	total: 4,691	correct: 4,554	acc: 97.08%
* class: 5 (knife)	total: 2,075	correct: 1,877	acc: 90.46%
* class: 6 (motorcycle)	total: 5,796	correct: 5,542	acc: 95.62%
* class: 7 (person)	total: 4,000	correct: 3,059	acc: 76.47%
* class: 8 (plant)	total: 4,549	correct: 3,941	acc: 86.63%
* class: 9 (skateboard)	total: 2,281	correct: 2,038	acc: 89.35%
* class: 10 (train)	total: 4,236	correct: 3,949	acc: 93.22%
* class: 11 (truck)	total: 5,548	correct: 3,427	acc: 61.77%
* average: 86.45%
epoch [15/25][3200/4762]	time 0.146 (0.155)	data 0.001 (0.001)	eta 2:06:50	loss 0.3071 (0.3693)	loss_x 0.2943 (0.3595)	loss_u 0.0128 (0.0098)	acc_x 90.6250 (87.3867)	lr 6.962598e-04
epoch [15/25][3300/4762]	time 0.141 (0.155)	data 0.001 (0.001)	eta 2:06:33	loss 0.3665 (0.3697)	loss_x 0.3651 (0.3600)	loss_u 0.0013 (0.0097)	acc_x 90.6250 (87.3655)	lr 6.962598e-04
epoch [15/25][3400/4762]	time 0.143 (0.155)	data 0.001 (0.001)	eta 2:06:19	loss 0.4157 (0.3697)	loss_x 0.4100 (0.3600)	loss_u 0.0056 (0.0098)	acc_x 87.5000 (87.3585)	lr 6.962598e-04
epoch [15/25][3500/4762]	time 0.141 (0.155)	data 0.001 (0.001)	eta 2:06:06	loss 0.0947 (0.3697)	loss_x 0.0936 (0.3599)	loss_u 0.0011 (0.0097)	acc_x 100.0000 (87.3536)	lr 6.962598e-04
epoch [15/25][3600/4762]	time 0.145 (0.155)	data 0.001 (0.001)	eta 2:05:45	loss 0.5174 (0.3702)	loss_x 0.5126 (0.3605)	loss_u 0.0048 (0.0098)	acc_x 81.2500 (87.3255)	lr 6.962598e-04
epoch [15/25][3700/4762]	time 0.153 (0.155)	data 0.001 (0.001)	eta 2:05:32	loss 0.1207 (0.3707)	loss_x 0.1173 (0.3609)	loss_u 0.0034 (0.0098)	acc_x 96.8750 (87.3041)	lr 6.962598e-04
epoch [15/25][3800/4762]	time 0.137 (0.155)	data 0.001 (0.001)	eta 2:05:13	loss 0.1840 (0.3705)	loss_x 0.1696 (0.3608)	loss_u 0.0144 (0.0097)	acc_x 100.0000 (87.3059)	lr 6.962598e-04
epoch [15/25][3900/4762]	time 0.150 (0.155)	data 0.001 (0.001)	eta 2:05:02	loss 0.1859 (0.3706)	loss_x 0.1722 (0.3609)	loss_u 0.0137 (0.0097)	acc_x 96.8750 (87.3101)	lr 6.962598e-04
epoch [15/25][4000/4762]	time 0.177 (0.155)	data 0.001 (0.001)	eta 2:04:51	loss 0.7205 (0.3699)	loss_x 0.7169 (0.3602)	loss_u 0.0036 (0.0097)	acc_x 75.0000 (87.3242)	lr 6.962598e-04
epoch [15/25][4100/4762]	time 0.150 (0.155)	data 0.001 (0.001)	eta 2:04:47	loss 0.2853 (0.3696)	loss_x 0.2813 (0.3599)	loss_u 0.0040 (0.0097)	acc_x 87.5000 (87.3407)	lr 6.962598e-04
epoch [15/25][4200/4762]	time 0.157 (0.155)	data 0.001 (0.001)	eta 2:04:37	loss 0.6747 (0.3700)	loss_x 0.6736 (0.3604)	loss_u 0.0011 (0.0097)	acc_x 78.1250 (87.3185)	lr 6.962598e-04
epoch [15/25][4300/4762]	time 0.147 (0.155)	data 0.001 (0.001)	eta 2:04:20	loss 0.3492 (0.3706)	loss_x 0.3446 (0.3610)	loss_u 0.0046 (0.0096)	acc_x 81.2500 (87.3016)	lr 6.962598e-04
epoch [15/25][4400/4762]	time 0.138 (0.155)	data 0.001 (0.001)	eta 2:04:02	loss 0.4103 (0.3707)	loss_x 0.4001 (0.3610)	loss_u 0.0103 (0.0097)	acc_x 87.5000 (87.2955)	lr 6.962598e-04
epoch [15/25][4500/4762]	time 0.171 (0.155)	data 0.001 (0.001)	eta 2:03:48	loss 0.1588 (0.3705)	loss_x 0.1582 (0.3608)	loss_u 0.0005 (0.0097)	acc_x 96.8750 (87.3076)	lr 6.962598e-04
epoch [15/25][4600/4762]	time 0.148 (0.155)	data 0.001 (0.001)	eta 2:03:32	loss 0.3671 (0.3707)	loss_x 0.3587 (0.3609)	loss_u 0.0084 (0.0097)	acc_x 81.2500 (87.2948)	lr 6.962598e-04
epoch [15/25][4700/4762]	time 0.141 (0.155)	data 0.001 (0.001)	eta 2:03:12	loss 0.1415 (0.3710)	loss_x 0.1260 (0.3612)	loss_u 0.0155 (0.0098)	acc_x 96.8750 (87.2945)	lr 6.962598e-04
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,606
* accuracy: 84.14%
* error: 15.86%
* macro_f1: 84.45%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,587	acc: 98.38%
* class: 1 (bicycle)	total: 3,475	correct: 2,950	acc: 84.89%
* class: 2 (bus)	total: 4,690	correct: 4,303	acc: 91.75%
* class: 3 (car)	total: 10,401	correct: 7,581	acc: 72.89%
* class: 4 (horse)	total: 4,691	correct: 4,575	acc: 97.53%
* class: 5 (knife)	total: 2,075	correct: 1,876	acc: 90.41%
* class: 6 (motorcycle)	total: 5,796	correct: 5,504	acc: 94.96%
* class: 7 (person)	total: 4,000	correct: 3,074	acc: 76.85%
* class: 8 (plant)	total: 4,549	correct: 3,856	acc: 84.77%
* class: 9 (skateboard)	total: 2,281	correct: 2,047	acc: 89.74%
* class: 10 (train)	total: 4,236	correct: 3,901	acc: 92.09%
* class: 11 (truck)	total: 5,548	correct: 3,352	acc: 60.42%
* average: 86.22%
epoch [16/25][100/4762]	time 0.142 (0.154)	data 0.001 (0.003)	eta 2:02:05	loss 0.2853 (0.3540)	loss_x 0.2809 (0.3438)	loss_u 0.0045 (0.0103)	acc_x 87.5000 (88.1250)	lr 1.855400e-04
epoch [16/25][200/4762]	time 0.142 (0.154)	data 0.001 (0.002)	eta 2:01:57	loss 0.5277 (0.3613)	loss_x 0.5267 (0.3510)	loss_u 0.0009 (0.0103)	acc_x 75.0000 (87.8281)	lr 1.855400e-04
epoch [16/25][300/4762]	time 0.148 (0.153)	data 0.001 (0.002)	eta 2:00:47	loss 0.3606 (0.3704)	loss_x 0.3544 (0.3608)	loss_u 0.0062 (0.0096)	acc_x 87.5000 (87.3438)	lr 1.855400e-04
epoch [16/25][400/4762]	time 0.156 (0.152)	data 0.001 (0.001)	eta 1:59:52	loss 0.2283 (0.3731)	loss_x 0.2252 (0.3635)	loss_u 0.0031 (0.0096)	acc_x 96.8750 (87.3203)	lr 1.855400e-04
epoch [16/25][500/4762]	time 0.148 (0.153)	data 0.001 (0.001)	eta 1:59:48	loss 0.1949 (0.3716)	loss_x 0.1272 (0.3615)	loss_u 0.0677 (0.0101)	acc_x 96.8750 (87.4313)	lr 1.855400e-04
epoch [16/25][600/4762]	time 0.161 (0.153)	data 0.001 (0.001)	eta 1:59:44	loss 0.3768 (0.3744)	loss_x 0.3762 (0.3644)	loss_u 0.0006 (0.0100)	acc_x 84.3750 (87.4531)	lr 1.855400e-04
epoch [16/25][700/4762]	time 0.151 (0.154)	data 0.001 (0.001)	eta 2:00:12	loss 0.3196 (0.3754)	loss_x 0.3089 (0.3654)	loss_u 0.0107 (0.0100)	acc_x 93.7500 (87.4107)	lr 1.855400e-04
epoch [16/25][800/4762]	time 0.145 (0.154)	data 0.001 (0.001)	eta 2:00:00	loss 0.2573 (0.3753)	loss_x 0.2554 (0.3654)	loss_u 0.0019 (0.0100)	acc_x 87.5000 (87.4414)	lr 1.855400e-04
epoch [16/25][900/4762]	time 0.148 (0.154)	data 0.001 (0.001)	eta 2:00:08	loss 0.5155 (0.3738)	loss_x 0.4980 (0.3639)	loss_u 0.0176 (0.0099)	acc_x 81.2500 (87.4236)	lr 1.855400e-04
epoch [16/25][1000/4762]	time 0.143 (0.155)	data 0.001 (0.001)	eta 2:00:18	loss 0.3309 (0.3734)	loss_x 0.3270 (0.3633)	loss_u 0.0039 (0.0101)	acc_x 84.3750 (87.4000)	lr 1.855400e-04
epoch [16/25][1100/4762]	time 0.161 (0.155)	data 0.001 (0.001)	eta 2:00:06	loss 0.2381 (0.3739)	loss_x 0.1935 (0.3639)	loss_u 0.0445 (0.0100)	acc_x 93.7500 (87.3267)	lr 1.855400e-04
epoch [16/25][1200/4762]	time 0.168 (0.155)	data 0.001 (0.001)	eta 1:59:49	loss 0.3184 (0.3737)	loss_x 0.3170 (0.3636)	loss_u 0.0014 (0.0101)	acc_x 90.6250 (87.3490)	lr 1.855400e-04
epoch [16/25][1300/4762]	time 0.138 (0.155)	data 0.001 (0.001)	eta 1:59:36	loss 0.4963 (0.3741)	loss_x 0.4784 (0.3640)	loss_u 0.0179 (0.0101)	acc_x 78.1250 (87.3101)	lr 1.855400e-04
epoch [16/25][1400/4762]	time 0.182 (0.155)	data 0.001 (0.001)	eta 1:59:29	loss 0.3737 (0.3735)	loss_x 0.3733 (0.3633)	loss_u 0.0005 (0.0101)	acc_x 78.1250 (87.3058)	lr 1.855400e-04
epoch [16/25][1500/4762]	time 0.164 (0.155)	data 0.000 (0.001)	eta 1:59:20	loss 0.3882 (0.3737)	loss_x 0.3872 (0.3637)	loss_u 0.0010 (0.0100)	acc_x 90.6250 (87.3354)	lr 1.855400e-04
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,698
* accuracy: 84.31%
* error: 15.69%
* macro_f1: 84.48%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,582	acc: 98.24%
* class: 1 (bicycle)	total: 3,475	correct: 2,947	acc: 84.81%
* class: 2 (bus)	total: 4,690	correct: 4,274	acc: 91.13%
* class: 3 (car)	total: 10,401	correct: 7,653	acc: 73.58%
* class: 4 (horse)	total: 4,691	correct: 4,576	acc: 97.55%
* class: 5 (knife)	total: 2,075	correct: 1,821	acc: 87.76%
* class: 6 (motorcycle)	total: 5,796	correct: 5,505	acc: 94.98%
* class: 7 (person)	total: 4,000	correct: 3,029	acc: 75.72%
* class: 8 (plant)	total: 4,549	correct: 3,945	acc: 86.72%
* class: 9 (skateboard)	total: 2,281	correct: 2,078	acc: 91.10%
* class: 10 (train)	total: 4,236	correct: 3,920	acc: 92.54%
* class: 11 (truck)	total: 5,548	correct: 3,368	acc: 60.71%
* average: 86.24%
epoch [16/25][1600/4762]	time 0.170 (0.155)	data 0.001 (0.001)	eta 1:59:06	loss 0.1354 (0.3735)	loss_x 0.1338 (0.3634)	loss_u 0.0016 (0.0101)	acc_x 93.7500 (87.3223)	lr 1.855400e-04
epoch [16/25][1700/4762]	time 0.163 (0.155)	data 0.001 (0.001)	eta 1:58:37	loss 0.2654 (0.3732)	loss_x 0.2605 (0.3631)	loss_u 0.0048 (0.0101)	acc_x 84.3750 (87.3364)	lr 1.855400e-04
epoch [16/25][1800/4762]	time 0.138 (0.155)	data 0.001 (0.001)	eta 1:58:18	loss 0.7268 (0.3742)	loss_x 0.7237 (0.3640)	loss_u 0.0031 (0.0101)	acc_x 75.0000 (87.2882)	lr 1.855400e-04
epoch [16/25][1900/4762]	time 0.172 (0.155)	data 0.001 (0.001)	eta 1:57:44	loss 0.4070 (0.3735)	loss_x 0.3628 (0.3634)	loss_u 0.0443 (0.0101)	acc_x 84.3750 (87.2944)	lr 1.855400e-04
epoch [16/25][2000/4762]	time 0.139 (0.154)	data 0.001 (0.001)	eta 1:57:17	loss 0.1211 (0.3741)	loss_x 0.1077 (0.3640)	loss_u 0.0134 (0.0102)	acc_x 100.0000 (87.2797)	lr 1.855400e-04
epoch [16/25][2100/4762]	time 0.173 (0.154)	data 0.001 (0.001)	eta 1:56:47	loss 0.4994 (0.3745)	loss_x 0.4784 (0.3643)	loss_u 0.0210 (0.0102)	acc_x 84.3750 (87.2693)	lr 1.855400e-04
epoch [16/25][2200/4762]	time 0.179 (0.154)	data 0.002 (0.001)	eta 1:56:29	loss 0.4644 (0.3746)	loss_x 0.4597 (0.3644)	loss_u 0.0048 (0.0102)	acc_x 81.2500 (87.2429)	lr 1.855400e-04
epoch [16/25][2300/4762]	time 0.158 (0.154)	data 0.001 (0.001)	eta 1:56:18	loss 0.5191 (0.3740)	loss_x 0.5178 (0.3639)	loss_u 0.0013 (0.0101)	acc_x 81.2500 (87.2323)	lr 1.855400e-04
epoch [16/25][2400/4762]	time 0.147 (0.154)	data 0.001 (0.001)	eta 1:56:03	loss 0.4518 (0.3730)	loss_x 0.4332 (0.3629)	loss_u 0.0186 (0.0101)	acc_x 84.3750 (87.2734)	lr 1.855400e-04
epoch [16/25][2500/4762]	time 0.137 (0.154)	data 0.001 (0.001)	eta 1:55:52	loss 0.4152 (0.3735)	loss_x 0.4088 (0.3635)	loss_u 0.0065 (0.0100)	acc_x 84.3750 (87.2750)	lr 1.855400e-04
epoch [16/25][2600/4762]	time 0.149 (0.154)	data 0.001 (0.001)	eta 1:55:40	loss 0.4111 (0.3736)	loss_x 0.4071 (0.3636)	loss_u 0.0039 (0.0101)	acc_x 84.3750 (87.2716)	lr 1.855400e-04
epoch [16/25][2700/4762]	time 0.152 (0.154)	data 0.001 (0.001)	eta 1:55:24	loss 0.4423 (0.3735)	loss_x 0.4306 (0.3634)	loss_u 0.0116 (0.0101)	acc_x 81.2500 (87.2801)	lr 1.855400e-04
epoch [16/25][2800/4762]	time 0.138 (0.154)	data 0.001 (0.001)	eta 1:55:05	loss 0.5317 (0.3737)	loss_x 0.5266 (0.3636)	loss_u 0.0051 (0.0100)	acc_x 84.3750 (87.2533)	lr 1.855400e-04
epoch [16/25][2900/4762]	time 0.148 (0.154)	data 0.001 (0.001)	eta 1:54:51	loss 0.2172 (0.3735)	loss_x 0.2162 (0.3635)	loss_u 0.0010 (0.0100)	acc_x 93.7500 (87.2349)	lr 1.855400e-04
epoch [16/25][3000/4762]	time 0.181 (0.154)	data 0.001 (0.001)	eta 1:54:43	loss 0.2011 (0.3731)	loss_x 0.2007 (0.3632)	loss_u 0.0004 (0.0100)	acc_x 90.6250 (87.2500)	lr 1.855400e-04
epoch [16/25][3100/4762]	time 0.169 (0.155)	data 0.001 (0.001)	eta 1:54:38	loss 0.4296 (0.3728)	loss_x 0.4276 (0.3628)	loss_u 0.0020 (0.0100)	acc_x 81.2500 (87.2339)	lr 1.855400e-04
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,815
* accuracy: 84.52%
* error: 15.48%
* macro_f1: 84.70%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,585	acc: 98.33%
* class: 1 (bicycle)	total: 3,475	correct: 2,883	acc: 82.96%
* class: 2 (bus)	total: 4,690	correct: 4,283	acc: 91.32%
* class: 3 (car)	total: 10,401	correct: 7,908	acc: 76.03%
* class: 4 (horse)	total: 4,691	correct: 4,585	acc: 97.74%
* class: 5 (knife)	total: 2,075	correct: 1,914	acc: 92.24%
* class: 6 (motorcycle)	total: 5,796	correct: 5,506	acc: 95.00%
* class: 7 (person)	total: 4,000	correct: 2,986	acc: 74.65%
* class: 8 (plant)	total: 4,549	correct: 3,885	acc: 85.40%
* class: 9 (skateboard)	total: 2,281	correct: 2,027	acc: 88.86%
* class: 10 (train)	total: 4,236	correct: 3,909	acc: 92.28%
* class: 11 (truck)	total: 5,548	correct: 3,344	acc: 60.27%
* average: 86.26%
epoch [16/25][3200/4762]	time 0.163 (0.154)	data 0.001 (0.001)	eta 1:54:21	loss 0.1985 (0.3726)	loss_x 0.1970 (0.3627)	loss_u 0.0015 (0.0099)	acc_x 90.6250 (87.2402)	lr 1.855400e-04
epoch [16/25][3300/4762]	time 0.187 (0.155)	data 0.001 (0.001)	eta 1:54:09	loss 0.2307 (0.3723)	loss_x 0.2293 (0.3624)	loss_u 0.0014 (0.0099)	acc_x 90.6250 (87.2614)	lr 1.855400e-04
epoch [16/25][3400/4762]	time 0.141 (0.155)	data 0.001 (0.001)	eta 1:53:54	loss 0.1855 (0.3723)	loss_x 0.1841 (0.3624)	loss_u 0.0015 (0.0099)	acc_x 96.8750 (87.2776)	lr 1.855400e-04
epoch [16/25][3500/4762]	time 0.143 (0.155)	data 0.001 (0.001)	eta 1:53:42	loss 0.4152 (0.3728)	loss_x 0.4103 (0.3628)	loss_u 0.0049 (0.0100)	acc_x 90.6250 (87.2571)	lr 1.855400e-04
epoch [16/25][3600/4762]	time 0.160 (0.155)	data 0.001 (0.001)	eta 1:53:26	loss 0.3482 (0.3729)	loss_x 0.3398 (0.3629)	loss_u 0.0084 (0.0100)	acc_x 90.6250 (87.2569)	lr 1.855400e-04
epoch [16/25][3700/4762]	time 0.145 (0.155)	data 0.001 (0.001)	eta 1:53:09	loss 0.3910 (0.3728)	loss_x 0.3874 (0.3628)	loss_u 0.0036 (0.0100)	acc_x 84.3750 (87.2449)	lr 1.855400e-04
epoch [16/25][3800/4762]	time 0.148 (0.155)	data 0.001 (0.001)	eta 1:52:57	loss 0.5364 (0.3725)	loss_x 0.4797 (0.3625)	loss_u 0.0567 (0.0100)	acc_x 84.3750 (87.2664)	lr 1.855400e-04
epoch [16/25][3900/4762]	time 0.144 (0.155)	data 0.001 (0.001)	eta 1:52:47	loss 0.1238 (0.3718)	loss_x 0.1195 (0.3619)	loss_u 0.0043 (0.0099)	acc_x 93.7500 (87.2989)	lr 1.855400e-04
epoch [16/25][4000/4762]	time 0.181 (0.155)	data 0.001 (0.001)	eta 1:52:43	loss 0.4109 (0.3717)	loss_x 0.3456 (0.3618)	loss_u 0.0653 (0.0099)	acc_x 90.6250 (87.2914)	lr 1.855400e-04
epoch [16/25][4100/4762]	time 0.145 (0.155)	data 0.001 (0.001)	eta 1:52:38	loss 0.6872 (0.3718)	loss_x 0.6777 (0.3620)	loss_u 0.0094 (0.0099)	acc_x 78.1250 (87.2889)	lr 1.855400e-04
epoch [16/25][4200/4762]	time 0.149 (0.155)	data 0.001 (0.001)	eta 1:52:27	loss 0.3083 (0.3715)	loss_x 0.3058 (0.3616)	loss_u 0.0025 (0.0099)	acc_x 90.6250 (87.2991)	lr 1.855400e-04
epoch [16/25][4300/4762]	time 0.147 (0.156)	data 0.001 (0.001)	eta 1:52:19	loss 0.3187 (0.3716)	loss_x 0.3024 (0.3617)	loss_u 0.0163 (0.0099)	acc_x 90.6250 (87.2980)	lr 1.855400e-04
epoch [16/25][4400/4762]	time 0.166 (0.155)	data 0.001 (0.001)	eta 1:51:59	loss 0.3079 (0.3715)	loss_x 0.3042 (0.3616)	loss_u 0.0037 (0.0099)	acc_x 90.6250 (87.3004)	lr 1.855400e-04
epoch [16/25][4500/4762]	time 0.163 (0.155)	data 0.001 (0.001)	eta 1:51:44	loss 0.5888 (0.3717)	loss_x 0.5870 (0.3618)	loss_u 0.0018 (0.0099)	acc_x 75.0000 (87.2958)	lr 1.855400e-04
epoch [16/25][4600/4762]	time 0.172 (0.156)	data 0.001 (0.001)	eta 1:51:38	loss 0.4124 (0.3718)	loss_x 0.4040 (0.3619)	loss_u 0.0085 (0.0098)	acc_x 81.2500 (87.3057)	lr 1.855400e-04
epoch [16/25][4700/4762]	time 0.159 (0.156)	data 0.001 (0.001)	eta 1:51:24	loss 0.3584 (0.3719)	loss_x 0.3004 (0.3621)	loss_u 0.0579 (0.0098)	acc_x 84.3750 (87.2859)	lr 1.855400e-04
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,868
* accuracy: 84.62%
* error: 15.38%
* macro_f1: 84.64%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,583	acc: 98.27%
* class: 1 (bicycle)	total: 3,475	correct: 2,934	acc: 84.43%
* class: 2 (bus)	total: 4,690	correct: 4,236	acc: 90.32%
* class: 3 (car)	total: 10,401	correct: 7,899	acc: 75.94%
* class: 4 (horse)	total: 4,691	correct: 4,575	acc: 97.53%
* class: 5 (knife)	total: 2,075	correct: 1,888	acc: 90.99%
* class: 6 (motorcycle)	total: 5,796	correct: 5,529	acc: 95.39%
* class: 7 (person)	total: 4,000	correct: 2,921	acc: 73.03%
* class: 8 (plant)	total: 4,549	correct: 3,913	acc: 86.02%
* class: 9 (skateboard)	total: 2,281	correct: 2,043	acc: 89.57%
* class: 10 (train)	total: 4,236	correct: 3,947	acc: 93.18%
* class: 11 (truck)	total: 5,548	correct: 3,400	acc: 61.28%
* average: 86.33%
epoch [17/25][100/4762]	time 0.140 (0.155)	data 0.001 (0.003)	eta 1:50:40	loss 0.4387 (0.3859)	loss_x 0.4317 (0.3741)	loss_u 0.0070 (0.0118)	acc_x 81.2500 (86.5938)	lr 2.138669e-03
epoch [17/25][200/4762]	time 0.171 (0.154)	data 0.001 (0.002)	eta 1:49:37	loss 0.5689 (0.3777)	loss_x 0.5440 (0.3676)	loss_u 0.0250 (0.0100)	acc_x 78.1250 (86.7656)	lr 2.138669e-03
epoch [17/25][300/4762]	time 0.171 (0.153)	data 0.006 (0.002)	eta 1:48:50	loss 0.4559 (0.3649)	loss_x 0.4416 (0.3552)	loss_u 0.0143 (0.0097)	acc_x 87.5000 (87.2812)	lr 2.138669e-03
epoch [17/25][400/4762]	time 0.174 (0.154)	data 0.001 (0.002)	eta 1:48:39	loss 0.2353 (0.3715)	loss_x 0.2321 (0.3622)	loss_u 0.0032 (0.0093)	acc_x 93.7500 (87.0938)	lr 2.138669e-03
epoch [17/25][500/4762]	time 0.160 (0.153)	data 0.001 (0.001)	eta 1:48:21	loss 0.3260 (0.3755)	loss_x 0.3055 (0.3665)	loss_u 0.0205 (0.0089)	acc_x 87.5000 (86.9313)	lr 2.138669e-03
epoch [17/25][600/4762]	time 0.151 (0.154)	data 0.001 (0.001)	eta 1:48:08	loss 0.2653 (0.3726)	loss_x 0.2532 (0.3635)	loss_u 0.0122 (0.0090)	acc_x 87.5000 (87.2188)	lr 2.138669e-03
epoch [17/25][700/4762]	time 0.144 (0.154)	data 0.001 (0.001)	eta 1:48:09	loss 0.3301 (0.3698)	loss_x 0.3239 (0.3606)	loss_u 0.0063 (0.0091)	acc_x 84.3750 (87.3348)	lr 2.138669e-03
epoch [17/25][800/4762]	time 0.141 (0.154)	data 0.001 (0.001)	eta 1:47:54	loss 0.7600 (0.3673)	loss_x 0.7270 (0.3581)	loss_u 0.0330 (0.0091)	acc_x 75.0000 (87.4141)	lr 2.138669e-03
epoch [17/25][900/4762]	time 0.174 (0.154)	data 0.001 (0.001)	eta 1:47:56	loss 0.4324 (0.3662)	loss_x 0.4171 (0.3568)	loss_u 0.0152 (0.0094)	acc_x 87.5000 (87.4479)	lr 2.138669e-03
epoch [17/25][1000/4762]	time 0.169 (0.154)	data 0.001 (0.001)	eta 1:47:41	loss 0.2339 (0.3647)	loss_x 0.2103 (0.3552)	loss_u 0.0237 (0.0095)	acc_x 93.7500 (87.5031)	lr 2.138669e-03
epoch [17/25][1100/4762]	time 0.162 (0.154)	data 0.001 (0.001)	eta 1:47:30	loss 0.2111 (0.3674)	loss_x 0.1980 (0.3579)	loss_u 0.0131 (0.0095)	acc_x 93.7500 (87.3494)	lr 2.138669e-03
epoch [17/25][1200/4762]	time 0.141 (0.155)	data 0.001 (0.001)	eta 1:47:17	loss 0.6001 (0.3686)	loss_x 0.5945 (0.3590)	loss_u 0.0056 (0.0096)	acc_x 75.0000 (87.3099)	lr 2.138669e-03
epoch [17/25][1300/4762]	time 0.171 (0.154)	data 0.001 (0.001)	eta 1:46:50	loss 0.6117 (0.3699)	loss_x 0.6080 (0.3603)	loss_u 0.0037 (0.0096)	acc_x 75.0000 (87.3149)	lr 2.138669e-03
epoch [17/25][1400/4762]	time 0.166 (0.154)	data 0.001 (0.001)	eta 1:46:30	loss 0.2190 (0.3698)	loss_x 0.1921 (0.3602)	loss_u 0.0269 (0.0095)	acc_x 87.5000 (87.3348)	lr 2.138669e-03
epoch [17/25][1500/4762]	time 0.137 (0.154)	data 0.001 (0.001)	eta 1:46:24	loss 0.2397 (0.3698)	loss_x 0.2337 (0.3603)	loss_u 0.0059 (0.0095)	acc_x 87.5000 (87.3125)	lr 2.138669e-03
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,925
* accuracy: 84.72%
* error: 15.28%
* macro_f1: 84.92%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,584	acc: 98.30%
* class: 1 (bicycle)	total: 3,475	correct: 2,936	acc: 84.49%
* class: 2 (bus)	total: 4,690	correct: 4,262	acc: 90.87%
* class: 3 (car)	total: 10,401	correct: 7,827	acc: 75.25%
* class: 4 (horse)	total: 4,691	correct: 4,579	acc: 97.61%
* class: 5 (knife)	total: 2,075	correct: 1,863	acc: 89.78%
* class: 6 (motorcycle)	total: 5,796	correct: 5,520	acc: 95.24%
* class: 7 (person)	total: 4,000	correct: 3,014	acc: 75.35%
* class: 8 (plant)	total: 4,549	correct: 3,940	acc: 86.61%
* class: 9 (skateboard)	total: 2,281	correct: 2,063	acc: 90.44%
* class: 10 (train)	total: 4,236	correct: 3,944	acc: 93.11%
* class: 11 (truck)	total: 5,548	correct: 3,393	acc: 61.16%
* average: 86.52%
epoch [17/25][1600/4762]	time 0.136 (0.154)	data 0.000 (0.001)	eta 1:46:02	loss 0.6813 (0.3716)	loss_x 0.6780 (0.3622)	loss_u 0.0033 (0.0093)	acc_x 78.1250 (87.2363)	lr 2.138669e-03
epoch [17/25][1700/4762]	time 0.161 (0.154)	data 0.001 (0.001)	eta 1:45:33	loss 0.3342 (0.3712)	loss_x 0.3282 (0.3619)	loss_u 0.0060 (0.0093)	acc_x 84.3750 (87.2647)	lr 2.138669e-03
epoch [17/25][1800/4762]	time 0.138 (0.154)	data 0.001 (0.001)	eta 1:45:24	loss 0.2858 (0.3716)	loss_x 0.2787 (0.3623)	loss_u 0.0071 (0.0093)	acc_x 90.6250 (87.2309)	lr 2.138669e-03
epoch [17/25][1900/4762]	time 0.142 (0.154)	data 0.001 (0.001)	eta 1:45:09	loss 0.3711 (0.3722)	loss_x 0.3679 (0.3629)	loss_u 0.0032 (0.0093)	acc_x 84.3750 (87.1809)	lr 2.138669e-03
epoch [17/25][2000/4762]	time 0.154 (0.154)	data 0.001 (0.001)	eta 1:44:47	loss 0.4138 (0.3723)	loss_x 0.3920 (0.3630)	loss_u 0.0219 (0.0092)	acc_x 87.5000 (87.1891)	lr 2.138669e-03
epoch [17/25][2100/4762]	time 0.172 (0.154)	data 0.001 (0.001)	eta 1:44:28	loss 0.3720 (0.3724)	loss_x 0.3618 (0.3631)	loss_u 0.0102 (0.0093)	acc_x 84.3750 (87.1786)	lr 2.138669e-03
epoch [17/25][2200/4762]	time 0.139 (0.154)	data 0.001 (0.001)	eta 1:44:17	loss 0.1576 (0.3718)	loss_x 0.1291 (0.3625)	loss_u 0.0285 (0.0093)	acc_x 96.8750 (87.2017)	lr 2.138669e-03
epoch [17/25][2300/4762]	time 0.145 (0.154)	data 0.001 (0.001)	eta 1:44:01	loss 0.2116 (0.3719)	loss_x 0.2107 (0.3626)	loss_u 0.0009 (0.0093)	acc_x 96.8750 (87.1821)	lr 2.138669e-03
epoch [17/25][2400/4762]	time 0.159 (0.154)	data 0.004 (0.001)	eta 1:43:55	loss 0.1336 (0.3728)	loss_x 0.1303 (0.3635)	loss_u 0.0033 (0.0093)	acc_x 96.8750 (87.1484)	lr 2.138669e-03
epoch [17/25][2500/4762]	time 0.179 (0.154)	data 0.001 (0.001)	eta 1:43:46	loss 0.2232 (0.3728)	loss_x 0.1957 (0.3635)	loss_u 0.0276 (0.0093)	acc_x 96.8750 (87.1700)	lr 2.138669e-03
epoch [17/25][2600/4762]	time 0.139 (0.154)	data 0.001 (0.001)	eta 1:43:25	loss 0.6333 (0.3728)	loss_x 0.5955 (0.3634)	loss_u 0.0378 (0.0093)	acc_x 78.1250 (87.1755)	lr 2.138669e-03
epoch [17/25][2700/4762]	time 0.147 (0.154)	data 0.001 (0.001)	eta 1:43:07	loss 0.5295 (0.3737)	loss_x 0.5216 (0.3642)	loss_u 0.0079 (0.0095)	acc_x 75.0000 (87.1412)	lr 2.138669e-03
epoch [17/25][2800/4762]	time 0.144 (0.154)	data 0.001 (0.001)	eta 1:42:49	loss 0.2368 (0.3741)	loss_x 0.1922 (0.3646)	loss_u 0.0446 (0.0095)	acc_x 90.6250 (87.1083)	lr 2.138669e-03
epoch [17/25][2900/4762]	time 0.144 (0.154)	data 0.001 (0.001)	eta 1:42:26	loss 0.2507 (0.3739)	loss_x 0.2469 (0.3644)	loss_u 0.0038 (0.0095)	acc_x 96.8750 (87.1304)	lr 2.138669e-03
epoch [17/25][3000/4762]	time 0.140 (0.154)	data 0.001 (0.001)	eta 1:42:13	loss 0.3861 (0.3742)	loss_x 0.3756 (0.3647)	loss_u 0.0104 (0.0095)	acc_x 90.6250 (87.1094)	lr 2.138669e-03
epoch [17/25][3100/4762]	time 0.144 (0.154)	data 0.001 (0.001)	eta 1:42:00	loss 0.3587 (0.3744)	loss_x 0.3543 (0.3649)	loss_u 0.0043 (0.0095)	acc_x 87.5000 (87.0998)	lr 2.138669e-03
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,695
* accuracy: 84.31%
* error: 15.69%
* macro_f1: 84.44%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,591	acc: 98.49%
* class: 1 (bicycle)	total: 3,475	correct: 2,914	acc: 83.86%
* class: 2 (bus)	total: 4,690	correct: 4,308	acc: 91.86%
* class: 3 (car)	total: 10,401	correct: 7,717	acc: 74.19%
* class: 4 (horse)	total: 4,691	correct: 4,578	acc: 97.59%
* class: 5 (knife)	total: 2,075	correct: 1,847	acc: 89.01%
* class: 6 (motorcycle)	total: 5,796	correct: 5,506	acc: 95.00%
* class: 7 (person)	total: 4,000	correct: 2,931	acc: 73.28%
* class: 8 (plant)	total: 4,549	correct: 3,882	acc: 85.34%
* class: 9 (skateboard)	total: 2,281	correct: 2,080	acc: 91.19%
* class: 10 (train)	total: 4,236	correct: 3,900	acc: 92.07%
* class: 11 (truck)	total: 5,548	correct: 3,441	acc: 62.02%
* average: 86.16%
epoch [17/25][3200/4762]	time 0.164 (0.154)	data 0.001 (0.001)	eta 1:41:51	loss 0.2427 (0.3740)	loss_x 0.2408 (0.3645)	loss_u 0.0018 (0.0095)	acc_x 90.6250 (87.1104)	lr 2.138669e-03
epoch [17/25][3300/4762]	time 0.143 (0.154)	data 0.001 (0.001)	eta 1:41:31	loss 0.2161 (0.3745)	loss_x 0.2112 (0.3649)	loss_u 0.0050 (0.0096)	acc_x 87.5000 (87.0956)	lr 2.138669e-03
epoch [17/25][3400/4762]	time 0.137 (0.154)	data 0.001 (0.001)	eta 1:41:09	loss 0.3076 (0.3741)	loss_x 0.3037 (0.3645)	loss_u 0.0039 (0.0096)	acc_x 87.5000 (87.1029)	lr 2.138669e-03
epoch [17/25][3500/4762]	time 0.149 (0.154)	data 0.001 (0.001)	eta 1:40:54	loss 0.3728 (0.3737)	loss_x 0.3656 (0.3640)	loss_u 0.0072 (0.0096)	acc_x 87.5000 (87.1205)	lr 2.138669e-03
epoch [17/25][3600/4762]	time 0.166 (0.154)	data 0.001 (0.001)	eta 1:40:37	loss 0.5596 (0.3741)	loss_x 0.5479 (0.3645)	loss_u 0.0117 (0.0096)	acc_x 78.1250 (87.1024)	lr 2.138669e-03
epoch [17/25][3700/4762]	time 0.182 (0.154)	data 0.001 (0.001)	eta 1:40:21	loss 0.3010 (0.3736)	loss_x 0.3005 (0.3639)	loss_u 0.0005 (0.0097)	acc_x 87.5000 (87.1275)	lr 2.138669e-03
epoch [17/25][3800/4762]	time 0.155 (0.154)	data 0.001 (0.001)	eta 1:40:05	loss 0.4579 (0.3734)	loss_x 0.4421 (0.3637)	loss_u 0.0158 (0.0097)	acc_x 78.1250 (87.1373)	lr 2.138669e-03
epoch [17/25][3900/4762]	time 0.145 (0.154)	data 0.000 (0.001)	eta 1:39:47	loss 0.4276 (0.3729)	loss_x 0.4150 (0.3632)	loss_u 0.0126 (0.0097)	acc_x 81.2500 (87.1611)	lr 2.138669e-03
epoch [17/25][4000/4762]	time 0.136 (0.154)	data 0.001 (0.001)	eta 1:39:30	loss 0.3935 (0.3732)	loss_x 0.3843 (0.3635)	loss_u 0.0091 (0.0097)	acc_x 87.5000 (87.1570)	lr 2.138669e-03
epoch [17/25][4100/4762]	time 0.157 (0.154)	data 0.001 (0.001)	eta 1:39:17	loss 0.4936 (0.3735)	loss_x 0.4759 (0.3638)	loss_u 0.0177 (0.0097)	acc_x 87.5000 (87.1448)	lr 2.138669e-03
epoch [17/25][4200/4762]	time 0.161 (0.154)	data 0.001 (0.001)	eta 1:39:02	loss 0.4381 (0.3735)	loss_x 0.4353 (0.3638)	loss_u 0.0028 (0.0097)	acc_x 84.3750 (87.1362)	lr 2.138669e-03
epoch [17/25][4300/4762]	time 0.156 (0.154)	data 0.001 (0.001)	eta 1:38:49	loss 0.5233 (0.3733)	loss_x 0.5040 (0.3635)	loss_u 0.0194 (0.0098)	acc_x 84.3750 (87.1453)	lr 2.138669e-03
epoch [17/25][4400/4762]	time 0.141 (0.154)	data 0.001 (0.001)	eta 1:38:33	loss 0.3552 (0.3737)	loss_x 0.3466 (0.3640)	loss_u 0.0086 (0.0098)	acc_x 87.5000 (87.1243)	lr 2.138669e-03
epoch [17/25][4500/4762]	time 0.148 (0.154)	data 0.001 (0.001)	eta 1:38:18	loss 0.3774 (0.3739)	loss_x 0.3742 (0.3641)	loss_u 0.0031 (0.0098)	acc_x 78.1250 (87.1160)	lr 2.138669e-03
epoch [17/25][4600/4762]	time 0.177 (0.154)	data 0.000 (0.001)	eta 1:38:08	loss 1.0307 (0.3740)	loss_x 0.9121 (0.3642)	loss_u 0.1186 (0.0098)	acc_x 68.7500 (87.1121)	lr 2.138669e-03
epoch [17/25][4700/4762]	time 0.150 (0.154)	data 0.001 (0.001)	eta 1:37:57	loss 0.1811 (0.3738)	loss_x 0.1795 (0.3640)	loss_u 0.0016 (0.0098)	acc_x 87.5000 (87.1330)	lr 2.138669e-03
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,624
* accuracy: 84.18%
* error: 15.82%
* macro_f1: 84.32%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,590	acc: 98.46%
* class: 1 (bicycle)	total: 3,475	correct: 2,922	acc: 84.09%
* class: 2 (bus)	total: 4,690	correct: 4,272	acc: 91.09%
* class: 3 (car)	total: 10,401	correct: 7,768	acc: 74.69%
* class: 4 (horse)	total: 4,691	correct: 4,588	acc: 97.80%
* class: 5 (knife)	total: 2,075	correct: 1,883	acc: 90.75%
* class: 6 (motorcycle)	total: 5,796	correct: 5,525	acc: 95.32%
* class: 7 (person)	total: 4,000	correct: 2,926	acc: 73.15%
* class: 8 (plant)	total: 4,549	correct: 3,805	acc: 83.64%
* class: 9 (skateboard)	total: 2,281	correct: 2,051	acc: 89.92%
* class: 10 (train)	total: 4,236	correct: 3,909	acc: 92.28%
* class: 11 (truck)	total: 5,548	correct: 3,385	acc: 61.01%
* average: 86.02%
epoch [18/25][100/4762]	time 0.143 (0.158)	data 0.001 (0.003)	eta 1:39:45	loss 0.3457 (0.3692)	loss_x 0.3340 (0.3609)	loss_u 0.0117 (0.0083)	acc_x 87.5000 (87.5312)	lr 2.894665e-03
epoch [18/25][200/4762]	time 0.137 (0.156)	data 0.001 (0.002)	eta 1:38:21	loss 0.3815 (0.3778)	loss_x 0.3757 (0.3682)	loss_u 0.0058 (0.0096)	acc_x 87.5000 (86.8906)	lr 2.894665e-03
epoch [18/25][300/4762]	time 0.152 (0.154)	data 0.001 (0.002)	eta 1:37:00	loss 0.6685 (0.3816)	loss_x 0.6640 (0.3721)	loss_u 0.0045 (0.0095)	acc_x 78.1250 (86.6354)	lr 2.894665e-03
epoch [18/25][400/4762]	time 0.144 (0.153)	data 0.001 (0.001)	eta 1:36:11	loss 0.4484 (0.3858)	loss_x 0.4432 (0.3763)	loss_u 0.0052 (0.0096)	acc_x 84.3750 (86.3906)	lr 2.894665e-03
epoch [18/25][500/4762]	time 0.139 (0.153)	data 0.001 (0.001)	eta 1:35:51	loss 0.3438 (0.3848)	loss_x 0.3377 (0.3749)	loss_u 0.0060 (0.0099)	acc_x 81.2500 (86.5438)	lr 2.894665e-03
epoch [18/25][600/4762]	time 0.145 (0.153)	data 0.001 (0.001)	eta 1:35:36	loss 0.3684 (0.3847)	loss_x 0.3662 (0.3749)	loss_u 0.0022 (0.0098)	acc_x 84.3750 (86.5521)	lr 2.894665e-03
epoch [18/25][700/4762]	time 0.153 (0.153)	data 0.000 (0.001)	eta 1:35:32	loss 0.1791 (0.3825)	loss_x 0.1737 (0.3723)	loss_u 0.0054 (0.0102)	acc_x 96.8750 (86.7500)	lr 2.894665e-03
epoch [18/25][800/4762]	time 0.145 (0.153)	data 0.001 (0.001)	eta 1:35:13	loss 0.3600 (0.3777)	loss_x 0.3551 (0.3676)	loss_u 0.0049 (0.0101)	acc_x 87.5000 (86.8906)	lr 2.894665e-03
epoch [18/25][900/4762]	time 0.149 (0.153)	data 0.001 (0.001)	eta 1:35:08	loss 0.4249 (0.3740)	loss_x 0.4225 (0.3640)	loss_u 0.0024 (0.0100)	acc_x 84.3750 (86.9618)	lr 2.894665e-03
epoch [18/25][1000/4762]	time 0.152 (0.153)	data 0.001 (0.001)	eta 1:34:47	loss 0.3959 (0.3747)	loss_x 0.3721 (0.3649)	loss_u 0.0239 (0.0099)	acc_x 81.2500 (86.9594)	lr 2.894665e-03
epoch [18/25][1100/4762]	time 0.145 (0.154)	data 0.001 (0.001)	eta 1:34:46	loss 0.3126 (0.3724)	loss_x 0.3087 (0.3626)	loss_u 0.0039 (0.0099)	acc_x 87.5000 (87.0483)	lr 2.894665e-03
epoch [18/25][1200/4762]	time 0.148 (0.154)	data 0.001 (0.001)	eta 1:34:39	loss 0.1976 (0.3721)	loss_x 0.1909 (0.3623)	loss_u 0.0067 (0.0097)	acc_x 90.6250 (87.1224)	lr 2.894665e-03
epoch [18/25][1300/4762]	time 0.163 (0.154)	data 0.001 (0.001)	eta 1:34:23	loss 0.3107 (0.3720)	loss_x 0.3099 (0.3623)	loss_u 0.0008 (0.0097)	acc_x 87.5000 (87.0962)	lr 2.894665e-03
epoch [18/25][1400/4762]	time 0.144 (0.154)	data 0.001 (0.001)	eta 1:34:08	loss 0.1557 (0.3721)	loss_x 0.1537 (0.3624)	loss_u 0.0021 (0.0097)	acc_x 96.8750 (87.0960)	lr 2.894665e-03
epoch [18/25][1500/4762]	time 0.154 (0.154)	data 0.001 (0.001)	eta 1:34:05	loss 0.3921 (0.3735)	loss_x 0.3765 (0.3637)	loss_u 0.0156 (0.0098)	acc_x 87.5000 (87.0625)	lr 2.894665e-03
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,455
* accuracy: 83.87%
* error: 16.13%
* macro_f1: 83.91%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,579	acc: 98.16%
* class: 1 (bicycle)	total: 3,475	correct: 2,940	acc: 84.60%
* class: 2 (bus)	total: 4,690	correct: 4,260	acc: 90.83%
* class: 3 (car)	total: 10,401	correct: 7,674	acc: 73.78%
* class: 4 (horse)	total: 4,691	correct: 4,595	acc: 97.95%
* class: 5 (knife)	total: 2,075	correct: 1,896	acc: 91.37%
* class: 6 (motorcycle)	total: 5,796	correct: 5,543	acc: 95.63%
* class: 7 (person)	total: 4,000	correct: 2,663	acc: 66.58%
* class: 8 (plant)	total: 4,549	correct: 3,886	acc: 85.43%
* class: 9 (skateboard)	total: 2,281	correct: 2,055	acc: 90.09%
* class: 10 (train)	total: 4,236	correct: 3,963	acc: 93.56%
* class: 11 (truck)	total: 5,548	correct: 3,401	acc: 61.30%
* average: 85.77%
epoch [18/25][1600/4762]	time 0.160 (0.154)	data 0.001 (0.001)	eta 1:33:54	loss 0.0930 (0.3738)	loss_x 0.0797 (0.3640)	loss_u 0.0133 (0.0098)	acc_x 100.0000 (87.0742)	lr 2.894665e-03
epoch [18/25][1700/4762]	time 0.185 (0.154)	data 0.001 (0.001)	eta 1:33:38	loss 0.1910 (0.3746)	loss_x 0.1881 (0.3646)	loss_u 0.0028 (0.0100)	acc_x 93.7500 (87.0478)	lr 2.894665e-03
epoch [18/25][1800/4762]	time 0.137 (0.155)	data 0.001 (0.001)	eta 1:33:29	loss 0.4256 (0.3737)	loss_x 0.4139 (0.3637)	loss_u 0.0117 (0.0100)	acc_x 84.3750 (87.0764)	lr 2.894665e-03
epoch [18/25][1900/4762]	time 0.140 (0.154)	data 0.001 (0.001)	eta 1:33:08	loss 0.3529 (0.3736)	loss_x 0.3513 (0.3636)	loss_u 0.0016 (0.0100)	acc_x 90.6250 (87.0674)	lr 2.894665e-03
epoch [18/25][2000/4762]	time 0.145 (0.154)	data 0.001 (0.001)	eta 1:32:47	loss 0.2340 (0.3722)	loss_x 0.2119 (0.3623)	loss_u 0.0221 (0.0099)	acc_x 90.6250 (87.1219)	lr 2.894665e-03
epoch [18/25][2100/4762]	time 0.143 (0.154)	data 0.001 (0.001)	eta 1:32:27	loss 0.4073 (0.3719)	loss_x 0.4026 (0.3620)	loss_u 0.0047 (0.0099)	acc_x 81.2500 (87.1473)	lr 2.894665e-03
epoch [18/25][2200/4762]	time 0.150 (0.154)	data 0.001 (0.001)	eta 1:32:07	loss 0.7093 (0.3720)	loss_x 0.7077 (0.3621)	loss_u 0.0016 (0.0099)	acc_x 71.8750 (87.1506)	lr 2.894665e-03
epoch [18/25][2300/4762]	time 0.157 (0.154)	data 0.001 (0.001)	eta 1:31:48	loss 0.3941 (0.3720)	loss_x 0.3869 (0.3622)	loss_u 0.0072 (0.0098)	acc_x 84.3750 (87.1549)	lr 2.894665e-03
epoch [18/25][2400/4762]	time 0.139 (0.154)	data 0.001 (0.001)	eta 1:31:31	loss 0.3998 (0.3727)	loss_x 0.3971 (0.3629)	loss_u 0.0027 (0.0098)	acc_x 81.2500 (87.1302)	lr 2.894665e-03
epoch [18/25][2500/4762]	time 0.148 (0.154)	data 0.001 (0.001)	eta 1:31:15	loss 0.6106 (0.3721)	loss_x 0.5938 (0.3622)	loss_u 0.0168 (0.0098)	acc_x 87.5000 (87.1675)	lr 2.894665e-03
epoch [18/25][2600/4762]	time 0.144 (0.154)	data 0.001 (0.001)	eta 1:31:01	loss 0.5945 (0.3719)	loss_x 0.5892 (0.3621)	loss_u 0.0053 (0.0098)	acc_x 75.0000 (87.1743)	lr 2.894665e-03
epoch [18/25][2700/4762]	time 0.154 (0.154)	data 0.002 (0.001)	eta 1:30:54	loss 0.6995 (0.3724)	loss_x 0.6847 (0.3626)	loss_u 0.0148 (0.0098)	acc_x 78.1250 (87.1644)	lr 2.894665e-03
epoch [18/25][2800/4762]	time 0.192 (0.154)	data 0.001 (0.001)	eta 1:30:42	loss 0.3798 (0.3720)	loss_x 0.3771 (0.3623)	loss_u 0.0027 (0.0098)	acc_x 90.6250 (87.1853)	lr 2.894665e-03
epoch [18/25][2900/4762]	time 0.152 (0.154)	data 0.001 (0.001)	eta 1:30:29	loss 0.4174 (0.3723)	loss_x 0.3989 (0.3625)	loss_u 0.0186 (0.0098)	acc_x 84.3750 (87.1810)	lr 2.894665e-03
epoch [18/25][3000/4762]	time 0.139 (0.154)	data 0.001 (0.001)	eta 1:30:16	loss 0.4045 (0.3731)	loss_x 0.4012 (0.3633)	loss_u 0.0033 (0.0098)	acc_x 84.3750 (87.1531)	lr 2.894665e-03
epoch [18/25][3100/4762]	time 0.168 (0.155)	data 0.001 (0.001)	eta 1:30:08	loss 0.3544 (0.3728)	loss_x 0.3495 (0.3630)	loss_u 0.0049 (0.0098)	acc_x 90.6250 (87.1613)	lr 2.894665e-03
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,844
* accuracy: 84.57%
* error: 15.43%
* macro_f1: 84.82%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,578	acc: 98.13%
* class: 1 (bicycle)	total: 3,475	correct: 2,959	acc: 85.15%
* class: 2 (bus)	total: 4,690	correct: 4,221	acc: 90.00%
* class: 3 (car)	total: 10,401	correct: 7,661	acc: 73.66%
* class: 4 (horse)	total: 4,691	correct: 4,582	acc: 97.68%
* class: 5 (knife)	total: 2,075	correct: 1,894	acc: 91.28%
* class: 6 (motorcycle)	total: 5,796	correct: 5,503	acc: 94.94%
* class: 7 (person)	total: 4,000	correct: 2,979	acc: 74.47%
* class: 8 (plant)	total: 4,549	correct: 3,911	acc: 85.97%
* class: 9 (skateboard)	total: 2,281	correct: 2,061	acc: 90.36%
* class: 10 (train)	total: 4,236	correct: 3,952	acc: 93.30%
* class: 11 (truck)	total: 5,548	correct: 3,543	acc: 63.86%
* average: 86.57%
epoch [18/25][3200/4762]	time 0.137 (0.154)	data 0.001 (0.001)	eta 1:29:51	loss 0.3098 (0.3731)	loss_x 0.3079 (0.3634)	loss_u 0.0019 (0.0098)	acc_x 93.7500 (87.1436)	lr 2.894665e-03
epoch [18/25][3300/4762]	time 0.145 (0.154)	data 0.001 (0.001)	eta 1:29:33	loss 0.2441 (0.3726)	loss_x 0.2299 (0.3628)	loss_u 0.0142 (0.0098)	acc_x 90.6250 (87.1657)	lr 2.894665e-03
epoch [18/25][3400/4762]	time 0.147 (0.154)	data 0.000 (0.001)	eta 1:29:13	loss 0.2469 (0.3728)	loss_x 0.2421 (0.3630)	loss_u 0.0048 (0.0098)	acc_x 90.6250 (87.1480)	lr 2.894665e-03
epoch [18/25][3500/4762]	time 0.145 (0.154)	data 0.001 (0.001)	eta 1:28:59	loss 0.4132 (0.3734)	loss_x 0.4069 (0.3637)	loss_u 0.0063 (0.0098)	acc_x 81.2500 (87.1312)	lr 2.894665e-03
epoch [18/25][3600/4762]	time 0.152 (0.154)	data 0.001 (0.001)	eta 1:28:42	loss 0.0999 (0.3736)	loss_x 0.0939 (0.3639)	loss_u 0.0060 (0.0097)	acc_x 100.0000 (87.1137)	lr 2.894665e-03
epoch [18/25][3700/4762]	time 0.141 (0.154)	data 0.001 (0.001)	eta 1:28:24	loss 0.3949 (0.3739)	loss_x 0.3911 (0.3642)	loss_u 0.0037 (0.0097)	acc_x 84.3750 (87.1022)	lr 2.894665e-03
epoch [18/25][3800/4762]	time 0.151 (0.154)	data 0.001 (0.001)	eta 1:28:07	loss 0.0913 (0.3740)	loss_x 0.0798 (0.3643)	loss_u 0.0115 (0.0097)	acc_x 100.0000 (87.1151)	lr 2.894665e-03
epoch [18/25][3900/4762]	time 0.156 (0.154)	data 0.001 (0.001)	eta 1:27:53	loss 0.3091 (0.3743)	loss_x 0.3078 (0.3645)	loss_u 0.0013 (0.0097)	acc_x 87.5000 (87.1042)	lr 2.894665e-03
epoch [18/25][4000/4762]	time 0.180 (0.154)	data 0.001 (0.001)	eta 1:27:41	loss 0.4154 (0.3743)	loss_x 0.4105 (0.3646)	loss_u 0.0049 (0.0097)	acc_x 84.3750 (87.1172)	lr 2.894665e-03
epoch [18/25][4100/4762]	time 0.151 (0.154)	data 0.001 (0.001)	eta 1:27:25	loss 0.3350 (0.3742)	loss_x 0.3217 (0.3645)	loss_u 0.0134 (0.0097)	acc_x 84.3750 (87.1265)	lr 2.894665e-03
epoch [18/25][4200/4762]	time 0.140 (0.154)	data 0.001 (0.001)	eta 1:27:08	loss 0.5136 (0.3738)	loss_x 0.5047 (0.3641)	loss_u 0.0089 (0.0097)	acc_x 84.3750 (87.1414)	lr 2.894665e-03
epoch [18/25][4300/4762]	time 0.181 (0.154)	data 0.001 (0.001)	eta 1:26:54	loss 0.5091 (0.3737)	loss_x 0.4746 (0.3640)	loss_u 0.0345 (0.0097)	acc_x 84.3750 (87.1446)	lr 2.894665e-03
epoch [18/25][4400/4762]	time 0.145 (0.154)	data 0.001 (0.001)	eta 1:26:38	loss 0.4945 (0.3735)	loss_x 0.4823 (0.3639)	loss_u 0.0123 (0.0097)	acc_x 87.5000 (87.1612)	lr 2.894665e-03
epoch [18/25][4500/4762]	time 0.141 (0.154)	data 0.001 (0.001)	eta 1:26:22	loss 0.2111 (0.3732)	loss_x 0.2028 (0.3635)	loss_u 0.0083 (0.0096)	acc_x 90.6250 (87.1694)	lr 2.894665e-03
epoch [18/25][4600/4762]	time 0.142 (0.154)	data 0.002 (0.001)	eta 1:26:04	loss 0.3421 (0.3733)	loss_x 0.3362 (0.3636)	loss_u 0.0059 (0.0097)	acc_x 87.5000 (87.1692)	lr 2.894665e-03
epoch [18/25][4700/4762]	time 0.154 (0.154)	data 0.001 (0.001)	eta 1:25:49	loss 0.4996 (0.3730)	loss_x 0.4971 (0.3634)	loss_u 0.0025 (0.0096)	acc_x 81.2500 (87.1922)	lr 2.894665e-03
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,873
* accuracy: 84.63%
* error: 15.37%
* macro_f1: 84.82%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,572	acc: 97.97%
* class: 1 (bicycle)	total: 3,475	correct: 2,942	acc: 84.66%
* class: 2 (bus)	total: 4,690	correct: 4,286	acc: 91.39%
* class: 3 (car)	total: 10,401	correct: 7,744	acc: 74.45%
* class: 4 (horse)	total: 4,691	correct: 4,570	acc: 97.42%
* class: 5 (knife)	total: 2,075	correct: 1,855	acc: 89.40%
* class: 6 (motorcycle)	total: 5,796	correct: 5,514	acc: 95.13%
* class: 7 (person)	total: 4,000	correct: 2,977	acc: 74.42%
* class: 8 (plant)	total: 4,549	correct: 3,973	acc: 87.34%
* class: 9 (skateboard)	total: 2,281	correct: 2,067	acc: 90.62%
* class: 10 (train)	total: 4,236	correct: 3,878	acc: 91.55%
* class: 11 (truck)	total: 5,548	correct: 3,495	acc: 63.00%
* average: 86.45%
epoch [19/25][100/4762]	time 0.156 (0.157)	data 0.001 (0.003)	eta 1:26:45	loss 0.5941 (0.3674)	loss_x 0.5829 (0.3570)	loss_u 0.0112 (0.0103)	acc_x 75.0000 (87.5625)	lr 1.036475e-03
epoch [19/25][200/4762]	time 0.145 (0.156)	data 0.001 (0.002)	eta 1:26:16	loss 0.6807 (0.3621)	loss_x 0.6657 (0.3523)	loss_u 0.0150 (0.0098)	acc_x 78.1250 (87.6094)	lr 1.036475e-03
epoch [19/25][300/4762]	time 0.168 (0.155)	data 0.001 (0.002)	eta 1:25:36	loss 0.3925 (0.3642)	loss_x 0.3836 (0.3547)	loss_u 0.0089 (0.0095)	acc_x 87.5000 (87.6042)	lr 1.036475e-03
epoch [19/25][400/4762]	time 0.148 (0.155)	data 0.001 (0.001)	eta 1:25:16	loss 0.4282 (0.3653)	loss_x 0.4231 (0.3560)	loss_u 0.0051 (0.0093)	acc_x 90.6250 (87.6797)	lr 1.036475e-03
epoch [19/25][500/4762]	time 0.147 (0.155)	data 0.001 (0.001)	eta 1:24:49	loss 0.3076 (0.3665)	loss_x 0.3034 (0.3571)	loss_u 0.0042 (0.0095)	acc_x 90.6250 (87.4813)	lr 1.036475e-03
epoch [19/25][600/4762]	time 0.154 (0.155)	data 0.001 (0.001)	eta 1:24:37	loss 0.3758 (0.3681)	loss_x 0.3713 (0.3586)	loss_u 0.0045 (0.0095)	acc_x 84.3750 (87.4219)	lr 1.036475e-03
epoch [19/25][700/4762]	time 0.161 (0.155)	data 0.001 (0.001)	eta 1:24:27	loss 0.4282 (0.3698)	loss_x 0.3794 (0.3602)	loss_u 0.0488 (0.0096)	acc_x 87.5000 (87.3839)	lr 1.036475e-03
epoch [19/25][800/4762]	time 0.185 (0.155)	data 0.001 (0.001)	eta 1:24:12	loss 0.2489 (0.3679)	loss_x 0.2414 (0.3585)	loss_u 0.0075 (0.0094)	acc_x 93.7500 (87.4375)	lr 1.036475e-03
epoch [19/25][900/4762]	time 0.166 (0.155)	data 0.001 (0.001)	eta 1:23:52	loss 0.4217 (0.3688)	loss_x 0.4139 (0.3594)	loss_u 0.0078 (0.0093)	acc_x 87.5000 (87.4201)	lr 1.036475e-03
epoch [19/25][1000/4762]	time 0.183 (0.155)	data 0.001 (0.001)	eta 1:23:41	loss 0.4827 (0.3685)	loss_x 0.4818 (0.3590)	loss_u 0.0009 (0.0095)	acc_x 75.0000 (87.3937)	lr 1.036475e-03
epoch [19/25][1100/4762]	time 0.166 (0.156)	data 0.001 (0.001)	eta 1:23:41	loss 0.3894 (0.3673)	loss_x 0.3729 (0.3578)	loss_u 0.0165 (0.0095)	acc_x 90.6250 (87.4688)	lr 1.036475e-03
epoch [19/25][1200/4762]	time 0.148 (0.156)	data 0.001 (0.001)	eta 1:23:31	loss 0.6783 (0.3682)	loss_x 0.6781 (0.3589)	loss_u 0.0002 (0.0093)	acc_x 71.8750 (87.4427)	lr 1.036475e-03
epoch [19/25][1300/4762]	time 0.184 (0.156)	data 0.001 (0.001)	eta 1:23:20	loss 0.3368 (0.3676)	loss_x 0.3278 (0.3584)	loss_u 0.0091 (0.0092)	acc_x 90.6250 (87.4207)	lr 1.036475e-03
epoch [19/25][1400/4762]	time 0.165 (0.156)	data 0.001 (0.001)	eta 1:22:55	loss 0.4064 (0.3685)	loss_x 0.3950 (0.3590)	loss_u 0.0114 (0.0094)	acc_x 90.6250 (87.3728)	lr 1.036475e-03
epoch [19/25][1500/4762]	time 0.140 (0.156)	data 0.001 (0.001)	eta 1:22:31	loss 0.6010 (0.3682)	loss_x 0.5986 (0.3588)	loss_u 0.0024 (0.0095)	acc_x 81.2500 (87.3708)	lr 1.036475e-03
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,656
* accuracy: 84.23%
* error: 15.77%
* macro_f1: 84.19%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,584	acc: 98.30%
* class: 1 (bicycle)	total: 3,475	correct: 2,917	acc: 83.94%
* class: 2 (bus)	total: 4,690	correct: 4,273	acc: 91.11%
* class: 3 (car)	total: 10,401	correct: 7,803	acc: 75.02%
* class: 4 (horse)	total: 4,691	correct: 4,578	acc: 97.59%
* class: 5 (knife)	total: 2,075	correct: 1,903	acc: 91.71%
* class: 6 (motorcycle)	total: 5,796	correct: 5,512	acc: 95.10%
* class: 7 (person)	total: 4,000	correct: 2,856	acc: 71.40%
* class: 8 (plant)	total: 4,549	correct: 3,902	acc: 85.78%
* class: 9 (skateboard)	total: 2,281	correct: 2,036	acc: 89.26%
* class: 10 (train)	total: 4,236	correct: 3,925	acc: 92.66%
* class: 11 (truck)	total: 5,548	correct: 3,367	acc: 60.69%
* average: 86.05%
epoch [19/25][1600/4762]	time 0.157 (0.156)	data 0.001 (0.001)	eta 1:22:23	loss 0.3131 (0.3693)	loss_x 0.3072 (0.3597)	loss_u 0.0059 (0.0096)	acc_x 90.6250 (87.3457)	lr 1.036475e-03
epoch [19/25][1700/4762]	time 0.148 (0.156)	data 0.001 (0.001)	eta 1:22:07	loss 0.4876 (0.3693)	loss_x 0.4831 (0.3598)	loss_u 0.0045 (0.0095)	acc_x 81.2500 (87.3603)	lr 1.036475e-03
epoch [19/25][1800/4762]	time 0.147 (0.156)	data 0.001 (0.001)	eta 1:21:53	loss 0.4265 (0.3689)	loss_x 0.4198 (0.3593)	loss_u 0.0066 (0.0095)	acc_x 87.5000 (87.3628)	lr 1.036475e-03
epoch [19/25][1900/4762]	time 0.136 (0.156)	data 0.001 (0.001)	eta 1:21:33	loss 0.3787 (0.3702)	loss_x 0.3781 (0.3605)	loss_u 0.0006 (0.0097)	acc_x 90.6250 (87.3355)	lr 1.036475e-03
epoch [19/25][2000/4762]	time 0.143 (0.156)	data 0.001 (0.001)	eta 1:21:13	loss 0.2918 (0.3712)	loss_x 0.2811 (0.3616)	loss_u 0.0107 (0.0097)	acc_x 87.5000 (87.3312)	lr 1.036475e-03
epoch [19/25][2100/4762]	time 0.151 (0.155)	data 0.001 (0.001)	eta 1:20:53	loss 0.2781 (0.3715)	loss_x 0.2712 (0.3619)	loss_u 0.0069 (0.0096)	acc_x 93.7500 (87.3155)	lr 1.036475e-03
epoch [19/25][2200/4762]	time 0.173 (0.155)	data 0.001 (0.001)	eta 1:20:33	loss 0.4797 (0.3714)	loss_x 0.4598 (0.3619)	loss_u 0.0199 (0.0095)	acc_x 84.3750 (87.3153)	lr 1.036475e-03
epoch [19/25][2300/4762]	time 0.142 (0.155)	data 0.001 (0.001)	eta 1:20:18	loss 0.4363 (0.3718)	loss_x 0.4349 (0.3624)	loss_u 0.0014 (0.0094)	acc_x 84.3750 (87.3030)	lr 1.036475e-03
epoch [19/25][2400/4762]	time 0.165 (0.155)	data 0.001 (0.001)	eta 1:19:57	loss 0.4227 (0.3720)	loss_x 0.4191 (0.3626)	loss_u 0.0035 (0.0095)	acc_x 81.2500 (87.2747)	lr 1.036475e-03
epoch [19/25][2500/4762]	time 0.143 (0.155)	data 0.001 (0.001)	eta 1:19:34	loss 0.4441 (0.3724)	loss_x 0.4415 (0.3629)	loss_u 0.0026 (0.0095)	acc_x 90.6250 (87.2763)	lr 1.036475e-03
epoch [19/25][2600/4762]	time 0.143 (0.155)	data 0.001 (0.001)	eta 1:19:13	loss 0.3786 (0.3716)	loss_x 0.3781 (0.3621)	loss_u 0.0005 (0.0095)	acc_x 87.5000 (87.3137)	lr 1.036475e-03
epoch [19/25][2700/4762]	time 0.139 (0.155)	data 0.001 (0.001)	eta 1:18:55	loss 0.2968 (0.3711)	loss_x 0.2839 (0.3617)	loss_u 0.0129 (0.0095)	acc_x 84.3750 (87.3137)	lr 1.036475e-03
epoch [19/25][2800/4762]	time 0.155 (0.155)	data 0.001 (0.001)	eta 1:18:40	loss 0.3143 (0.3716)	loss_x 0.3125 (0.3621)	loss_u 0.0018 (0.0095)	acc_x 81.2500 (87.2958)	lr 1.036475e-03
epoch [19/25][2900/4762]	time 0.142 (0.155)	data 0.001 (0.001)	eta 1:18:27	loss 0.1566 (0.3713)	loss_x 0.1549 (0.3618)	loss_u 0.0017 (0.0095)	acc_x 93.7500 (87.3050)	lr 1.036475e-03
epoch [19/25][3000/4762]	time 0.158 (0.155)	data 0.002 (0.001)	eta 1:18:08	loss 0.1419 (0.3709)	loss_x 0.1395 (0.3615)	loss_u 0.0024 (0.0094)	acc_x 96.8750 (87.3156)	lr 1.036475e-03
epoch [19/25][3100/4762]	time 0.158 (0.155)	data 0.001 (0.001)	eta 1:17:54	loss 0.1364 (0.3706)	loss_x 0.1341 (0.3613)	loss_u 0.0023 (0.0093)	acc_x 96.8750 (87.3226)	lr 1.036475e-03
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,927
* accuracy: 84.72%
* error: 15.28%
* macro_f1: 84.95%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,579	acc: 98.16%
* class: 1 (bicycle)	total: 3,475	correct: 2,945	acc: 84.75%
* class: 2 (bus)	total: 4,690	correct: 4,268	acc: 91.00%
* class: 3 (car)	total: 10,401	correct: 7,812	acc: 75.11%
* class: 4 (horse)	total: 4,691	correct: 4,578	acc: 97.59%
* class: 5 (knife)	total: 2,075	correct: 1,884	acc: 90.80%
* class: 6 (motorcycle)	total: 5,796	correct: 5,515	acc: 95.15%
* class: 7 (person)	total: 4,000	correct: 3,068	acc: 76.70%
* class: 8 (plant)	total: 4,549	correct: 3,936	acc: 86.52%
* class: 9 (skateboard)	total: 2,281	correct: 2,054	acc: 90.05%
* class: 10 (train)	total: 4,236	correct: 3,931	acc: 92.80%
* class: 11 (truck)	total: 5,548	correct: 3,357	acc: 60.51%
* average: 86.59%
epoch [19/25][3200/4762]	time 0.156 (0.155)	data 0.001 (0.001)	eta 1:17:39	loss 0.3327 (0.3707)	loss_x 0.3276 (0.3614)	loss_u 0.0052 (0.0093)	acc_x 90.6250 (87.3145)	lr 1.036475e-03
epoch [19/25][3300/4762]	time 0.175 (0.155)	data 0.001 (0.001)	eta 1:17:20	loss 0.3472 (0.3710)	loss_x 0.3469 (0.3617)	loss_u 0.0003 (0.0093)	acc_x 87.5000 (87.2955)	lr 1.036475e-03
epoch [19/25][3400/4762]	time 0.167 (0.154)	data 0.001 (0.001)	eta 1:17:03	loss 0.3911 (0.3713)	loss_x 0.3856 (0.3621)	loss_u 0.0056 (0.0092)	acc_x 87.5000 (87.2950)	lr 1.036475e-03
epoch [19/25][3500/4762]	time 0.154 (0.155)	data 0.001 (0.001)	eta 1:16:51	loss 0.5402 (0.3708)	loss_x 0.5341 (0.3616)	loss_u 0.0061 (0.0092)	acc_x 81.2500 (87.2964)	lr 1.036475e-03
epoch [19/25][3600/4762]	time 0.158 (0.155)	data 0.001 (0.001)	eta 1:16:34	loss 0.2480 (0.3709)	loss_x 0.2279 (0.3616)	loss_u 0.0201 (0.0093)	acc_x 93.7500 (87.2934)	lr 1.036475e-03
epoch [19/25][3700/4762]	time 0.157 (0.154)	data 0.001 (0.001)	eta 1:16:16	loss 0.4852 (0.3705)	loss_x 0.4561 (0.3613)	loss_u 0.0291 (0.0093)	acc_x 81.2500 (87.3049)	lr 1.036475e-03
epoch [19/25][3800/4762]	time 0.151 (0.154)	data 0.001 (0.001)	eta 1:15:58	loss 0.1682 (0.3706)	loss_x 0.1562 (0.3613)	loss_u 0.0120 (0.0093)	acc_x 93.7500 (87.3117)	lr 1.036475e-03
epoch [19/25][3900/4762]	time 0.162 (0.154)	data 0.001 (0.001)	eta 1:15:39	loss 0.6588 (0.3705)	loss_x 0.6267 (0.3612)	loss_u 0.0321 (0.0093)	acc_x 71.8750 (87.3069)	lr 1.036475e-03
epoch [19/25][4000/4762]	time 0.143 (0.154)	data 0.001 (0.001)	eta 1:15:22	loss 0.5177 (0.3710)	loss_x 0.5116 (0.3617)	loss_u 0.0061 (0.0093)	acc_x 81.2500 (87.2828)	lr 1.036475e-03
epoch [19/25][4100/4762]	time 0.173 (0.154)	data 0.001 (0.001)	eta 1:15:04	loss 0.3497 (0.3708)	loss_x 0.3423 (0.3615)	loss_u 0.0073 (0.0093)	acc_x 87.5000 (87.2980)	lr 1.036475e-03
epoch [19/25][4200/4762]	time 0.162 (0.154)	data 0.001 (0.001)	eta 1:14:49	loss 0.4347 (0.3708)	loss_x 0.4316 (0.3615)	loss_u 0.0030 (0.0093)	acc_x 81.2500 (87.2984)	lr 1.036475e-03
epoch [19/25][4300/4762]	time 0.149 (0.154)	data 0.001 (0.001)	eta 1:14:33	loss 0.2211 (0.3704)	loss_x 0.1845 (0.3611)	loss_u 0.0366 (0.0093)	acc_x 93.7500 (87.3052)	lr 1.036475e-03
epoch [19/25][4400/4762]	time 0.142 (0.154)	data 0.001 (0.001)	eta 1:14:17	loss 0.6102 (0.3704)	loss_x 0.6016 (0.3611)	loss_u 0.0086 (0.0093)	acc_x 75.0000 (87.3196)	lr 1.036475e-03
epoch [19/25][4500/4762]	time 0.141 (0.154)	data 0.001 (0.001)	eta 1:14:01	loss 0.3258 (0.3703)	loss_x 0.3174 (0.3609)	loss_u 0.0084 (0.0094)	acc_x 87.5000 (87.3236)	lr 1.036475e-03
epoch [19/25][4600/4762]	time 0.144 (0.154)	data 0.001 (0.001)	eta 1:13:46	loss 0.4367 (0.3704)	loss_x 0.4350 (0.3610)	loss_u 0.0017 (0.0094)	acc_x 81.2500 (87.3179)	lr 1.036475e-03
epoch [19/25][4700/4762]	time 0.159 (0.154)	data 0.001 (0.001)	eta 1:13:32	loss 0.4834 (0.3706)	loss_x 0.4771 (0.3612)	loss_u 0.0062 (0.0094)	acc_x 81.2500 (87.2999)	lr 1.036475e-03
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,704
* accuracy: 84.32%
* error: 15.68%
* macro_f1: 84.34%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,580	acc: 98.19%
* class: 1 (bicycle)	total: 3,475	correct: 2,906	acc: 83.63%
* class: 2 (bus)	total: 4,690	correct: 4,259	acc: 90.81%
* class: 3 (car)	total: 10,401	correct: 7,787	acc: 74.87%
* class: 4 (horse)	total: 4,691	correct: 4,555	acc: 97.10%
* class: 5 (knife)	total: 2,075	correct: 1,781	acc: 85.83%
* class: 6 (motorcycle)	total: 5,796	correct: 5,534	acc: 95.48%
* class: 7 (person)	total: 4,000	correct: 2,983	acc: 74.58%
* class: 8 (plant)	total: 4,549	correct: 3,866	acc: 84.99%
* class: 9 (skateboard)	total: 2,281	correct: 2,076	acc: 91.01%
* class: 10 (train)	total: 4,236	correct: 3,909	acc: 92.28%
* class: 11 (truck)	total: 5,548	correct: 3,468	acc: 62.51%
* average: 85.94%
epoch [20/25][100/4762]	time 0.163 (0.153)	data 0.001 (0.003)	eta 1:12:40	loss 0.3925 (0.3548)	loss_x 0.3815 (0.3448)	loss_u 0.0110 (0.0100)	acc_x 87.5000 (88.1875)	lr 4.712526e-05
epoch [20/25][200/4762]	time 0.140 (0.152)	data 0.001 (0.002)	eta 1:11:56	loss 0.2972 (0.3626)	loss_x 0.2941 (0.3527)	loss_u 0.0030 (0.0099)	acc_x 90.6250 (87.3750)	lr 4.712526e-05
epoch [20/25][300/4762]	time 0.136 (0.151)	data 0.001 (0.002)	eta 1:11:14	loss 0.5046 (0.3665)	loss_x 0.4882 (0.3570)	loss_u 0.0164 (0.0095)	acc_x 81.2500 (87.2500)	lr 4.712526e-05
epoch [20/25][400/4762]	time 0.159 (0.151)	data 0.001 (0.001)	eta 1:10:53	loss 0.4444 (0.3727)	loss_x 0.3869 (0.3636)	loss_u 0.0575 (0.0090)	acc_x 84.3750 (87.0312)	lr 4.712526e-05
epoch [20/25][500/4762]	time 0.151 (0.151)	data 0.001 (0.001)	eta 1:10:24	loss 0.4057 (0.3768)	loss_x 0.4024 (0.3679)	loss_u 0.0033 (0.0089)	acc_x 84.3750 (86.8812)	lr 4.712526e-05
epoch [20/25][600/4762]	time 0.137 (0.150)	data 0.001 (0.001)	eta 1:10:08	loss 0.4186 (0.3776)	loss_x 0.4102 (0.3684)	loss_u 0.0084 (0.0092)	acc_x 87.5000 (87.0052)	lr 4.712526e-05
epoch [20/25][700/4762]	time 0.146 (0.150)	data 0.001 (0.001)	eta 1:09:54	loss 0.5079 (0.3729)	loss_x 0.5027 (0.3639)	loss_u 0.0052 (0.0090)	acc_x 81.2500 (87.2143)	lr 4.712526e-05
epoch [20/25][800/4762]	time 0.165 (0.151)	data 0.001 (0.001)	eta 1:09:39	loss 0.6022 (0.3755)	loss_x 0.5923 (0.3662)	loss_u 0.0098 (0.0093)	acc_x 78.1250 (87.1836)	lr 4.712526e-05
epoch [20/25][900/4762]	time 0.144 (0.150)	data 0.001 (0.001)	eta 1:09:24	loss 0.2230 (0.3745)	loss_x 0.2173 (0.3652)	loss_u 0.0057 (0.0093)	acc_x 90.6250 (87.2049)	lr 4.712526e-05
epoch [20/25][1000/4762]	time 0.158 (0.151)	data 0.001 (0.001)	eta 1:09:12	loss 0.4465 (0.3744)	loss_x 0.4420 (0.3649)	loss_u 0.0045 (0.0094)	acc_x 84.3750 (87.2188)	lr 4.712526e-05
epoch [20/25][1100/4762]	time 0.137 (0.151)	data 0.001 (0.001)	eta 1:09:05	loss 0.3746 (0.3750)	loss_x 0.3665 (0.3655)	loss_u 0.0081 (0.0095)	acc_x 87.5000 (87.2074)	lr 4.712526e-05
epoch [20/25][1200/4762]	time 0.139 (0.151)	data 0.001 (0.001)	eta 1:09:06	loss 0.4445 (0.3746)	loss_x 0.4335 (0.3652)	loss_u 0.0110 (0.0094)	acc_x 90.6250 (87.2161)	lr 4.712526e-05
epoch [20/25][1300/4762]	time 0.170 (0.152)	data 0.001 (0.001)	eta 1:08:57	loss 0.1945 (0.3749)	loss_x 0.1894 (0.3656)	loss_u 0.0051 (0.0093)	acc_x 93.7500 (87.2067)	lr 4.712526e-05
epoch [20/25][1400/4762]	time 0.158 (0.152)	data 0.001 (0.001)	eta 1:08:43	loss 0.3554 (0.3742)	loss_x 0.3239 (0.3648)	loss_u 0.0315 (0.0094)	acc_x 93.7500 (87.2143)	lr 4.712526e-05
epoch [20/25][1500/4762]	time 0.142 (0.152)	data 0.001 (0.001)	eta 1:08:30	loss 0.4771 (0.3752)	loss_x 0.4756 (0.3658)	loss_u 0.0015 (0.0094)	acc_x 84.3750 (87.1917)	lr 4.712526e-05
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,595
* accuracy: 84.12%
* error: 15.88%
* macro_f1: 84.21%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,586	acc: 98.35%
* class: 1 (bicycle)	total: 3,475	correct: 2,911	acc: 83.77%
* class: 2 (bus)	total: 4,690	correct: 4,310	acc: 91.90%
* class: 3 (car)	total: 10,401	correct: 7,809	acc: 75.08%
* class: 4 (horse)	total: 4,691	correct: 4,572	acc: 97.46%
* class: 5 (knife)	total: 2,075	correct: 1,878	acc: 90.51%
* class: 6 (motorcycle)	total: 5,796	correct: 5,539	acc: 95.57%
* class: 7 (person)	total: 4,000	correct: 2,893	acc: 72.33%
* class: 8 (plant)	total: 4,549	correct: 3,901	acc: 85.76%
* class: 9 (skateboard)	total: 2,281	correct: 2,058	acc: 90.22%
* class: 10 (train)	total: 4,236	correct: 3,906	acc: 92.21%
* class: 11 (truck)	total: 5,548	correct: 3,232	acc: 58.26%
* average: 85.95%
epoch [20/25][1600/4762]	time 0.171 (0.152)	data 0.001 (0.001)	eta 1:08:18	loss 0.4580 (0.3753)	loss_x 0.4525 (0.3658)	loss_u 0.0056 (0.0095)	acc_x 81.2500 (87.1699)	lr 4.712526e-05
epoch [20/25][1700/4762]	time 0.161 (0.152)	data 0.001 (0.001)	eta 1:08:00	loss 0.4054 (0.3749)	loss_x 0.4017 (0.3654)	loss_u 0.0037 (0.0095)	acc_x 90.6250 (87.2206)	lr 4.712526e-05
epoch [20/25][1800/4762]	time 0.142 (0.152)	data 0.001 (0.001)	eta 1:07:51	loss 0.3432 (0.3756)	loss_x 0.3116 (0.3662)	loss_u 0.0315 (0.0094)	acc_x 93.7500 (87.1476)	lr 4.712526e-05
epoch [20/25][1900/4762]	time 0.138 (0.152)	data 0.001 (0.001)	eta 1:07:35	loss 0.3689 (0.3762)	loss_x 0.3551 (0.3669)	loss_u 0.0138 (0.0094)	acc_x 84.3750 (87.1168)	lr 4.712526e-05
epoch [20/25][2000/4762]	time 0.163 (0.152)	data 0.001 (0.001)	eta 1:07:20	loss 0.5415 (0.3755)	loss_x 0.5388 (0.3660)	loss_u 0.0028 (0.0095)	acc_x 81.2500 (87.1469)	lr 4.712526e-05
epoch [20/25][2100/4762]	time 0.146 (0.152)	data 0.001 (0.001)	eta 1:07:03	loss 0.5233 (0.3762)	loss_x 0.5124 (0.3666)	loss_u 0.0109 (0.0096)	acc_x 84.3750 (87.1265)	lr 4.712526e-05
epoch [20/25][2200/4762]	time 0.143 (0.152)	data 0.001 (0.001)	eta 1:06:50	loss 0.2690 (0.3763)	loss_x 0.2596 (0.3666)	loss_u 0.0093 (0.0097)	acc_x 90.6250 (87.1236)	lr 4.712526e-05
epoch [20/25][2300/4762]	time 0.138 (0.152)	data 0.001 (0.001)	eta 1:06:38	loss 0.4447 (0.3764)	loss_x 0.4421 (0.3668)	loss_u 0.0026 (0.0097)	acc_x 78.1250 (87.1291)	lr 4.712526e-05
epoch [20/25][2400/4762]	time 0.142 (0.152)	data 0.001 (0.001)	eta 1:06:24	loss 0.5679 (0.3765)	loss_x 0.5590 (0.3668)	loss_u 0.0090 (0.0097)	acc_x 75.0000 (87.1185)	lr 4.712526e-05
epoch [20/25][2500/4762]	time 0.144 (0.152)	data 0.001 (0.001)	eta 1:06:08	loss 0.1402 (0.3755)	loss_x 0.1389 (0.3660)	loss_u 0.0014 (0.0096)	acc_x 93.7500 (87.1550)	lr 4.712526e-05
epoch [20/25][2600/4762]	time 0.141 (0.152)	data 0.001 (0.001)	eta 1:05:51	loss 0.6648 (0.3757)	loss_x 0.6437 (0.3661)	loss_u 0.0211 (0.0095)	acc_x 84.3750 (87.1418)	lr 4.712526e-05
epoch [20/25][2700/4762]	time 0.149 (0.152)	data 0.001 (0.001)	eta 1:05:35	loss 0.3604 (0.3757)	loss_x 0.3315 (0.3661)	loss_u 0.0289 (0.0095)	acc_x 87.5000 (87.1516)	lr 4.712526e-05
epoch [20/25][2800/4762]	time 0.168 (0.152)	data 0.001 (0.001)	eta 1:05:19	loss 0.4464 (0.3754)	loss_x 0.4390 (0.3659)	loss_u 0.0074 (0.0095)	acc_x 87.5000 (87.1652)	lr 4.712526e-05
epoch [20/25][2900/4762]	time 0.161 (0.152)	data 0.001 (0.001)	eta 1:05:06	loss 0.2896 (0.3751)	loss_x 0.2805 (0.3655)	loss_u 0.0091 (0.0095)	acc_x 90.6250 (87.1670)	lr 4.712526e-05
epoch [20/25][3000/4762]	time 0.137 (0.152)	data 0.001 (0.001)	eta 1:04:51	loss 0.2841 (0.3743)	loss_x 0.2619 (0.3648)	loss_u 0.0222 (0.0095)	acc_x 90.6250 (87.1823)	lr 4.712526e-05
epoch [20/25][3100/4762]	time 0.144 (0.152)	data 0.001 (0.001)	eta 1:04:36	loss 0.3925 (0.3741)	loss_x 0.3877 (0.3647)	loss_u 0.0048 (0.0094)	acc_x 90.6250 (87.1815)	lr 4.712526e-05
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,714
* accuracy: 84.34%
* error: 15.66%
* macro_f1: 84.55%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,582	acc: 98.24%
* class: 1 (bicycle)	total: 3,475	correct: 2,965	acc: 85.32%
* class: 2 (bus)	total: 4,690	correct: 4,258	acc: 90.79%
* class: 3 (car)	total: 10,401	correct: 7,536	acc: 72.45%
* class: 4 (horse)	total: 4,691	correct: 4,581	acc: 97.66%
* class: 5 (knife)	total: 2,075	correct: 1,844	acc: 88.87%
* class: 6 (motorcycle)	total: 5,796	correct: 5,496	acc: 94.82%
* class: 7 (person)	total: 4,000	correct: 2,953	acc: 73.83%
* class: 8 (plant)	total: 4,549	correct: 3,934	acc: 86.48%
* class: 9 (skateboard)	total: 2,281	correct: 2,085	acc: 91.41%
* class: 10 (train)	total: 4,236	correct: 3,929	acc: 92.75%
* class: 11 (truck)	total: 5,548	correct: 3,551	acc: 64.01%
* average: 86.39%
epoch [20/25][3200/4762]	time 0.154 (0.152)	data 0.001 (0.001)	eta 1:04:21	loss 0.4712 (0.3734)	loss_x 0.4675 (0.3640)	loss_u 0.0037 (0.0094)	acc_x 78.1250 (87.2207)	lr 4.712526e-05
epoch [20/25][3300/4762]	time 0.172 (0.152)	data 0.014 (0.001)	eta 1:04:06	loss 0.3231 (0.3732)	loss_x 0.3199 (0.3638)	loss_u 0.0031 (0.0094)	acc_x 84.3750 (87.2216)	lr 4.712526e-05
epoch [20/25][3400/4762]	time 0.154 (0.152)	data 0.002 (0.001)	eta 1:03:52	loss 0.3362 (0.3736)	loss_x 0.3268 (0.3642)	loss_u 0.0094 (0.0094)	acc_x 93.7500 (87.2169)	lr 4.712526e-05
epoch [20/25][3500/4762]	time 0.144 (0.152)	data 0.001 (0.001)	eta 1:03:41	loss 0.3964 (0.3740)	loss_x 0.3935 (0.3647)	loss_u 0.0029 (0.0094)	acc_x 87.5000 (87.2009)	lr 4.712526e-05
epoch [20/25][3600/4762]	time 0.161 (0.152)	data 0.001 (0.001)	eta 1:03:26	loss 0.3156 (0.3739)	loss_x 0.3141 (0.3645)	loss_u 0.0015 (0.0094)	acc_x 87.5000 (87.2101)	lr 4.712526e-05
epoch [20/25][3700/4762]	time 0.156 (0.152)	data 0.001 (0.001)	eta 1:03:10	loss 0.3824 (0.3739)	loss_x 0.3704 (0.3645)	loss_u 0.0121 (0.0094)	acc_x 87.5000 (87.2137)	lr 4.712526e-05
epoch [20/25][3800/4762]	time 0.151 (0.152)	data 0.001 (0.001)	eta 1:02:52	loss 0.2608 (0.3736)	loss_x 0.2507 (0.3642)	loss_u 0.0101 (0.0094)	acc_x 90.6250 (87.2179)	lr 4.712526e-05
epoch [20/25][3900/4762]	time 0.145 (0.152)	data 0.001 (0.001)	eta 1:02:35	loss 0.2974 (0.3734)	loss_x 0.2903 (0.3640)	loss_u 0.0071 (0.0094)	acc_x 90.6250 (87.2212)	lr 4.712526e-05
epoch [20/25][4000/4762]	time 0.139 (0.152)	data 0.001 (0.001)	eta 1:02:20	loss 0.3356 (0.3738)	loss_x 0.3289 (0.3644)	loss_u 0.0067 (0.0094)	acc_x 81.2500 (87.2008)	lr 4.712526e-05
epoch [20/25][4100/4762]	time 0.161 (0.152)	data 0.001 (0.001)	eta 1:02:01	loss 0.4586 (0.3739)	loss_x 0.4509 (0.3645)	loss_u 0.0077 (0.0094)	acc_x 87.5000 (87.2035)	lr 4.712526e-05
epoch [20/25][4200/4762]	time 0.149 (0.152)	data 0.001 (0.001)	eta 1:01:46	loss 0.5636 (0.3738)	loss_x 0.5545 (0.3643)	loss_u 0.0091 (0.0095)	acc_x 78.1250 (87.2076)	lr 4.712526e-05
epoch [20/25][4300/4762]	time 0.159 (0.152)	data 0.001 (0.001)	eta 1:01:31	loss 0.3820 (0.3739)	loss_x 0.3606 (0.3644)	loss_u 0.0214 (0.0095)	acc_x 87.5000 (87.1999)	lr 4.712526e-05
epoch [20/25][4400/4762]	time 0.147 (0.152)	data 0.001 (0.001)	eta 1:01:17	loss 0.3073 (0.3739)	loss_x 0.2985 (0.3644)	loss_u 0.0088 (0.0095)	acc_x 93.7500 (87.2017)	lr 4.712526e-05
epoch [20/25][4500/4762]	time 0.143 (0.152)	data 0.001 (0.001)	eta 1:01:01	loss 0.5160 (0.3737)	loss_x 0.4957 (0.3642)	loss_u 0.0203 (0.0095)	acc_x 81.2500 (87.2083)	lr 4.712526e-05
epoch [20/25][4600/4762]	time 0.158 (0.152)	data 0.001 (0.001)	eta 1:00:47	loss 0.3268 (0.3732)	loss_x 0.3237 (0.3637)	loss_u 0.0031 (0.0095)	acc_x 90.6250 (87.2269)	lr 4.712526e-05
epoch [20/25][4700/4762]	time 0.141 (0.152)	data 0.001 (0.001)	eta 1:00:32	loss 0.5196 (0.3735)	loss_x 0.5120 (0.3641)	loss_u 0.0076 (0.0095)	acc_x 81.2500 (87.2061)	lr 4.712526e-05
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,839
* accuracy: 84.57%
* error: 15.43%
* macro_f1: 84.73%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,582	acc: 98.24%
* class: 1 (bicycle)	total: 3,475	correct: 2,929	acc: 84.29%
* class: 2 (bus)	total: 4,690	correct: 4,232	acc: 90.23%
* class: 3 (car)	total: 10,401	correct: 7,757	acc: 74.58%
* class: 4 (horse)	total: 4,691	correct: 4,599	acc: 98.04%
* class: 5 (knife)	total: 2,075	correct: 1,865	acc: 89.88%
* class: 6 (motorcycle)	total: 5,796	correct: 5,513	acc: 95.12%
* class: 7 (person)	total: 4,000	correct: 2,922	acc: 73.05%
* class: 8 (plant)	total: 4,549	correct: 3,974	acc: 87.36%
* class: 9 (skateboard)	total: 2,281	correct: 2,063	acc: 90.44%
* class: 10 (train)	total: 4,236	correct: 3,962	acc: 93.53%
* class: 11 (truck)	total: 5,548	correct: 3,441	acc: 62.02%
* average: 86.40%
epoch [21/25][100/4762]	time 0.176 (0.158)	data 0.001 (0.004)	eta 1:02:29	loss 0.2160 (0.3664)	loss_x 0.2104 (0.3553)	loss_u 0.0056 (0.0111)	acc_x 96.8750 (87.4062)	lr 1.781072e-03
epoch [21/25][200/4762]	time 0.160 (0.154)	data 0.001 (0.002)	eta 1:00:43	loss 0.2074 (0.3615)	loss_x 0.1913 (0.3517)	loss_u 0.0161 (0.0098)	acc_x 100.0000 (87.7656)	lr 1.781072e-03
epoch [21/25][300/4762]	time 0.154 (0.154)	data 0.001 (0.002)	eta 1:00:32	loss 0.4267 (0.3661)	loss_x 0.4248 (0.3558)	loss_u 0.0018 (0.0103)	acc_x 81.2500 (87.4271)	lr 1.781072e-03
epoch [21/25][400/4762]	time 0.188 (0.154)	data 0.001 (0.002)	eta 1:00:09	loss 0.6129 (0.3651)	loss_x 0.6112 (0.3551)	loss_u 0.0017 (0.0100)	acc_x 78.1250 (87.4766)	lr 1.781072e-03
epoch [21/25][500/4762]	time 0.162 (0.154)	data 0.001 (0.001)	eta 0:59:42	loss 0.3369 (0.3692)	loss_x 0.3352 (0.3591)	loss_u 0.0017 (0.0101)	acc_x 87.5000 (87.4062)	lr 1.781072e-03
epoch [21/25][600/4762]	time 0.137 (0.153)	data 0.001 (0.001)	eta 0:59:17	loss 0.2450 (0.3683)	loss_x 0.2259 (0.3585)	loss_u 0.0191 (0.0098)	acc_x 87.5000 (87.4115)	lr 1.781072e-03
epoch [21/25][700/4762]	time 0.138 (0.153)	data 0.001 (0.001)	eta 0:58:53	loss 0.3154 (0.3701)	loss_x 0.3086 (0.3605)	loss_u 0.0068 (0.0096)	acc_x 87.5000 (87.4464)	lr 1.781072e-03
epoch [21/25][800/4762]	time 0.150 (0.153)	data 0.001 (0.001)	eta 0:58:32	loss 0.4063 (0.3722)	loss_x 0.3998 (0.3628)	loss_u 0.0065 (0.0094)	acc_x 87.5000 (87.3594)	lr 1.781072e-03
epoch [21/25][900/4762]	time 0.141 (0.153)	data 0.001 (0.001)	eta 0:58:18	loss 0.3434 (0.3721)	loss_x 0.3423 (0.3627)	loss_u 0.0010 (0.0094)	acc_x 87.5000 (87.3333)	lr 1.781072e-03
epoch [21/25][1000/4762]	time 0.144 (0.152)	data 0.001 (0.001)	eta 0:57:57	loss 0.3179 (0.3716)	loss_x 0.3166 (0.3622)	loss_u 0.0014 (0.0094)	acc_x 87.5000 (87.3219)	lr 1.781072e-03
epoch [21/25][1100/4762]	time 0.153 (0.153)	data 0.001 (0.001)	eta 0:57:45	loss 0.3060 (0.3734)	loss_x 0.3030 (0.3641)	loss_u 0.0030 (0.0093)	acc_x 87.5000 (87.2585)	lr 1.781072e-03
epoch [21/25][1200/4762]	time 0.143 (0.152)	data 0.001 (0.001)	eta 0:57:27	loss 0.4092 (0.3721)	loss_x 0.4056 (0.3629)	loss_u 0.0036 (0.0092)	acc_x 78.1250 (87.3177)	lr 1.781072e-03
epoch [21/25][1300/4762]	time 0.144 (0.152)	data 0.001 (0.001)	eta 0:57:09	loss 0.4223 (0.3726)	loss_x 0.4177 (0.3636)	loss_u 0.0046 (0.0090)	acc_x 78.1250 (87.2740)	lr 1.781072e-03
epoch [21/25][1400/4762]	time 0.145 (0.152)	data 0.002 (0.001)	eta 0:56:56	loss 0.3635 (0.3729)	loss_x 0.3609 (0.3639)	loss_u 0.0026 (0.0090)	acc_x 87.5000 (87.2679)	lr 1.781072e-03
epoch [21/25][1500/4762]	time 0.143 (0.153)	data 0.001 (0.001)	eta 0:56:43	loss 0.4329 (0.3729)	loss_x 0.4257 (0.3640)	loss_u 0.0073 (0.0089)	acc_x 81.2500 (87.2562)	lr 1.781072e-03
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,990
* accuracy: 84.84%
* error: 15.16%
* macro_f1: 84.91%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,589	acc: 98.44%
* class: 1 (bicycle)	total: 3,475	correct: 2,912	acc: 83.80%
* class: 2 (bus)	total: 4,690	correct: 4,271	acc: 91.07%
* class: 3 (car)	total: 10,401	correct: 8,112	acc: 77.99%
* class: 4 (horse)	total: 4,691	correct: 4,587	acc: 97.78%
* class: 5 (knife)	total: 2,075	correct: 1,892	acc: 91.18%
* class: 6 (motorcycle)	total: 5,796	correct: 5,498	acc: 94.86%
* class: 7 (person)	total: 4,000	correct: 2,960	acc: 74.00%
* class: 8 (plant)	total: 4,549	correct: 3,932	acc: 86.44%
* class: 9 (skateboard)	total: 2,281	correct: 2,037	acc: 89.30%
* class: 10 (train)	total: 4,236	correct: 3,895	acc: 91.95%
* class: 11 (truck)	total: 5,548	correct: 3,305	acc: 59.57%
* average: 86.36%
epoch [21/25][1600/4762]	time 0.207 (0.153)	data 0.001 (0.001)	eta 0:56:33	loss 0.4470 (0.3730)	loss_x 0.4362 (0.3642)	loss_u 0.0108 (0.0088)	acc_x 84.3750 (87.2695)	lr 1.781072e-03
epoch [21/25][1700/4762]	time 0.159 (0.153)	data 0.001 (0.001)	eta 0:56:21	loss 0.4451 (0.3736)	loss_x 0.4285 (0.3647)	loss_u 0.0167 (0.0089)	acc_x 84.3750 (87.2426)	lr 1.781072e-03
epoch [21/25][1800/4762]	time 0.158 (0.153)	data 0.001 (0.001)	eta 0:56:13	loss 0.2475 (0.3749)	loss_x 0.2458 (0.3658)	loss_u 0.0017 (0.0091)	acc_x 90.6250 (87.1858)	lr 1.781072e-03
epoch [21/25][1900/4762]	time 0.193 (0.153)	data 0.001 (0.001)	eta 0:55:55	loss 0.7300 (0.3745)	loss_x 0.7221 (0.3656)	loss_u 0.0078 (0.0089)	acc_x 78.1250 (87.1645)	lr 1.781072e-03
epoch [21/25][2000/4762]	time 0.168 (0.153)	data 0.001 (0.001)	eta 0:55:43	loss 0.1483 (0.3744)	loss_x 0.1389 (0.3655)	loss_u 0.0093 (0.0089)	acc_x 100.0000 (87.1531)	lr 1.781072e-03
epoch [21/25][2100/4762]	time 0.155 (0.153)	data 0.001 (0.001)	eta 0:55:23	loss 0.2593 (0.3734)	loss_x 0.2521 (0.3644)	loss_u 0.0072 (0.0090)	acc_x 87.5000 (87.1696)	lr 1.781072e-03
epoch [21/25][2200/4762]	time 0.142 (0.153)	data 0.001 (0.001)	eta 0:55:07	loss 1.0043 (0.3724)	loss_x 0.9969 (0.3634)	loss_u 0.0074 (0.0090)	acc_x 62.5000 (87.2102)	lr 1.781072e-03
epoch [21/25][2300/4762]	time 0.152 (0.153)	data 0.001 (0.001)	eta 0:54:51	loss 0.2963 (0.3721)	loss_x 0.2944 (0.3631)	loss_u 0.0019 (0.0090)	acc_x 90.6250 (87.2147)	lr 1.781072e-03
epoch [21/25][2400/4762]	time 0.158 (0.153)	data 0.001 (0.001)	eta 0:54:36	loss 0.4821 (0.3735)	loss_x 0.4805 (0.3645)	loss_u 0.0015 (0.0089)	acc_x 84.3750 (87.1680)	lr 1.781072e-03
epoch [21/25][2500/4762]	time 0.176 (0.153)	data 0.001 (0.001)	eta 0:54:23	loss 0.4140 (0.3738)	loss_x 0.4111 (0.3649)	loss_u 0.0029 (0.0089)	acc_x 81.2500 (87.1488)	lr 1.781072e-03
epoch [21/25][2600/4762]	time 0.147 (0.153)	data 0.001 (0.001)	eta 0:54:05	loss 0.2221 (0.3741)	loss_x 0.2216 (0.3651)	loss_u 0.0005 (0.0090)	acc_x 93.7500 (87.1370)	lr 1.781072e-03
epoch [21/25][2700/4762]	time 0.138 (0.153)	data 0.001 (0.001)	eta 0:53:49	loss 0.3532 (0.3740)	loss_x 0.3439 (0.3650)	loss_u 0.0093 (0.0090)	acc_x 84.3750 (87.1586)	lr 1.781072e-03
epoch [21/25][2800/4762]	time 0.147 (0.153)	data 0.001 (0.001)	eta 0:53:33	loss 0.3433 (0.3737)	loss_x 0.3405 (0.3647)	loss_u 0.0028 (0.0090)	acc_x 84.3750 (87.1741)	lr 1.781072e-03
epoch [21/25][2900/4762]	time 0.164 (0.153)	data 0.001 (0.001)	eta 0:53:15	loss 0.4939 (0.3741)	loss_x 0.4571 (0.3651)	loss_u 0.0368 (0.0090)	acc_x 81.2500 (87.1562)	lr 1.781072e-03
epoch [21/25][3000/4762]	time 0.138 (0.153)	data 0.001 (0.001)	eta 0:53:02	loss 0.3187 (0.3744)	loss_x 0.3150 (0.3653)	loss_u 0.0037 (0.0090)	acc_x 81.2500 (87.1229)	lr 1.781072e-03
epoch [21/25][3100/4762]	time 0.150 (0.153)	data 0.001 (0.001)	eta 0:52:48	loss 0.2893 (0.3739)	loss_x 0.2784 (0.3649)	loss_u 0.0109 (0.0090)	acc_x 90.6250 (87.1290)	lr 1.781072e-03
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,825
* accuracy: 84.54%
* error: 15.46%
* macro_f1: 84.61%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,586	acc: 98.35%
* class: 1 (bicycle)	total: 3,475	correct: 2,915	acc: 83.88%
* class: 2 (bus)	total: 4,690	correct: 4,264	acc: 90.92%
* class: 3 (car)	total: 10,401	correct: 7,902	acc: 75.97%
* class: 4 (horse)	total: 4,691	correct: 4,591	acc: 97.87%
* class: 5 (knife)	total: 2,075	correct: 1,836	acc: 88.48%
* class: 6 (motorcycle)	total: 5,796	correct: 5,511	acc: 95.08%
* class: 7 (person)	total: 4,000	correct: 2,992	acc: 74.80%
* class: 8 (plant)	total: 4,549	correct: 3,951	acc: 86.85%
* class: 9 (skateboard)	total: 2,281	correct: 2,063	acc: 90.44%
* class: 10 (train)	total: 4,236	correct: 3,935	acc: 92.89%
* class: 11 (truck)	total: 5,548	correct: 3,279	acc: 59.10%
* average: 86.22%
epoch [21/25][3200/4762]	time 0.187 (0.153)	data 0.001 (0.001)	eta 0:52:34	loss 0.2877 (0.3739)	loss_x 0.2860 (0.3649)	loss_u 0.0017 (0.0090)	acc_x 84.3750 (87.1475)	lr 1.781072e-03
epoch [21/25][3300/4762]	time 0.138 (0.153)	data 0.001 (0.001)	eta 0:52:19	loss 0.2351 (0.3736)	loss_x 0.2320 (0.3645)	loss_u 0.0031 (0.0091)	acc_x 90.6250 (87.1544)	lr 1.781072e-03
epoch [21/25][3400/4762]	time 0.141 (0.153)	data 0.001 (0.001)	eta 0:52:03	loss 0.3153 (0.3731)	loss_x 0.3074 (0.3640)	loss_u 0.0079 (0.0091)	acc_x 90.6250 (87.1544)	lr 1.781072e-03
epoch [21/25][3500/4762]	time 0.141 (0.153)	data 0.001 (0.001)	eta 0:51:50	loss 0.2881 (0.3734)	loss_x 0.2825 (0.3642)	loss_u 0.0056 (0.0091)	acc_x 87.5000 (87.1536)	lr 1.781072e-03
epoch [21/25][3600/4762]	time 0.139 (0.153)	data 0.001 (0.001)	eta 0:51:33	loss 0.4246 (0.3739)	loss_x 0.4158 (0.3648)	loss_u 0.0087 (0.0092)	acc_x 87.5000 (87.1328)	lr 1.781072e-03
epoch [21/25][3700/4762]	time 0.147 (0.153)	data 0.001 (0.001)	eta 0:51:17	loss 0.5448 (0.3735)	loss_x 0.5401 (0.3643)	loss_u 0.0047 (0.0092)	acc_x 84.3750 (87.1562)	lr 1.781072e-03
epoch [21/25][3800/4762]	time 0.136 (0.153)	data 0.001 (0.001)	eta 0:51:01	loss 0.4927 (0.3731)	loss_x 0.4894 (0.3638)	loss_u 0.0033 (0.0092)	acc_x 78.1250 (87.1686)	lr 1.781072e-03
epoch [21/25][3900/4762]	time 0.165 (0.153)	data 0.001 (0.001)	eta 0:50:45	loss 0.4250 (0.3723)	loss_x 0.4172 (0.3630)	loss_u 0.0079 (0.0092)	acc_x 84.3750 (87.1963)	lr 1.781072e-03
epoch [21/25][4000/4762]	time 0.162 (0.153)	data 0.001 (0.001)	eta 0:50:29	loss 0.3614 (0.3716)	loss_x 0.3564 (0.3623)	loss_u 0.0050 (0.0093)	acc_x 78.1250 (87.2070)	lr 1.781072e-03
epoch [21/25][4100/4762]	time 0.141 (0.153)	data 0.001 (0.001)	eta 0:50:11	loss 0.3240 (0.3719)	loss_x 0.3134 (0.3627)	loss_u 0.0106 (0.0092)	acc_x 84.3750 (87.1875)	lr 1.781072e-03
epoch [21/25][4200/4762]	time 0.149 (0.153)	data 0.001 (0.001)	eta 0:49:54	loss 0.2558 (0.3715)	loss_x 0.2548 (0.3623)	loss_u 0.0010 (0.0092)	acc_x 93.7500 (87.2024)	lr 1.781072e-03
epoch [21/25][4300/4762]	time 0.146 (0.153)	data 0.001 (0.001)	eta 0:49:38	loss 0.2883 (0.3711)	loss_x 0.2855 (0.3620)	loss_u 0.0029 (0.0092)	acc_x 90.6250 (87.2151)	lr 1.781072e-03
epoch [21/25][4400/4762]	time 0.144 (0.153)	data 0.001 (0.001)	eta 0:49:23	loss 0.4047 (0.3710)	loss_x 0.3985 (0.3618)	loss_u 0.0062 (0.0092)	acc_x 87.5000 (87.2131)	lr 1.781072e-03
epoch [21/25][4500/4762]	time 0.149 (0.153)	data 0.001 (0.001)	eta 0:49:07	loss 0.3555 (0.3708)	loss_x 0.3538 (0.3616)	loss_u 0.0017 (0.0092)	acc_x 90.6250 (87.2160)	lr 1.781072e-03
epoch [21/25][4600/4762]	time 0.140 (0.153)	data 0.001 (0.001)	eta 0:48:51	loss 0.4223 (0.3711)	loss_x 0.4100 (0.3619)	loss_u 0.0123 (0.0092)	acc_x 84.3750 (87.1984)	lr 1.781072e-03
epoch [21/25][4700/4762]	time 0.154 (0.153)	data 0.001 (0.001)	eta 0:48:36	loss 0.2191 (0.3708)	loss_x 0.2177 (0.3616)	loss_u 0.0014 (0.0092)	acc_x 90.6250 (87.2048)	lr 1.781072e-03
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,867
* accuracy: 84.62%
* error: 15.38%
* macro_f1: 84.67%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,589	acc: 98.44%
* class: 1 (bicycle)	total: 3,475	correct: 2,921	acc: 84.06%
* class: 2 (bus)	total: 4,690	correct: 4,256	acc: 90.75%
* class: 3 (car)	total: 10,401	correct: 7,899	acc: 75.94%
* class: 4 (horse)	total: 4,691	correct: 4,591	acc: 97.87%
* class: 5 (knife)	total: 2,075	correct: 1,863	acc: 89.78%
* class: 6 (motorcycle)	total: 5,796	correct: 5,521	acc: 95.26%
* class: 7 (person)	total: 4,000	correct: 3,011	acc: 75.28%
* class: 8 (plant)	total: 4,549	correct: 3,898	acc: 85.69%
* class: 9 (skateboard)	total: 2,281	correct: 2,044	acc: 89.61%
* class: 10 (train)	total: 4,236	correct: 3,926	acc: 92.68%
* class: 11 (truck)	total: 5,548	correct: 3,348	acc: 60.35%
* average: 86.31%
epoch [22/25][100/4762]	time 0.157 (0.157)	data 0.001 (0.004)	eta 0:49:33	loss 0.3542 (0.3511)	loss_x 0.3497 (0.3442)	loss_u 0.0045 (0.0069)	acc_x 84.3750 (87.9062)	lr 2.988172e-03
epoch [22/25][200/4762]	time 0.184 (0.156)	data 0.001 (0.002)	eta 0:48:53	loss 0.3988 (0.3596)	loss_x 0.3895 (0.3522)	loss_u 0.0092 (0.0074)	acc_x 81.2500 (87.3750)	lr 2.988172e-03
epoch [22/25][300/4762]	time 0.142 (0.155)	data 0.001 (0.002)	eta 0:48:16	loss 0.3087 (0.3607)	loss_x 0.3001 (0.3529)	loss_u 0.0085 (0.0078)	acc_x 87.5000 (87.4167)	lr 2.988172e-03
epoch [22/25][400/4762]	time 0.138 (0.154)	data 0.001 (0.001)	eta 0:47:47	loss 0.5415 (0.3592)	loss_x 0.5345 (0.3510)	loss_u 0.0070 (0.0082)	acc_x 81.2500 (87.4531)	lr 2.988172e-03
epoch [22/25][500/4762]	time 0.138 (0.154)	data 0.001 (0.001)	eta 0:47:32	loss 0.5214 (0.3613)	loss_x 0.5187 (0.3532)	loss_u 0.0026 (0.0081)	acc_x 84.3750 (87.3937)	lr 2.988172e-03
epoch [22/25][600/4762]	time 0.164 (0.153)	data 0.001 (0.001)	eta 0:47:08	loss 0.4355 (0.3614)	loss_x 0.4227 (0.3532)	loss_u 0.0128 (0.0082)	acc_x 90.6250 (87.4583)	lr 2.988172e-03
epoch [22/25][700/4762]	time 0.143 (0.154)	data 0.001 (0.001)	eta 0:46:57	loss 0.4119 (0.3617)	loss_x 0.4105 (0.3535)	loss_u 0.0014 (0.0082)	acc_x 84.3750 (87.3661)	lr 2.988172e-03
epoch [22/25][800/4762]	time 0.137 (0.153)	data 0.001 (0.001)	eta 0:46:30	loss 0.4395 (0.3633)	loss_x 0.4318 (0.3551)	loss_u 0.0076 (0.0082)	acc_x 90.6250 (87.3750)	lr 2.988172e-03
epoch [22/25][900/4762]	time 0.141 (0.153)	data 0.001 (0.001)	eta 0:46:14	loss 0.3302 (0.3637)	loss_x 0.3239 (0.3553)	loss_u 0.0063 (0.0084)	acc_x 84.3750 (87.3194)	lr 2.988172e-03
epoch [22/25][1000/4762]	time 0.152 (0.153)	data 0.001 (0.001)	eta 0:45:56	loss 0.3355 (0.3647)	loss_x 0.3322 (0.3562)	loss_u 0.0032 (0.0085)	acc_x 90.6250 (87.2406)	lr 2.988172e-03
epoch [22/25][1100/4762]	time 0.140 (0.152)	data 0.001 (0.001)	eta 0:45:36	loss 0.6669 (0.3644)	loss_x 0.6608 (0.3559)	loss_u 0.0061 (0.0085)	acc_x 78.1250 (87.2500)	lr 2.988172e-03
epoch [22/25][1200/4762]	time 0.173 (0.152)	data 0.001 (0.001)	eta 0:45:19	loss 0.3057 (0.3658)	loss_x 0.3000 (0.3572)	loss_u 0.0058 (0.0086)	acc_x 84.3750 (87.2344)	lr 2.988172e-03
epoch [22/25][1300/4762]	time 0.144 (0.152)	data 0.001 (0.001)	eta 0:45:01	loss 0.2742 (0.3644)	loss_x 0.2665 (0.3557)	loss_u 0.0077 (0.0087)	acc_x 90.6250 (87.3125)	lr 2.988172e-03
epoch [22/25][1400/4762]	time 0.145 (0.152)	data 0.001 (0.001)	eta 0:44:41	loss 0.2444 (0.3646)	loss_x 0.2318 (0.3558)	loss_u 0.0126 (0.0088)	acc_x 93.7500 (87.3304)	lr 2.988172e-03
epoch [22/25][1500/4762]	time 0.152 (0.152)	data 0.001 (0.001)	eta 0:44:26	loss 0.5294 (0.3663)	loss_x 0.5175 (0.3575)	loss_u 0.0119 (0.0089)	acc_x 81.2500 (87.2750)	lr 2.988172e-03
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,730
* accuracy: 84.37%
* error: 15.63%
* macro_f1: 84.50%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,588	acc: 98.41%
* class: 1 (bicycle)	total: 3,475	correct: 2,892	acc: 83.22%
* class: 2 (bus)	total: 4,690	correct: 4,249	acc: 90.60%
* class: 3 (car)	total: 10,401	correct: 7,670	acc: 73.74%
* class: 4 (horse)	total: 4,691	correct: 4,575	acc: 97.53%
* class: 5 (knife)	total: 2,075	correct: 1,868	acc: 90.02%
* class: 6 (motorcycle)	total: 5,796	correct: 5,533	acc: 95.46%
* class: 7 (person)	total: 4,000	correct: 2,990	acc: 74.75%
* class: 8 (plant)	total: 4,549	correct: 3,909	acc: 85.93%
* class: 9 (skateboard)	total: 2,281	correct: 2,078	acc: 91.10%
* class: 10 (train)	total: 4,236	correct: 3,930	acc: 92.78%
* class: 11 (truck)	total: 5,548	correct: 3,448	acc: 62.15%
* average: 86.31%
epoch [22/25][1600/4762]	time 0.145 (0.152)	data 0.001 (0.001)	eta 0:44:13	loss 0.4244 (0.3667)	loss_x 0.4056 (0.3579)	loss_u 0.0188 (0.0088)	acc_x 81.2500 (87.2637)	lr 2.988172e-03
epoch [22/25][1700/4762]	time 0.149 (0.152)	data 0.001 (0.001)	eta 0:44:03	loss 0.6388 (0.3663)	loss_x 0.6145 (0.3574)	loss_u 0.0243 (0.0089)	acc_x 78.1250 (87.2868)	lr 2.988172e-03
epoch [22/25][1800/4762]	time 0.153 (0.153)	data 0.001 (0.001)	eta 0:43:55	loss 0.4847 (0.3653)	loss_x 0.4799 (0.3563)	loss_u 0.0048 (0.0089)	acc_x 84.3750 (87.3090)	lr 2.988172e-03
epoch [22/25][1900/4762]	time 0.143 (0.153)	data 0.001 (0.001)	eta 0:43:37	loss 0.3890 (0.3656)	loss_x 0.3852 (0.3567)	loss_u 0.0038 (0.0089)	acc_x 81.2500 (87.3092)	lr 2.988172e-03
epoch [22/25][2000/4762]	time 0.157 (0.153)	data 0.001 (0.001)	eta 0:43:23	loss 0.2649 (0.3662)	loss_x 0.2614 (0.3573)	loss_u 0.0035 (0.0089)	acc_x 93.7500 (87.3297)	lr 2.988172e-03
epoch [22/25][2100/4762]	time 0.146 (0.153)	data 0.001 (0.001)	eta 0:43:08	loss 0.3143 (0.3658)	loss_x 0.3033 (0.3568)	loss_u 0.0111 (0.0090)	acc_x 90.6250 (87.3720)	lr 2.988172e-03
epoch [22/25][2200/4762]	time 0.138 (0.153)	data 0.001 (0.001)	eta 0:42:55	loss 0.2849 (0.3662)	loss_x 0.2800 (0.3572)	loss_u 0.0048 (0.0090)	acc_x 87.5000 (87.3622)	lr 2.988172e-03
epoch [22/25][2300/4762]	time 0.157 (0.153)	data 0.001 (0.001)	eta 0:42:41	loss 0.2333 (0.3657)	loss_x 0.2268 (0.3566)	loss_u 0.0065 (0.0090)	acc_x 90.6250 (87.3913)	lr 2.988172e-03
epoch [22/25][2400/4762]	time 0.144 (0.153)	data 0.001 (0.001)	eta 0:42:24	loss 0.7262 (0.3660)	loss_x 0.6763 (0.3570)	loss_u 0.0499 (0.0090)	acc_x 75.0000 (87.3711)	lr 2.988172e-03
epoch [22/25][2500/4762]	time 0.166 (0.153)	data 0.001 (0.001)	eta 0:42:10	loss 0.4789 (0.3659)	loss_x 0.4753 (0.3568)	loss_u 0.0036 (0.0090)	acc_x 81.2500 (87.3738)	lr 2.988172e-03
epoch [22/25][2600/4762]	time 0.143 (0.153)	data 0.001 (0.001)	eta 0:41:56	loss 0.4154 (0.3657)	loss_x 0.4118 (0.3567)	loss_u 0.0036 (0.0090)	acc_x 87.5000 (87.3954)	lr 2.988172e-03
epoch [22/25][2700/4762]	time 0.138 (0.153)	data 0.003 (0.001)	eta 0:41:38	loss 0.4574 (0.3662)	loss_x 0.4515 (0.3572)	loss_u 0.0059 (0.0090)	acc_x 81.2500 (87.3785)	lr 2.988172e-03
epoch [22/25][2800/4762]	time 0.175 (0.153)	data 0.001 (0.001)	eta 0:41:22	loss 0.6520 (0.3669)	loss_x 0.6509 (0.3579)	loss_u 0.0011 (0.0090)	acc_x 84.3750 (87.3415)	lr 2.988172e-03
epoch [22/25][2900/4762]	time 0.167 (0.153)	data 0.001 (0.001)	eta 0:41:05	loss 0.4239 (0.3671)	loss_x 0.4047 (0.3581)	loss_u 0.0192 (0.0091)	acc_x 90.6250 (87.3491)	lr 2.988172e-03
epoch [22/25][3000/4762]	time 0.164 (0.153)	data 0.001 (0.001)	eta 0:40:50	loss 0.4254 (0.3672)	loss_x 0.4242 (0.3581)	loss_u 0.0013 (0.0091)	acc_x 81.2500 (87.3344)	lr 2.988172e-03
epoch [22/25][3100/4762]	time 0.142 (0.153)	data 0.001 (0.001)	eta 0:40:35	loss 0.3307 (0.3670)	loss_x 0.3297 (0.3580)	loss_u 0.0010 (0.0090)	acc_x 90.6250 (87.3427)	lr 2.988172e-03
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,691
* accuracy: 84.30%
* error: 15.70%
* macro_f1: 84.35%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,587	acc: 98.38%
* class: 1 (bicycle)	total: 3,475	correct: 2,884	acc: 82.99%
* class: 2 (bus)	total: 4,690	correct: 4,251	acc: 90.64%
* class: 3 (car)	total: 10,401	correct: 7,715	acc: 74.18%
* class: 4 (horse)	total: 4,691	correct: 4,580	acc: 97.63%
* class: 5 (knife)	total: 2,075	correct: 1,868	acc: 90.02%
* class: 6 (motorcycle)	total: 5,796	correct: 5,518	acc: 95.20%
* class: 7 (person)	total: 4,000	correct: 2,796	acc: 69.90%
* class: 8 (plant)	total: 4,549	correct: 3,981	acc: 87.51%
* class: 9 (skateboard)	total: 2,281	correct: 2,053	acc: 90.00%
* class: 10 (train)	total: 4,236	correct: 3,946	acc: 93.15%
* class: 11 (truck)	total: 5,548	correct: 3,512	acc: 63.30%
* average: 86.08%
epoch [22/25][3200/4762]	time 0.144 (0.153)	data 0.000 (0.001)	eta 0:40:22	loss 0.6205 (0.3678)	loss_x 0.6200 (0.3587)	loss_u 0.0005 (0.0091)	acc_x 84.3750 (87.3135)	lr 2.988172e-03
epoch [22/25][3300/4762]	time 0.151 (0.153)	data 0.001 (0.001)	eta 0:40:07	loss 0.3774 (0.3679)	loss_x 0.3762 (0.3588)	loss_u 0.0012 (0.0091)	acc_x 87.5000 (87.3078)	lr 2.988172e-03
epoch [22/25][3400/4762]	time 0.141 (0.153)	data 0.001 (0.001)	eta 0:39:51	loss 0.4281 (0.3679)	loss_x 0.4255 (0.3588)	loss_u 0.0027 (0.0091)	acc_x 87.5000 (87.3263)	lr 2.988172e-03
epoch [22/25][3500/4762]	time 0.145 (0.153)	data 0.001 (0.001)	eta 0:39:37	loss 0.1675 (0.3685)	loss_x 0.1556 (0.3593)	loss_u 0.0120 (0.0092)	acc_x 96.8750 (87.3196)	lr 2.988172e-03
epoch [22/25][3600/4762]	time 0.141 (0.153)	data 0.001 (0.001)	eta 0:39:22	loss 0.5780 (0.3687)	loss_x 0.5648 (0.3595)	loss_u 0.0132 (0.0092)	acc_x 84.3750 (87.3012)	lr 2.988172e-03
epoch [22/25][3700/4762]	time 0.158 (0.153)	data 0.001 (0.001)	eta 0:39:05	loss 0.2976 (0.3691)	loss_x 0.2942 (0.3599)	loss_u 0.0034 (0.0092)	acc_x 87.5000 (87.2863)	lr 2.988172e-03
epoch [22/25][3800/4762]	time 0.146 (0.153)	data 0.001 (0.001)	eta 0:38:49	loss 0.2767 (0.3691)	loss_x 0.2691 (0.3599)	loss_u 0.0076 (0.0092)	acc_x 90.6250 (87.2887)	lr 2.988172e-03
epoch [22/25][3900/4762]	time 0.160 (0.153)	data 0.001 (0.001)	eta 0:38:35	loss 0.3511 (0.3690)	loss_x 0.3500 (0.3598)	loss_u 0.0011 (0.0093)	acc_x 87.5000 (87.2957)	lr 2.988172e-03
epoch [22/25][4000/4762]	time 0.137 (0.153)	data 0.001 (0.001)	eta 0:38:21	loss 0.5896 (0.3692)	loss_x 0.5821 (0.3600)	loss_u 0.0075 (0.0093)	acc_x 75.0000 (87.2969)	lr 2.988172e-03
epoch [22/25][4100/4762]	time 0.141 (0.153)	data 0.001 (0.001)	eta 0:38:05	loss 0.5769 (0.3691)	loss_x 0.5666 (0.3597)	loss_u 0.0104 (0.0093)	acc_x 87.5000 (87.3049)	lr 2.988172e-03
epoch [22/25][4200/4762]	time 0.159 (0.153)	data 0.001 (0.001)	eta 0:37:49	loss 0.2279 (0.3693)	loss_x 0.2245 (0.3600)	loss_u 0.0034 (0.0093)	acc_x 93.7500 (87.3132)	lr 2.988172e-03
epoch [22/25][4300/4762]	time 0.139 (0.153)	data 0.001 (0.001)	eta 0:37:33	loss 0.2071 (0.3687)	loss_x 0.1650 (0.3594)	loss_u 0.0421 (0.0093)	acc_x 93.7500 (87.3234)	lr 2.988172e-03
epoch [22/25][4400/4762]	time 0.143 (0.153)	data 0.001 (0.001)	eta 0:37:17	loss 0.3467 (0.3687)	loss_x 0.3415 (0.3594)	loss_u 0.0051 (0.0093)	acc_x 90.6250 (87.3246)	lr 2.988172e-03
epoch [22/25][4500/4762]	time 0.137 (0.153)	data 0.001 (0.001)	eta 0:37:02	loss 0.5781 (0.3686)	loss_x 0.5768 (0.3593)	loss_u 0.0012 (0.0093)	acc_x 81.2500 (87.3215)	lr 2.988172e-03
epoch [22/25][4600/4762]	time 0.138 (0.153)	data 0.001 (0.001)	eta 0:36:46	loss 0.5162 (0.3686)	loss_x 0.5084 (0.3593)	loss_u 0.0077 (0.0093)	acc_x 84.3750 (87.3193)	lr 2.988172e-03
epoch [22/25][4700/4762]	time 0.141 (0.153)	data 0.001 (0.001)	eta 0:36:30	loss 0.5327 (0.3682)	loss_x 0.5289 (0.3589)	loss_u 0.0038 (0.0092)	acc_x 84.3750 (87.3338)	lr 2.988172e-03
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,984
* accuracy: 84.83%
* error: 15.17%
* macro_f1: 84.92%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,589	acc: 98.44%
* class: 1 (bicycle)	total: 3,475	correct: 2,935	acc: 84.46%
* class: 2 (bus)	total: 4,690	correct: 4,178	acc: 89.08%
* class: 3 (car)	total: 10,401	correct: 7,812	acc: 75.11%
* class: 4 (horse)	total: 4,691	correct: 4,592	acc: 97.89%
* class: 5 (knife)	total: 2,075	correct: 1,894	acc: 91.28%
* class: 6 (motorcycle)	total: 5,796	correct: 5,517	acc: 95.19%
* class: 7 (person)	total: 4,000	correct: 2,886	acc: 72.15%
* class: 8 (plant)	total: 4,549	correct: 3,982	acc: 87.54%
* class: 9 (skateboard)	total: 2,281	correct: 2,035	acc: 89.22%
* class: 10 (train)	total: 4,236	correct: 3,931	acc: 92.80%
* class: 11 (truck)	total: 5,548	correct: 3,633	acc: 65.48%
* average: 86.55%
epoch [23/25][100/4762]	time 0.144 (0.159)	data 0.001 (0.003)	eta 0:37:39	loss 0.5740 (0.3810)	loss_x 0.5693 (0.3717)	loss_u 0.0047 (0.0093)	acc_x 81.2500 (86.0625)	lr 1.405814e-03
epoch [23/25][200/4762]	time 0.135 (0.157)	data 0.001 (0.002)	eta 0:36:51	loss 0.6073 (0.3736)	loss_x 0.6029 (0.3645)	loss_u 0.0044 (0.0091)	acc_x 81.2500 (86.9062)	lr 1.405814e-03
epoch [23/25][300/4762]	time 0.146 (0.156)	data 0.001 (0.002)	eta 0:36:19	loss 0.2388 (0.3727)	loss_x 0.2259 (0.3629)	loss_u 0.0129 (0.0098)	acc_x 93.7500 (87.1354)	lr 1.405814e-03
epoch [23/25][400/4762]	time 0.179 (0.156)	data 0.001 (0.001)	eta 0:35:59	loss 0.2347 (0.3699)	loss_x 0.2296 (0.3601)	loss_u 0.0051 (0.0098)	acc_x 90.6250 (87.3203)	lr 1.405814e-03
epoch [23/25][500/4762]	time 0.156 (0.155)	data 0.001 (0.001)	eta 0:35:32	loss 0.2776 (0.3720)	loss_x 0.2761 (0.3621)	loss_u 0.0015 (0.0099)	acc_x 90.6250 (87.2687)	lr 1.405814e-03
epoch [23/25][600/4762]	time 0.178 (0.155)	data 0.001 (0.001)	eta 0:35:17	loss 0.3361 (0.3748)	loss_x 0.3350 (0.3649)	loss_u 0.0011 (0.0099)	acc_x 87.5000 (87.1667)	lr 1.405814e-03
epoch [23/25][700/4762]	time 0.156 (0.154)	data 0.001 (0.001)	eta 0:34:55	loss 0.2184 (0.3760)	loss_x 0.1952 (0.3661)	loss_u 0.0232 (0.0099)	acc_x 93.7500 (87.1429)	lr 1.405814e-03
epoch [23/25][800/4762]	time 0.144 (0.154)	data 0.001 (0.001)	eta 0:34:40	loss 0.4075 (0.3747)	loss_x 0.3998 (0.3651)	loss_u 0.0077 (0.0096)	acc_x 90.6250 (87.1562)	lr 1.405814e-03
epoch [23/25][900/4762]	time 0.151 (0.154)	data 0.001 (0.001)	eta 0:34:23	loss 0.3899 (0.3755)	loss_x 0.3829 (0.3657)	loss_u 0.0070 (0.0098)	acc_x 81.2500 (87.1389)	lr 1.405814e-03
epoch [23/25][1000/4762]	time 0.156 (0.154)	data 0.001 (0.001)	eta 0:34:05	loss 0.3147 (0.3746)	loss_x 0.3124 (0.3648)	loss_u 0.0023 (0.0098)	acc_x 87.5000 (87.1813)	lr 1.405814e-03
epoch [23/25][1100/4762]	time 0.143 (0.154)	data 0.001 (0.001)	eta 0:33:46	loss 0.2966 (0.3747)	loss_x 0.2898 (0.3648)	loss_u 0.0068 (0.0099)	acc_x 93.7500 (87.1932)	lr 1.405814e-03
epoch [23/25][1200/4762]	time 0.143 (0.154)	data 0.001 (0.001)	eta 0:33:28	loss 0.3582 (0.3761)	loss_x 0.3362 (0.3661)	loss_u 0.0219 (0.0100)	acc_x 93.7500 (87.1667)	lr 1.405814e-03
epoch [23/25][1300/4762]	time 0.169 (0.154)	data 0.001 (0.001)	eta 0:33:15	loss 0.4815 (0.3746)	loss_x 0.4752 (0.3645)	loss_u 0.0063 (0.0101)	acc_x 87.5000 (87.2380)	lr 1.405814e-03
epoch [23/25][1400/4762]	time 0.157 (0.154)	data 0.001 (0.001)	eta 0:33:01	loss 0.3466 (0.3754)	loss_x 0.3291 (0.3653)	loss_u 0.0175 (0.0101)	acc_x 90.6250 (87.1562)	lr 1.405814e-03
epoch [23/25][1500/4762]	time 0.151 (0.154)	data 0.001 (0.001)	eta 0:32:45	loss 0.2460 (0.3738)	loss_x 0.2354 (0.3637)	loss_u 0.0107 (0.0101)	acc_x 93.7500 (87.2292)	lr 1.405814e-03
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,780
* accuracy: 84.46%
* error: 15.54%
* macro_f1: 84.64%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,580	acc: 98.19%
* class: 1 (bicycle)	total: 3,475	correct: 2,948	acc: 84.83%
* class: 2 (bus)	total: 4,690	correct: 4,269	acc: 91.02%
* class: 3 (car)	total: 10,401	correct: 7,732	acc: 74.34%
* class: 4 (horse)	total: 4,691	correct: 4,587	acc: 97.78%
* class: 5 (knife)	total: 2,075	correct: 1,885	acc: 90.84%
* class: 6 (motorcycle)	total: 5,796	correct: 5,528	acc: 95.38%
* class: 7 (person)	total: 4,000	correct: 2,982	acc: 74.55%
* class: 8 (plant)	total: 4,549	correct: 3,871	acc: 85.10%
* class: 9 (skateboard)	total: 2,281	correct: 2,079	acc: 91.14%
* class: 10 (train)	total: 4,236	correct: 3,904	acc: 92.16%
* class: 11 (truck)	total: 5,548	correct: 3,415	acc: 61.55%
* average: 86.41%
epoch [23/25][1600/4762]	time 0.154 (0.154)	data 0.001 (0.001)	eta 0:32:29	loss 0.6733 (0.3749)	loss_x 0.6679 (0.3649)	loss_u 0.0054 (0.0100)	acc_x 78.1250 (87.1973)	lr 1.405814e-03
epoch [23/25][1700/4762]	time 0.145 (0.154)	data 0.001 (0.001)	eta 0:32:20	loss 0.2655 (0.3740)	loss_x 0.2616 (0.3640)	loss_u 0.0039 (0.0100)	acc_x 93.7500 (87.2371)	lr 1.405814e-03
epoch [23/25][1800/4762]	time 0.167 (0.155)	data 0.001 (0.001)	eta 0:32:10	loss 0.3841 (0.3731)	loss_x 0.3803 (0.3631)	loss_u 0.0038 (0.0100)	acc_x 87.5000 (87.2517)	lr 1.405814e-03
epoch [23/25][1900/4762]	time 0.170 (0.155)	data 0.001 (0.001)	eta 0:31:54	loss 0.2565 (0.3735)	loss_x 0.2542 (0.3634)	loss_u 0.0023 (0.0101)	acc_x 90.6250 (87.2204)	lr 1.405814e-03
epoch [23/25][2000/4762]	time 0.139 (0.154)	data 0.001 (0.001)	eta 0:31:35	loss 0.4738 (0.3744)	loss_x 0.4733 (0.3645)	loss_u 0.0006 (0.0099)	acc_x 84.3750 (87.1828)	lr 1.405814e-03
epoch [23/25][2100/4762]	time 0.149 (0.154)	data 0.001 (0.001)	eta 0:31:17	loss 0.5058 (0.3727)	loss_x 0.4971 (0.3629)	loss_u 0.0087 (0.0098)	acc_x 78.1250 (87.2411)	lr 1.405814e-03
epoch [23/25][2200/4762]	time 0.145 (0.154)	data 0.001 (0.001)	eta 0:31:02	loss 0.1862 (0.3726)	loss_x 0.1705 (0.3628)	loss_u 0.0157 (0.0098)	acc_x 96.8750 (87.2614)	lr 1.405814e-03
epoch [23/25][2300/4762]	time 0.138 (0.154)	data 0.001 (0.001)	eta 0:30:45	loss 0.3219 (0.3727)	loss_x 0.3156 (0.3629)	loss_u 0.0063 (0.0098)	acc_x 87.5000 (87.2568)	lr 1.405814e-03
epoch [23/25][2400/4762]	time 0.136 (0.154)	data 0.001 (0.001)	eta 0:30:29	loss 0.3860 (0.3725)	loss_x 0.3855 (0.3627)	loss_u 0.0005 (0.0098)	acc_x 90.6250 (87.2539)	lr 1.405814e-03
epoch [23/25][2500/4762]	time 0.168 (0.154)	data 0.001 (0.001)	eta 0:30:13	loss 0.3662 (0.3727)	loss_x 0.3581 (0.3629)	loss_u 0.0081 (0.0098)	acc_x 84.3750 (87.2313)	lr 1.405814e-03
epoch [23/25][2600/4762]	time 0.157 (0.154)	data 0.001 (0.001)	eta 0:29:56	loss 0.2692 (0.3725)	loss_x 0.2552 (0.3626)	loss_u 0.0140 (0.0098)	acc_x 93.7500 (87.2668)	lr 1.405814e-03
epoch [23/25][2700/4762]	time 0.156 (0.154)	data 0.001 (0.001)	eta 0:29:40	loss 0.5217 (0.3720)	loss_x 0.5193 (0.3621)	loss_u 0.0023 (0.0099)	acc_x 81.2500 (87.2859)	lr 1.405814e-03
epoch [23/25][2800/4762]	time 0.147 (0.154)	data 0.001 (0.001)	eta 0:29:25	loss 0.7129 (0.3719)	loss_x 0.7086 (0.3620)	loss_u 0.0043 (0.0099)	acc_x 75.0000 (87.2768)	lr 1.405814e-03
epoch [23/25][2900/4762]	time 0.149 (0.154)	data 0.001 (0.001)	eta 0:29:09	loss 0.4151 (0.3732)	loss_x 0.4137 (0.3633)	loss_u 0.0013 (0.0098)	acc_x 90.6250 (87.2306)	lr 1.405814e-03
epoch [23/25][3000/4762]	time 0.153 (0.154)	data 0.001 (0.001)	eta 0:28:54	loss 0.6045 (0.3722)	loss_x 0.6013 (0.3624)	loss_u 0.0032 (0.0098)	acc_x 81.2500 (87.2750)	lr 1.405814e-03
epoch [23/25][3100/4762]	time 0.149 (0.154)	data 0.001 (0.001)	eta 0:28:38	loss 0.4011 (0.3724)	loss_x 0.3984 (0.3626)	loss_u 0.0027 (0.0098)	acc_x 84.3750 (87.2681)	lr 1.405814e-03
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,837
* accuracy: 84.56%
* error: 15.44%
* macro_f1: 84.82%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,586	acc: 98.35%
* class: 1 (bicycle)	total: 3,475	correct: 2,888	acc: 83.11%
* class: 2 (bus)	total: 4,690	correct: 4,268	acc: 91.00%
* class: 3 (car)	total: 10,401	correct: 7,788	acc: 74.88%
* class: 4 (horse)	total: 4,691	correct: 4,575	acc: 97.53%
* class: 5 (knife)	total: 2,075	correct: 1,817	acc: 87.57%
* class: 6 (motorcycle)	total: 5,796	correct: 5,515	acc: 95.15%
* class: 7 (person)	total: 4,000	correct: 3,047	acc: 76.17%
* class: 8 (plant)	total: 4,549	correct: 3,951	acc: 86.85%
* class: 9 (skateboard)	total: 2,281	correct: 2,064	acc: 90.49%
* class: 10 (train)	total: 4,236	correct: 3,948	acc: 93.20%
* class: 11 (truck)	total: 5,548	correct: 3,390	acc: 61.10%
* average: 86.28%
epoch [23/25][3200/4762]	time 0.168 (0.154)	data 0.001 (0.001)	eta 0:28:24	loss 0.3235 (0.3720)	loss_x 0.3203 (0.3621)	loss_u 0.0032 (0.0098)	acc_x 90.6250 (87.2773)	lr 1.405814e-03
epoch [23/25][3300/4762]	time 0.154 (0.154)	data 0.001 (0.001)	eta 0:28:12	loss 0.2729 (0.3716)	loss_x 0.2702 (0.3618)	loss_u 0.0028 (0.0098)	acc_x 90.6250 (87.2860)	lr 1.405814e-03
epoch [23/25][3400/4762]	time 0.136 (0.154)	data 0.001 (0.001)	eta 0:27:55	loss 0.2278 (0.3717)	loss_x 0.2152 (0.3619)	loss_u 0.0126 (0.0098)	acc_x 93.7500 (87.2812)	lr 1.405814e-03
epoch [23/25][3500/4762]	time 0.162 (0.154)	data 0.001 (0.001)	eta 0:27:40	loss 0.2210 (0.3716)	loss_x 0.2187 (0.3618)	loss_u 0.0023 (0.0097)	acc_x 90.6250 (87.2893)	lr 1.405814e-03
epoch [23/25][3600/4762]	time 0.147 (0.154)	data 0.001 (0.001)	eta 0:27:24	loss 0.2738 (0.3711)	loss_x 0.2731 (0.3613)	loss_u 0.0007 (0.0097)	acc_x 87.5000 (87.2995)	lr 1.405814e-03
epoch [23/25][3700/4762]	time 0.137 (0.154)	data 0.001 (0.001)	eta 0:27:08	loss 0.4685 (0.3709)	loss_x 0.4655 (0.3613)	loss_u 0.0029 (0.0096)	acc_x 84.3750 (87.2829)	lr 1.405814e-03
epoch [23/25][3800/4762]	time 0.147 (0.154)	data 0.001 (0.001)	eta 0:26:52	loss 0.7744 (0.3705)	loss_x 0.7667 (0.3609)	loss_u 0.0078 (0.0096)	acc_x 75.0000 (87.3084)	lr 1.405814e-03
epoch [23/25][3900/4762]	time 0.160 (0.154)	data 0.001 (0.001)	eta 0:26:36	loss 0.2350 (0.3704)	loss_x 0.2332 (0.3607)	loss_u 0.0018 (0.0096)	acc_x 93.7500 (87.3077)	lr 1.405814e-03
epoch [23/25][4000/4762]	time 0.143 (0.154)	data 0.001 (0.001)	eta 0:26:20	loss 0.3039 (0.3700)	loss_x 0.2884 (0.3604)	loss_u 0.0155 (0.0096)	acc_x 87.5000 (87.3289)	lr 1.405814e-03
epoch [23/25][4100/4762]	time 0.137 (0.154)	data 0.001 (0.001)	eta 0:26:04	loss 0.5187 (0.3707)	loss_x 0.5139 (0.3611)	loss_u 0.0049 (0.0096)	acc_x 75.0000 (87.2950)	lr 1.405814e-03
epoch [23/25][4200/4762]	time 0.147 (0.154)	data 0.001 (0.001)	eta 0:25:48	loss 0.4041 (0.3707)	loss_x 0.3798 (0.3611)	loss_u 0.0243 (0.0096)	acc_x 87.5000 (87.3065)	lr 1.405814e-03
epoch [23/25][4300/4762]	time 0.154 (0.154)	data 0.001 (0.001)	eta 0:25:33	loss 0.3634 (0.3698)	loss_x 0.3457 (0.3603)	loss_u 0.0177 (0.0096)	acc_x 87.5000 (87.3328)	lr 1.405814e-03
epoch [23/25][4400/4762]	time 0.151 (0.154)	data 0.001 (0.001)	eta 0:25:17	loss 0.5005 (0.3693)	loss_x 0.4763 (0.3598)	loss_u 0.0242 (0.0095)	acc_x 81.2500 (87.3494)	lr 1.405814e-03
epoch [23/25][4500/4762]	time 0.163 (0.153)	data 0.001 (0.001)	eta 0:25:01	loss 0.4618 (0.3693)	loss_x 0.4489 (0.3598)	loss_u 0.0129 (0.0095)	acc_x 81.2500 (87.3472)	lr 1.405814e-03
epoch [23/25][4600/4762]	time 0.150 (0.153)	data 0.001 (0.001)	eta 0:24:45	loss 0.2546 (0.3689)	loss_x 0.2370 (0.3595)	loss_u 0.0177 (0.0094)	acc_x 90.6250 (87.3601)	lr 1.405814e-03
epoch [23/25][4700/4762]	time 0.139 (0.153)	data 0.001 (0.001)	eta 0:24:29	loss 0.6299 (0.3688)	loss_x 0.6175 (0.3594)	loss_u 0.0123 (0.0094)	acc_x 75.0000 (87.3590)	lr 1.405814e-03
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,948
* accuracy: 84.76%
* error: 15.24%
* macro_f1: 84.97%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,587	acc: 98.38%
* class: 1 (bicycle)	total: 3,475	correct: 2,924	acc: 84.14%
* class: 2 (bus)	total: 4,690	correct: 4,284	acc: 91.34%
* class: 3 (car)	total: 10,401	correct: 7,888	acc: 75.84%
* class: 4 (horse)	total: 4,691	correct: 4,574	acc: 97.51%
* class: 5 (knife)	total: 2,075	correct: 1,853	acc: 89.30%
* class: 6 (motorcycle)	total: 5,796	correct: 5,500	acc: 94.89%
* class: 7 (person)	total: 4,000	correct: 3,101	acc: 77.53%
* class: 8 (plant)	total: 4,549	correct: 3,923	acc: 86.24%
* class: 9 (skateboard)	total: 2,281	correct: 2,049	acc: 89.83%
* class: 10 (train)	total: 4,236	correct: 3,913	acc: 92.37%
* class: 11 (truck)	total: 5,548	correct: 3,352	acc: 60.42%
* average: 86.48%
epoch [24/25][100/4762]	time 0.186 (0.165)	data 0.001 (0.007)	eta 0:25:56	loss 0.4882 (0.3458)	loss_x 0.4791 (0.3360)	loss_u 0.0091 (0.0099)	acc_x 84.3750 (88.4375)	lr 0.000000e+00
epoch [24/25][200/4762]	time 0.151 (0.160)	data 0.001 (0.004)	eta 0:24:53	loss 0.2411 (0.3552)	loss_x 0.2399 (0.3461)	loss_u 0.0011 (0.0091)	acc_x 93.7500 (88.0469)	lr 0.000000e+00
epoch [24/25][300/4762]	time 0.142 (0.157)	data 0.000 (0.003)	eta 0:24:09	loss 0.3146 (0.3555)	loss_x 0.3124 (0.3468)	loss_u 0.0022 (0.0087)	acc_x 87.5000 (88.1458)	lr 0.000000e+00
epoch [24/25][400/4762]	time 0.175 (0.156)	data 0.001 (0.002)	eta 0:23:39	loss 0.3484 (0.3581)	loss_x 0.3439 (0.3491)	loss_u 0.0045 (0.0090)	acc_x 90.6250 (88.0859)	lr 0.000000e+00
epoch [24/25][500/4762]	time 0.151 (0.155)	data 0.001 (0.002)	eta 0:23:18	loss 0.2949 (0.3601)	loss_x 0.2813 (0.3508)	loss_u 0.0137 (0.0093)	acc_x 93.7500 (87.9000)	lr 0.000000e+00
epoch [24/25][600/4762]	time 0.173 (0.155)	data 0.001 (0.002)	eta 0:23:01	loss 0.3021 (0.3646)	loss_x 0.2931 (0.3547)	loss_u 0.0090 (0.0099)	acc_x 87.5000 (87.6927)	lr 0.000000e+00
epoch [24/25][700/4762]	time 0.154 (0.155)	data 0.001 (0.002)	eta 0:22:46	loss 0.3494 (0.3622)	loss_x 0.3373 (0.3527)	loss_u 0.0121 (0.0095)	acc_x 87.5000 (87.8259)	lr 0.000000e+00
epoch [24/25][800/4762]	time 0.160 (0.155)	data 0.001 (0.002)	eta 0:22:30	loss 0.4462 (0.3636)	loss_x 0.4375 (0.3542)	loss_u 0.0087 (0.0094)	acc_x 84.3750 (87.6992)	lr 0.000000e+00
epoch [24/25][900/4762]	time 0.141 (0.155)	data 0.001 (0.002)	eta 0:22:15	loss 0.4559 (0.3654)	loss_x 0.4335 (0.3560)	loss_u 0.0224 (0.0093)	acc_x 78.1250 (87.4861)	lr 0.000000e+00
epoch [24/25][1000/4762]	time 0.148 (0.155)	data 0.001 (0.001)	eta 0:22:00	loss 0.4739 (0.3667)	loss_x 0.4731 (0.3574)	loss_u 0.0007 (0.0093)	acc_x 81.2500 (87.4188)	lr 0.000000e+00
epoch [24/25][1100/4762]	time 0.153 (0.155)	data 0.001 (0.001)	eta 0:21:42	loss 0.4081 (0.3674)	loss_x 0.4024 (0.3580)	loss_u 0.0057 (0.0094)	acc_x 87.5000 (87.3835)	lr 0.000000e+00
epoch [24/25][1200/4762]	time 0.190 (0.155)	data 0.001 (0.001)	eta 0:21:26	loss 0.2890 (0.3695)	loss_x 0.2885 (0.3601)	loss_u 0.0005 (0.0094)	acc_x 90.6250 (87.3776)	lr 0.000000e+00
epoch [24/25][1300/4762]	time 0.153 (0.154)	data 0.001 (0.001)	eta 0:21:07	loss 0.3085 (0.3705)	loss_x 0.3074 (0.3612)	loss_u 0.0011 (0.0092)	acc_x 93.7500 (87.3486)	lr 0.000000e+00
epoch [24/25][1400/4762]	time 0.140 (0.154)	data 0.001 (0.001)	eta 0:20:49	loss 0.2515 (0.3699)	loss_x 0.2490 (0.3606)	loss_u 0.0024 (0.0092)	acc_x 90.6250 (87.3415)	lr 0.000000e+00
epoch [24/25][1500/4762]	time 0.165 (0.154)	data 0.001 (0.001)	eta 0:20:33	loss 0.4599 (0.3705)	loss_x 0.4526 (0.3612)	loss_u 0.0072 (0.0093)	acc_x 81.2500 (87.3229)	lr 0.000000e+00
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,809
* accuracy: 84.51%
* error: 15.49%
* macro_f1: 84.69%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,586	acc: 98.35%
* class: 1 (bicycle)	total: 3,475	correct: 2,909	acc: 83.71%
* class: 2 (bus)	total: 4,690	correct: 4,260	acc: 90.83%
* class: 3 (car)	total: 10,401	correct: 7,790	acc: 74.90%
* class: 4 (horse)	total: 4,691	correct: 4,585	acc: 97.74%
* class: 5 (knife)	total: 2,075	correct: 1,875	acc: 90.36%
* class: 6 (motorcycle)	total: 5,796	correct: 5,510	acc: 95.07%
* class: 7 (person)	total: 4,000	correct: 3,055	acc: 76.38%
* class: 8 (plant)	total: 4,549	correct: 3,847	acc: 84.57%
* class: 9 (skateboard)	total: 2,281	correct: 2,050	acc: 89.87%
* class: 10 (train)	total: 4,236	correct: 3,919	acc: 92.52%
* class: 11 (truck)	total: 5,548	correct: 3,423	acc: 61.70%
* average: 86.33%
epoch [24/25][1600/4762]	time 0.149 (0.154)	data 0.001 (0.001)	eta 0:20:19	loss 0.5697 (0.3707)	loss_x 0.5364 (0.3614)	loss_u 0.0333 (0.0092)	acc_x 78.1250 (87.3281)	lr 0.000000e+00
epoch [24/25][1700/4762]	time 0.143 (0.154)	data 0.001 (0.001)	eta 0:20:05	loss 0.4631 (0.3702)	loss_x 0.4551 (0.3610)	loss_u 0.0080 (0.0092)	acc_x 90.6250 (87.3125)	lr 0.000000e+00
epoch [24/25][1800/4762]	time 0.179 (0.154)	data 0.001 (0.002)	eta 0:19:53	loss 0.4887 (0.3694)	loss_x 0.4853 (0.3603)	loss_u 0.0034 (0.0091)	acc_x 84.3750 (87.3438)	lr 0.000000e+00
epoch [24/25][1900/4762]	time 0.136 (0.154)	data 0.001 (0.001)	eta 0:19:35	loss 0.3139 (0.3698)	loss_x 0.3126 (0.3608)	loss_u 0.0013 (0.0090)	acc_x 90.6250 (87.3109)	lr 0.000000e+00
epoch [24/25][2000/4762]	time 0.160 (0.154)	data 0.001 (0.001)	eta 0:19:18	loss 0.4226 (0.3708)	loss_x 0.4212 (0.3618)	loss_u 0.0014 (0.0090)	acc_x 84.3750 (87.2641)	lr 0.000000e+00
epoch [24/25][2100/4762]	time 0.140 (0.154)	data 0.001 (0.001)	eta 0:19:02	loss 0.6173 (0.3706)	loss_x 0.6164 (0.3615)	loss_u 0.0009 (0.0091)	acc_x 71.8750 (87.2946)	lr 0.000000e+00
epoch [24/25][2200/4762]	time 0.148 (0.154)	data 0.001 (0.001)	eta 0:18:45	loss 0.4609 (0.3701)	loss_x 0.4551 (0.3611)	loss_u 0.0058 (0.0091)	acc_x 87.5000 (87.2997)	lr 0.000000e+00
epoch [24/25][2300/4762]	time 0.163 (0.154)	data 0.001 (0.001)	eta 0:18:31	loss 0.2761 (0.3691)	loss_x 0.2723 (0.3600)	loss_u 0.0038 (0.0091)	acc_x 87.5000 (87.3247)	lr 0.000000e+00
epoch [24/25][2400/4762]	time 0.171 (0.154)	data 0.001 (0.001)	eta 0:18:15	loss 0.4849 (0.3702)	loss_x 0.4830 (0.3612)	loss_u 0.0020 (0.0090)	acc_x 78.1250 (87.2839)	lr 0.000000e+00
epoch [24/25][2500/4762]	time 0.144 (0.154)	data 0.001 (0.001)	eta 0:18:00	loss 0.3318 (0.3710)	loss_x 0.3188 (0.3620)	loss_u 0.0130 (0.0090)	acc_x 87.5000 (87.2463)	lr 0.000000e+00
epoch [24/25][2600/4762]	time 0.156 (0.154)	data 0.001 (0.001)	eta 0:17:45	loss 0.3685 (0.3706)	loss_x 0.3355 (0.3616)	loss_u 0.0330 (0.0090)	acc_x 87.5000 (87.2656)	lr 0.000000e+00
epoch [24/25][2700/4762]	time 0.147 (0.154)	data 0.001 (0.001)	eta 0:17:30	loss 0.4421 (0.3713)	loss_x 0.4365 (0.3623)	loss_u 0.0057 (0.0090)	acc_x 87.5000 (87.2373)	lr 0.000000e+00
epoch [24/25][2800/4762]	time 0.160 (0.154)	data 0.001 (0.001)	eta 0:17:15	loss 0.0768 (0.3712)	loss_x 0.0742 (0.3622)	loss_u 0.0026 (0.0090)	acc_x 100.0000 (87.2522)	lr 0.000000e+00
epoch [24/25][2900/4762]	time 0.158 (0.154)	data 0.001 (0.001)	eta 0:16:59	loss 0.4780 (0.3717)	loss_x 0.4717 (0.3627)	loss_u 0.0064 (0.0089)	acc_x 84.3750 (87.2392)	lr 0.000000e+00
epoch [24/25][3000/4762]	time 0.144 (0.154)	data 0.001 (0.001)	eta 0:16:43	loss 0.6090 (0.3721)	loss_x 0.5907 (0.3632)	loss_u 0.0183 (0.0089)	acc_x 81.2500 (87.2229)	lr 0.000000e+00
epoch [24/25][3100/4762]	time 0.143 (0.154)	data 0.001 (0.001)	eta 0:16:27	loss 0.3698 (0.3716)	loss_x 0.3689 (0.3627)	loss_u 0.0009 (0.0089)	acc_x 87.5000 (87.2450)	lr 0.000000e+00
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,595
* accuracy: 84.12%
* error: 15.88%
* macro_f1: 84.20%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,584	acc: 98.30%
* class: 1 (bicycle)	total: 3,475	correct: 2,914	acc: 83.86%
* class: 2 (bus)	total: 4,690	correct: 4,252	acc: 90.66%
* class: 3 (car)	total: 10,401	correct: 7,655	acc: 73.60%
* class: 4 (horse)	total: 4,691	correct: 4,591	acc: 97.87%
* class: 5 (knife)	total: 2,075	correct: 1,839	acc: 88.63%
* class: 6 (motorcycle)	total: 5,796	correct: 5,529	acc: 95.39%
* class: 7 (person)	total: 4,000	correct: 2,836	acc: 70.90%
* class: 8 (plant)	total: 4,549	correct: 3,896	acc: 85.65%
* class: 9 (skateboard)	total: 2,281	correct: 2,076	acc: 91.01%
* class: 10 (train)	total: 4,236	correct: 3,927	acc: 92.71%
* class: 11 (truck)	total: 5,548	correct: 3,496	acc: 63.01%
* average: 85.97%
epoch [24/25][3200/4762]	time 0.208 (0.154)	data 0.001 (0.001)	eta 0:16:13	loss 0.4673 (0.3710)	loss_x 0.4659 (0.3621)	loss_u 0.0014 (0.0089)	acc_x 87.5000 (87.2549)	lr 0.000000e+00
epoch [24/25][3300/4762]	time 0.166 (0.154)	data 0.001 (0.001)	eta 0:15:59	loss 0.4091 (0.3710)	loss_x 0.3989 (0.3621)	loss_u 0.0102 (0.0089)	acc_x 87.5000 (87.2462)	lr 0.000000e+00
epoch [24/25][3400/4762]	time 0.138 (0.154)	data 0.001 (0.001)	eta 0:15:44	loss 0.7328 (0.3711)	loss_x 0.6750 (0.3622)	loss_u 0.0578 (0.0089)	acc_x 78.1250 (87.2390)	lr 0.000000e+00
epoch [24/25][3500/4762]	time 0.169 (0.154)	data 0.001 (0.001)	eta 0:15:29	loss 0.4523 (0.3707)	loss_x 0.4487 (0.3618)	loss_u 0.0036 (0.0089)	acc_x 81.2500 (87.2420)	lr 0.000000e+00
epoch [24/25][3600/4762]	time 0.159 (0.154)	data 0.001 (0.001)	eta 0:15:13	loss 0.5497 (0.3705)	loss_x 0.5474 (0.3616)	loss_u 0.0024 (0.0089)	acc_x 81.2500 (87.2483)	lr 0.000000e+00
epoch [24/25][3700/4762]	time 0.153 (0.154)	data 0.001 (0.001)	eta 0:14:57	loss 0.3097 (0.3705)	loss_x 0.3078 (0.3616)	loss_u 0.0019 (0.0089)	acc_x 90.6250 (87.2399)	lr 0.000000e+00
epoch [24/25][3800/4762]	time 0.137 (0.154)	data 0.001 (0.001)	eta 0:14:41	loss 0.6476 (0.3706)	loss_x 0.6271 (0.3617)	loss_u 0.0205 (0.0089)	acc_x 81.2500 (87.2533)	lr 0.000000e+00
epoch [24/25][3900/4762]	time 0.150 (0.154)	data 0.001 (0.001)	eta 0:14:26	loss 0.3090 (0.3709)	loss_x 0.2889 (0.3620)	loss_u 0.0201 (0.0089)	acc_x 90.6250 (87.2428)	lr 0.000000e+00
epoch [24/25][4000/4762]	time 0.142 (0.154)	data 0.001 (0.001)	eta 0:14:11	loss 0.6461 (0.3710)	loss_x 0.6447 (0.3620)	loss_u 0.0015 (0.0090)	acc_x 78.1250 (87.2523)	lr 0.000000e+00
epoch [24/25][4100/4762]	time 0.136 (0.154)	data 0.001 (0.001)	eta 0:13:56	loss 0.4640 (0.3710)	loss_x 0.3443 (0.3621)	loss_u 0.1197 (0.0089)	acc_x 90.6250 (87.2576)	lr 0.000000e+00
epoch [24/25][4200/4762]	time 0.158 (0.154)	data 0.001 (0.001)	eta 0:13:40	loss 0.3819 (0.3705)	loss_x 0.3761 (0.3615)	loss_u 0.0058 (0.0090)	acc_x 84.3750 (87.2783)	lr 0.000000e+00
epoch [24/25][4300/4762]	time 0.160 (0.154)	data 0.003 (0.001)	eta 0:13:24	loss 0.4955 (0.3704)	loss_x 0.4943 (0.3614)	loss_u 0.0012 (0.0090)	acc_x 84.3750 (87.2907)	lr 0.000000e+00
epoch [24/25][4400/4762]	time 0.144 (0.154)	data 0.001 (0.001)	eta 0:13:08	loss 0.1985 (0.3699)	loss_x 0.1956 (0.3609)	loss_u 0.0029 (0.0090)	acc_x 90.6250 (87.3161)	lr 0.000000e+00
epoch [24/25][4500/4762]	time 0.139 (0.154)	data 0.002 (0.001)	eta 0:12:53	loss 0.3040 (0.3698)	loss_x 0.2963 (0.3609)	loss_u 0.0078 (0.0090)	acc_x 90.6250 (87.3174)	lr 0.000000e+00
epoch [24/25][4600/4762]	time 0.151 (0.154)	data 0.001 (0.001)	eta 0:12:37	loss 0.3236 (0.3694)	loss_x 0.3190 (0.3605)	loss_u 0.0046 (0.0090)	acc_x 84.3750 (87.3186)	lr 0.000000e+00
epoch [24/25][4700/4762]	time 0.169 (0.154)	data 0.001 (0.001)	eta 0:12:21	loss 0.3758 (0.3692)	loss_x 0.3707 (0.3602)	loss_u 0.0051 (0.0090)	acc_x 90.6250 (87.3265)	lr 0.000000e+00
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,667
* accuracy: 84.25%
* error: 15.75%
* macro_f1: 84.28%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,580	acc: 98.19%
* class: 1 (bicycle)	total: 3,475	correct: 2,896	acc: 83.34%
* class: 2 (bus)	total: 4,690	correct: 4,252	acc: 90.66%
* class: 3 (car)	total: 10,401	correct: 7,822	acc: 75.20%
* class: 4 (horse)	total: 4,691	correct: 4,581	acc: 97.66%
* class: 5 (knife)	total: 2,075	correct: 1,878	acc: 90.51%
* class: 6 (motorcycle)	total: 5,796	correct: 5,521	acc: 95.26%
* class: 7 (person)	total: 4,000	correct: 2,904	acc: 72.60%
* class: 8 (plant)	total: 4,549	correct: 3,888	acc: 85.47%
* class: 9 (skateboard)	total: 2,281	correct: 2,059	acc: 90.27%
* class: 10 (train)	total: 4,236	correct: 3,936	acc: 92.92%
* class: 11 (truck)	total: 5,548	correct: 3,350	acc: 60.38%
* average: 86.04%
epoch [25/25][100/4762]	time 0.177 (0.165)	data 0.001 (0.004)	eta 0:12:49	loss 0.1916 (0.3680)	loss_x 0.1902 (0.3569)	loss_u 0.0014 (0.0111)	acc_x 93.7500 (88.5312)	lr 1.405814e-03
epoch [25/25][200/4762]	time 0.179 (0.161)	data 0.001 (0.002)	eta 0:12:13	loss 0.2227 (0.3723)	loss_x 0.2151 (0.3627)	loss_u 0.0075 (0.0096)	acc_x 96.8750 (87.6719)	lr 1.405814e-03
epoch [25/25][300/4762]	time 0.137 (0.160)	data 0.000 (0.002)	eta 0:11:53	loss 0.3026 (0.3614)	loss_x 0.3015 (0.3526)	loss_u 0.0011 (0.0089)	acc_x 90.6250 (87.8438)	lr 1.405814e-03
epoch [25/25][400/4762]	time 0.147 (0.158)	data 0.001 (0.002)	eta 0:11:30	loss 0.4072 (0.3645)	loss_x 0.4071 (0.3560)	loss_u 0.0001 (0.0085)	acc_x 90.6250 (87.5859)	lr 1.405814e-03
epoch [25/25][500/4762]	time 0.174 (0.157)	data 0.001 (0.001)	eta 0:11:09	loss 0.5133 (0.3654)	loss_x 0.5010 (0.3569)	loss_u 0.0123 (0.0084)	acc_x 78.1250 (87.5375)	lr 1.405814e-03
epoch [25/25][600/4762]	time 0.169 (0.156)	data 0.001 (0.001)	eta 0:10:50	loss 0.3301 (0.3686)	loss_x 0.3237 (0.3600)	loss_u 0.0065 (0.0086)	acc_x 90.6250 (87.4167)	lr 1.405814e-03
epoch [25/25][700/4762]	time 0.175 (0.156)	data 0.001 (0.001)	eta 0:10:32	loss 0.2742 (0.3701)	loss_x 0.2736 (0.3617)	loss_u 0.0005 (0.0085)	acc_x 93.7500 (87.3884)	lr 1.405814e-03
epoch [25/25][800/4762]	time 0.159 (0.156)	data 0.002 (0.001)	eta 0:10:16	loss 0.4696 (0.3700)	loss_x 0.4574 (0.3616)	loss_u 0.0121 (0.0084)	acc_x 81.2500 (87.3516)	lr 1.405814e-03
epoch [25/25][900/4762]	time 0.157 (0.155)	data 0.001 (0.001)	eta 0:10:00	loss 0.3124 (0.3705)	loss_x 0.3035 (0.3621)	loss_u 0.0089 (0.0084)	acc_x 84.3750 (87.3090)	lr 1.405814e-03
epoch [25/25][1000/4762]	time 0.144 (0.155)	data 0.001 (0.001)	eta 0:09:43	loss 0.3293 (0.3711)	loss_x 0.3268 (0.3624)	loss_u 0.0025 (0.0087)	acc_x 87.5000 (87.2594)	lr 1.405814e-03
epoch [25/25][1100/4762]	time 0.145 (0.155)	data 0.001 (0.001)	eta 0:09:27	loss 0.6497 (0.3741)	loss_x 0.5847 (0.3653)	loss_u 0.0651 (0.0088)	acc_x 68.7500 (87.1676)	lr 1.405814e-03
epoch [25/25][1200/4762]	time 0.156 (0.155)	data 0.001 (0.001)	eta 0:09:10	loss 0.1938 (0.3732)	loss_x 0.1718 (0.3643)	loss_u 0.0220 (0.0089)	acc_x 93.7500 (87.2396)	lr 1.405814e-03
epoch [25/25][1300/4762]	time 0.141 (0.154)	data 0.001 (0.001)	eta 0:08:54	loss 0.4009 (0.3736)	loss_x 0.3950 (0.3643)	loss_u 0.0059 (0.0093)	acc_x 84.3750 (87.1995)	lr 1.405814e-03
epoch [25/25][1400/4762]	time 0.141 (0.154)	data 0.001 (0.001)	eta 0:08:38	loss 0.4662 (0.3730)	loss_x 0.4657 (0.3636)	loss_u 0.0005 (0.0094)	acc_x 90.6250 (87.2076)	lr 1.405814e-03
epoch [25/25][1500/4762]	time 0.142 (0.154)	data 0.001 (0.001)	eta 0:08:23	loss 0.5211 (0.3732)	loss_x 0.5192 (0.3637)	loss_u 0.0019 (0.0095)	acc_x 81.2500 (87.1833)	lr 1.405814e-03
Do evaluation on test set
=> result
* total: 55,388
* correct: 47,028
* accuracy: 84.91%
* error: 15.09%
* macro_f1: 85.04%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,582	acc: 98.24%
* class: 1 (bicycle)	total: 3,475	correct: 2,929	acc: 84.29%
* class: 2 (bus)	total: 4,690	correct: 4,227	acc: 90.13%
* class: 3 (car)	total: 10,401	correct: 8,020	acc: 77.11%
* class: 4 (horse)	total: 4,691	correct: 4,579	acc: 97.61%
* class: 5 (knife)	total: 2,075	correct: 1,848	acc: 89.06%
* class: 6 (motorcycle)	total: 5,796	correct: 5,510	acc: 95.07%
* class: 7 (person)	total: 4,000	correct: 3,076	acc: 76.90%
* class: 8 (plant)	total: 4,549	correct: 3,931	acc: 86.41%
* class: 9 (skateboard)	total: 2,281	correct: 2,067	acc: 90.62%
* class: 10 (train)	total: 4,236	correct: 3,922	acc: 92.59%
* class: 11 (truck)	total: 5,548	correct: 3,337	acc: 60.15%
* average: 86.51%
epoch [25/25][1600/4762]	time 0.153 (0.154)	data 0.001 (0.001)	eta 0:08:07	loss 0.5102 (0.3713)	loss_x 0.4976 (0.3617)	loss_u 0.0126 (0.0095)	acc_x 78.1250 (87.2617)	lr 1.405814e-03
epoch [25/25][1700/4762]	time 0.165 (0.155)	data 0.001 (0.001)	eta 0:07:53	loss 0.3860 (0.3725)	loss_x 0.3786 (0.3630)	loss_u 0.0074 (0.0095)	acc_x 90.6250 (87.2224)	lr 1.405814e-03
epoch [25/25][1800/4762]	time 0.150 (0.155)	data 0.001 (0.001)	eta 0:07:39	loss 0.1830 (0.3719)	loss_x 0.1798 (0.3624)	loss_u 0.0032 (0.0095)	acc_x 90.6250 (87.2240)	lr 1.405814e-03
epoch [25/25][1900/4762]	time 0.142 (0.155)	data 0.001 (0.001)	eta 0:07:23	loss 0.3627 (0.3713)	loss_x 0.3605 (0.3618)	loss_u 0.0022 (0.0095)	acc_x 87.5000 (87.2352)	lr 1.405814e-03
epoch [25/25][2000/4762]	time 0.157 (0.155)	data 0.001 (0.001)	eta 0:07:07	loss 0.4061 (0.3719)	loss_x 0.4050 (0.3625)	loss_u 0.0011 (0.0094)	acc_x 87.5000 (87.2250)	lr 1.405814e-03
epoch [25/25][2100/4762]	time 0.163 (0.155)	data 0.001 (0.001)	eta 0:06:51	loss 0.4499 (0.3718)	loss_x 0.4333 (0.3624)	loss_u 0.0166 (0.0094)	acc_x 87.5000 (87.2485)	lr 1.405814e-03
epoch [25/25][2200/4762]	time 0.137 (0.155)	data 0.001 (0.001)	eta 0:06:36	loss 0.2057 (0.3713)	loss_x 0.2046 (0.3620)	loss_u 0.0012 (0.0093)	acc_x 96.8750 (87.2614)	lr 1.405814e-03
epoch [25/25][2300/4762]	time 0.145 (0.155)	data 0.001 (0.001)	eta 0:06:20	loss 0.1412 (0.3711)	loss_x 0.1313 (0.3618)	loss_u 0.0099 (0.0094)	acc_x 93.7500 (87.2745)	lr 1.405814e-03
epoch [25/25][2400/4762]	time 0.149 (0.154)	data 0.001 (0.001)	eta 0:06:04	loss 0.4385 (0.3709)	loss_x 0.4215 (0.3615)	loss_u 0.0170 (0.0094)	acc_x 81.2500 (87.2943)	lr 1.405814e-03
epoch [25/25][2500/4762]	time 0.154 (0.154)	data 0.001 (0.001)	eta 0:05:49	loss 0.2024 (0.3707)	loss_x 0.1985 (0.3613)	loss_u 0.0040 (0.0094)	acc_x 93.7500 (87.3125)	lr 1.405814e-03
epoch [25/25][2600/4762]	time 0.140 (0.154)	data 0.001 (0.001)	eta 0:05:33	loss 0.2446 (0.3699)	loss_x 0.2382 (0.3604)	loss_u 0.0064 (0.0095)	acc_x 96.8750 (87.3389)	lr 1.405814e-03
epoch [25/25][2700/4762]	time 0.147 (0.154)	data 0.001 (0.001)	eta 0:05:17	loss 0.3085 (0.3698)	loss_x 0.2983 (0.3603)	loss_u 0.0102 (0.0095)	acc_x 90.6250 (87.3472)	lr 1.405814e-03
epoch [25/25][2800/4762]	time 0.140 (0.154)	data 0.001 (0.001)	eta 0:05:02	loss 0.3642 (0.3694)	loss_x 0.3608 (0.3599)	loss_u 0.0034 (0.0095)	acc_x 90.6250 (87.3728)	lr 1.405814e-03
epoch [25/25][2900/4762]	time 0.156 (0.154)	data 0.001 (0.001)	eta 0:04:46	loss 0.5581 (0.3698)	loss_x 0.5410 (0.3603)	loss_u 0.0171 (0.0095)	acc_x 78.1250 (87.3761)	lr 1.405814e-03
epoch [25/25][3000/4762]	time 0.143 (0.154)	data 0.001 (0.001)	eta 0:04:30	loss 0.2971 (0.3693)	loss_x 0.2798 (0.3599)	loss_u 0.0173 (0.0095)	acc_x 87.5000 (87.4062)	lr 1.405814e-03
epoch [25/25][3100/4762]	time 0.159 (0.154)	data 0.001 (0.001)	eta 0:04:15	loss 0.2581 (0.3692)	loss_x 0.2490 (0.3598)	loss_u 0.0091 (0.0094)	acc_x 90.6250 (87.4032)	lr 1.405814e-03
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,780
* accuracy: 84.46%
* error: 15.54%
* macro_f1: 84.52%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,592	acc: 98.52%
* class: 1 (bicycle)	total: 3,475	correct: 2,927	acc: 84.23%
* class: 2 (bus)	total: 4,690	correct: 4,228	acc: 90.15%
* class: 3 (car)	total: 10,401	correct: 7,849	acc: 75.46%
* class: 4 (horse)	total: 4,691	correct: 4,598	acc: 98.02%
* class: 5 (knife)	total: 2,075	correct: 1,884	acc: 90.80%
* class: 6 (motorcycle)	total: 5,796	correct: 5,512	acc: 95.10%
* class: 7 (person)	total: 4,000	correct: 2,829	acc: 70.72%
* class: 8 (plant)	total: 4,549	correct: 3,888	acc: 85.47%
* class: 9 (skateboard)	total: 2,281	correct: 2,065	acc: 90.53%
* class: 10 (train)	total: 4,236	correct: 3,946	acc: 93.15%
* class: 11 (truck)	total: 5,548	correct: 3,462	acc: 62.40%
* average: 86.21%
epoch [25/25][3200/4762]	time 0.147 (0.154)	data 0.001 (0.001)	eta 0:04:00	loss 0.2721 (0.3688)	loss_x 0.2615 (0.3594)	loss_u 0.0106 (0.0094)	acc_x 87.5000 (87.4043)	lr 1.405814e-03
epoch [25/25][3300/4762]	time 0.178 (0.154)	data 0.001 (0.001)	eta 0:03:45	loss 0.4526 (0.3688)	loss_x 0.4172 (0.3595)	loss_u 0.0354 (0.0094)	acc_x 87.5000 (87.4271)	lr 1.405814e-03
epoch [25/25][3400/4762]	time 0.139 (0.154)	data 0.001 (0.001)	eta 0:03:29	loss 0.5220 (0.3684)	loss_x 0.5198 (0.3591)	loss_u 0.0022 (0.0093)	acc_x 84.3750 (87.4393)	lr 1.405814e-03
epoch [25/25][3500/4762]	time 0.158 (0.154)	data 0.001 (0.001)	eta 0:03:14	loss 0.4385 (0.3682)	loss_x 0.4380 (0.3588)	loss_u 0.0004 (0.0093)	acc_x 78.1250 (87.4339)	lr 1.405814e-03
epoch [25/25][3600/4762]	time 0.148 (0.154)	data 0.001 (0.001)	eta 0:02:58	loss 0.2919 (0.3695)	loss_x 0.2701 (0.3602)	loss_u 0.0218 (0.0093)	acc_x 87.5000 (87.4028)	lr 1.405814e-03
epoch [25/25][3700/4762]	time 0.166 (0.154)	data 0.001 (0.001)	eta 0:02:43	loss 0.4517 (0.3691)	loss_x 0.4495 (0.3598)	loss_u 0.0022 (0.0093)	acc_x 84.3750 (87.4139)	lr 1.405814e-03
epoch [25/25][3800/4762]	time 0.166 (0.154)	data 0.001 (0.001)	eta 0:02:27	loss 0.4140 (0.3693)	loss_x 0.3993 (0.3600)	loss_u 0.0147 (0.0092)	acc_x 84.3750 (87.4137)	lr 1.405814e-03
epoch [25/25][3900/4762]	time 0.149 (0.154)	data 0.001 (0.001)	eta 0:02:12	loss 0.2221 (0.3689)	loss_x 0.2211 (0.3597)	loss_u 0.0010 (0.0092)	acc_x 93.7500 (87.4175)	lr 1.405814e-03
epoch [25/25][4000/4762]	time 0.188 (0.154)	data 0.001 (0.001)	eta 0:01:57	loss 0.1965 (0.3688)	loss_x 0.1958 (0.3595)	loss_u 0.0007 (0.0092)	acc_x 90.6250 (87.4227)	lr 1.405814e-03
epoch [25/25][4100/4762]	time 0.137 (0.154)	data 0.001 (0.001)	eta 0:01:41	loss 0.2630 (0.3691)	loss_x 0.2611 (0.3599)	loss_u 0.0019 (0.0092)	acc_x 90.6250 (87.4040)	lr 1.405814e-03
epoch [25/25][4200/4762]	time 0.142 (0.154)	data 0.001 (0.001)	eta 0:01:26	loss 0.4092 (0.3694)	loss_x 0.4079 (0.3602)	loss_u 0.0013 (0.0092)	acc_x 84.3750 (87.3884)	lr 1.405814e-03
epoch [25/25][4300/4762]	time 0.139 (0.154)	data 0.001 (0.001)	eta 0:01:10	loss 0.2963 (0.3698)	loss_x 0.2858 (0.3606)	loss_u 0.0105 (0.0092)	acc_x 93.7500 (87.3677)	lr 1.405814e-03
epoch [25/25][4400/4762]	time 0.164 (0.153)	data 0.001 (0.001)	eta 0:00:55	loss 0.3587 (0.3702)	loss_x 0.3583 (0.3609)	loss_u 0.0004 (0.0092)	acc_x 84.3750 (87.3601)	lr 1.405814e-03
epoch [25/25][4500/4762]	time 0.140 (0.153)	data 0.001 (0.001)	eta 0:00:40	loss 0.3928 (0.3708)	loss_x 0.3920 (0.3616)	loss_u 0.0007 (0.0092)	acc_x 87.5000 (87.3410)	lr 1.405814e-03
epoch [25/25][4600/4762]	time 0.172 (0.153)	data 0.001 (0.001)	eta 0:00:24	loss 0.2821 (0.3707)	loss_x 0.2805 (0.3616)	loss_u 0.0016 (0.0092)	acc_x 84.3750 (87.3512)	lr 1.405814e-03
epoch [25/25][4700/4762]	time 0.154 (0.153)	data 0.001 (0.001)	eta 0:00:09	loss 0.4385 (0.3707)	loss_x 0.4301 (0.3616)	loss_u 0.0084 (0.0091)	acc_x 87.5000 (87.3531)	lr 1.405814e-03
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,787
* accuracy: 84.47%
* error: 15.53%
* macro_f1: 84.66%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,568	acc: 97.86%
* class: 1 (bicycle)	total: 3,475	correct: 2,934	acc: 84.43%
* class: 2 (bus)	total: 4,690	correct: 4,247	acc: 90.55%
* class: 3 (car)	total: 10,401	correct: 7,977	acc: 76.69%
* class: 4 (horse)	total: 4,691	correct: 4,596	acc: 97.97%
* class: 5 (knife)	total: 2,075	correct: 1,854	acc: 89.35%
* class: 6 (motorcycle)	total: 5,796	correct: 5,514	acc: 95.13%
* class: 7 (person)	total: 4,000	correct: 2,972	acc: 74.30%
* class: 8 (plant)	total: 4,549	correct: 3,833	acc: 84.26%
* class: 9 (skateboard)	total: 2,281	correct: 2,064	acc: 90.49%
* class: 10 (train)	total: 4,236	correct: 3,893	acc: 91.90%
* class: 11 (truck)	total: 5,548	correct: 3,335	acc: 60.11%
* average: 86.09%
Checkpoint saved to "output/visda17/DAPL/ep25-32-v1/1.0_0.6_1.0_t0/seed_2/prompt_learner/model.pth.tar-25"
Finished training
Do evaluation on test set
=> result
* total: 55,388
* correct: 46,787
* accuracy: 84.47%
* error: 15.53%
* macro_f1: 84.66%
=> per-class result
* class: 0 (aeroplane)	total: 3,646	correct: 3,568	acc: 97.86%
* class: 1 (bicycle)	total: 3,475	correct: 2,934	acc: 84.43%
* class: 2 (bus)	total: 4,690	correct: 4,247	acc: 90.55%
* class: 3 (car)	total: 10,401	correct: 7,977	acc: 76.69%
* class: 4 (horse)	total: 4,691	correct: 4,596	acc: 97.97%
* class: 5 (knife)	total: 2,075	correct: 1,854	acc: 89.35%
* class: 6 (motorcycle)	total: 5,796	correct: 5,514	acc: 95.13%
* class: 7 (person)	total: 4,000	correct: 2,972	acc: 74.30%
* class: 8 (plant)	total: 4,549	correct: 3,833	acc: 84.26%
* class: 9 (skateboard)	total: 2,281	correct: 2,064	acc: 90.49%
* class: 10 (train)	total: 4,236	correct: 3,893	acc: 91.90%
* class: 11 (truck)	total: 5,548	correct: 3,335	acc: 60.11%
* average: 86.09%
Elapsed: 6:10:27
